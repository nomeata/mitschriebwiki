\documentclass[parskip,a4paper,twoside,DIV15,BCOR12mm]{scrbook}
\usepackage{la}

\author{Die Mitarbeiter von \url{http://mitschriebwiki.nomeata.de/}}
\title{Lineare Algebra II}

\makeindex

\begin{document}
\maketitle

\renewcommand{\thechapter}{\Roman{chapter}}
\addcontentsline{toc}{chapter}{Inhaltsverzeichnis}

\tableofcontents

\chapter{Vorwort}

\section{√úber dieses Skriptum}
Dies ist ein erweiterter Mitschrieb der Vorlesung \glqq Lineare Algebra II\grqq\ von Prof. Dr. Schmidt im
Sommersemester 2010 an der Universit√§t Karlsruhe (KIT). Die Mitschriebe der Vorlesung werden mit
ausdr√ºcklicher Genehmigung von Prof. Dr. Schmidt hier ver√∂ffentlicht, Prof. Dr. Schmidt ist f√ºr den
Inhalt nicht verantwortlich.

\section{Wer}
Gestartet wurde das Mitschriebwiki von Joachim Breitner. Beteiligt an diesem Mitschrieb sind
Rebecca Schwerdt, Manuel Kaiser und Philipp Ost.

\section{Wo}
Alle Kapitel inklusive \LaTeX-Quellen k√∂nnen unter \url{http://mitschriebwiki.nomeata.de} abgerufen werden.
Dort ist ein \emph{Wiki} eingerichtet und von Joachim Breitner um die \LaTeX-Funktionen erweitert worden.
Das hei√üt, jeder kann Fehler nachbessern und sich an der Entwicklung
beteiligen. Auf Wunsch ist auch ein Zugang √ºber \emph{Subversion} m√∂glich.


\renewcommand{\thechapter}{\arabic{chapter}}
\renewcommand{\chaptername}{¬ß}
\setcounter{chapter}{14}

\chapter{Multilineare Abbildungen und Tensorprodukte}
\section{Bilinearformen}
\begin{definition}
\index{Vektorraumpaarung}\index{Paarung}
\index{Bilinearform}
\index{ausgeartet!Paarung}
Seien $V,W$ $K$-VRme. Ein Abbildung $P:V\times W\to K$ hei√üt \textbf{\mbox{(Vektorraum-)}Paarung},
falls $P$ in jedem Argument linear ist, d.h. wenn f√ºr jedes feste $w_o\in W$
\[P(\cdot,w_0):V\to K, v\mapsto P(v,w_0)\]
und f√ºr jedes feste $v_0\in V$
\[P(v_0,\cdot):W\to K, w\mapsto P(v_0,w)\]
eine lineare Abbildung, also Linearform ist.\\
Im Fall $V=W$ hei√üt $P$ eine \textbf{Bilinearform} auf $V$.\\
Eine Paarung $P$ hei√üt \textbf{nicht ausgeartet}, wenn f√ºr jedes $w_0\in W$ und
f√ºr jedes $v_0\in V$ die Abbildung $P(\cdot,w_0)$ bzw. $P(v_0,\cdot)$ nicht die Nullabbildung
ist.
\end{definition}

\begin{comment}
Die Menge $\mathcal{P}(V,W)$ aller Paarungen von $V$ und $W$ ist ein untervektorraum
des $K$-VRms $\Abb(V\times W,K)$ aller Abbildungen von $V\times W$ nach $K$.
\end{comment}

\begin{example}
Auf dem Dualraum $W:=V^*(=\Hom(V,K))$ ist die nicht ausgeartete Paarung
\[P:V\times V^*\to K,(v,f)\mapsto f(v)\]
eine Bilinearform.\\
F√ºr eine Paarung $P:V\times W\to K$ setzen wir $\rho_w(v):=P(v,w)$ und erhalten
so Linearformen $\rho_w\in V^*$ f√ºr alle $w\in W$.
\end{example}

\begin{theo}
\begin{enumerate}
\item Die Abbildung $\rho:W\to V^*,w\mapsto \rho_w$ ist ein Homomorphismus
von $K$-VRmen.
\item Die Zuordnung $\eta:P\to \rho$ ist ein Isomorphismus, es gilt:
\[\mathcal{P}(V,W)\stackrel{\sim}{\to} \Hom(W,V^*)\]
\end{enumerate}
\end{theo}

\begin{proof}
\begin{enumerate}
\item Es gilt f√ºr alle $\alpha\in K,w_1,w_2\in W$:
\begin{align*}
\rho_{\alpha w_1+w_2}&=(v\mapsto P(v,\alpha w_1+w_2))\\
&=(v\mapsto \alpha P(v,w_1)+P(v,w_2))\\
&=\alpha((v\mapsto P(v,w_1))+(v\mapsto P(v,w_2)))\\
&=\alpha\rho_{w_1}+\rho_{w_2} 
\end{align*}
\item Homomorphie selbst nachrechnen!\\
Die Umkehrabbildung ist:
\[\Hom(W,V^*)\to \mathcal{P}(V,W),\rho\mapsto P:=((v,w)\mapsto(\rho(w))(v))\]
\end{enumerate}
\end{proof}

\begin{remind}
Lineare Abbildungen sind bereits durch ihre Wirkung auf einer Basis eindeutig
bestimmt. Dieses Prinzip gilt auch f√ºr Paarungen.
\end{remind}

\begin{comment}
\index{bilinear!Fortsetzung}\index{Fortsetzung!bilineare}
Seien $V,W$ $K$-VRme mit jeweiliger Basis $B:=\{b_1,\ldots,b_m\}\subseteq V,
C:=\{c_1,\ldots,c_n\}\subseteq W$, so ist eine Paarung $P$ auf $V\times W$
Bereits durch ihre Einschr√§nkung auf $B\times C$ festgelegt.\\
F√ºr $v:=\sum_{i=1}^m \alpha_i b_i,w:=\sum_{j=1}^n \beta_j c_j$ gilt:
\[P(v,w)=\sum_{i=1}^m\sum_{j=1}^n \alpha_i\beta_j\cdot P(b_i,c_j)\]
Jede Abbildung $P':B\times C\to K$ definiert √ºber diese Gleichung eine Paarung
$P':V\times W\to K$. Diese hei√üt \textbf{bilineare Fortsetzung}.
\end{comment}

\begin{definition}
\index{Fundamentalmatrix}
Die Matrix $D_{BC}(P):=(P(b_i,c_j))\in K^{m\times n}$ hei√üt \textbf{Fundamentalmatrix}
der Paarung $P$ bzgl. der Basen $B$ und $C$. Mit den Kkordinatenvektoren:
\[D_B(v)=\begin{pmatrix}\alpha_1\\\vdots\\\alpha_m\end{pmatrix}\text{ und }
D_C(w)=\begin{pmatrix}\beta_1\\\vdots\\\beta_n\end{pmatrix}\]
gilt nach obiger Gleichung:
\[P(v,w)=D_B(v)^T\cdot D_{BC}(P)\cdot D_C(w)\]
\end{definition}

\begin{theo}
Eine Paarung $P$ endlichdimensionaler $K$-VRme $V,W$ mit Basen $B,C$ ist genau dann
nicht ausgeartet, wenn die Dimensionen von $V$ und $W$ gleich und $D_{BC}(P)$ invertierbar
ist.
\end{theo}

\begin{proof}
Der Beweis erfolgt durch Implikation in beiden Richtungen:
\begin{enumerate}
\item["`$\impliedby$"'] Sei $\dim V=\dim W$ und $F:=D_{BC}(P)$ invertierbar.
Sei nun $w\ne 0\in W$, dann ist $D_C(w)\ne 0$.\\
Daraus folgt, dass auch $F\cdot D_C(w)$ nicht null ist. O.B.d.A sei die
$i$-te Koordinate ungleich null. Dann gilt:
\[P(b_i,w)=e_i^T\cdot F\cdot D_C(w)\ne 0\]
Insbesondere ist $P(\cdot,w)\ne 0$.
Analog folgt $P(v,\cdot)\ne 0$ f√ºr alle $0\ne v\in V$. Also ist $P$ nicht ausgeartet.
\item["`$\implies$"'] Sei $P$ nicht ausgeartet, dann ist insbesondere $\rho:W\to V^*,
w\mapsto \rho_w=(v\mapsto P(v,w))$ injektiv. Daraus folgt:
\[\dim V=\dim V^*\ge \dim W\]
Analog gilt:
\[\dim W=\dim W^*\ge \dim V\]
Also haben $V$ und $W$ gleiche Dimension.\\
\textbf{Annahme:} $F$ ist nicht invertierbar.\\
Dann existiert ein $D_C(w)\ne 0$, sodass $F\cdot D_C(w)$ gilt. Daraus folgt
f√ºr alle $v\in V$:
\[P(v,w)=D_B(v)^T\cdot F\cdot D_C(w)=0\ \lightning\]
Also ist $P(\cdot,w)=0$, was einen Widerspruch zur nicht Ausgeartetheit von $P$ darstellt.
\end{enumerate}
\end{proof}

\begin{theo}
Seien $B,\hat B$ Basen von $V$, $C,\hat C$ Basen von $W$ und $P$ eine Paarung von
$V$ und $W$. Dann gilt:
\[D_{BC}(P)=D_{\hat BB}(\id_V)^T\cdot D_{\hat B\hat C}(P)\cdot D_{\hat CC}(\id_W)\]
\end{theo}

\begin{proof}
F√ºr $(v,w)\in V\times W$ gilt:
\begin{align*}
P(v,w)&=D_{\hat B}(v)^T\cdot D_{\hat B\hat C}(P)\cdot D_{\hat C}(w)\\
&=(D_{\hat BB}(\id_V)\cdot D_B(v))^T\cdot D_{\hat B\hat C}(P)\cdot(D_{\hat CC}(\id_W)\cdot D_C(w))\\
&=D_B(v)^T \cdot (D_{\hat BB}(\id_V)^T \cdot D_{\hat B\hat C}(P)\cdot D_{\hat CC}(\id_W))\cdot D_C(w)
\end{align*}
Aber es gilt auch:
\[P(v,w)=D_B(v)^T\cdot D_{BC}(P)\cdot D_C(w)\]
Durch einsetzen aller Basispaare $b_i,c_j$ folgt die Behauptung.
\end{proof}

\begin{comment}
Mit der Dualbasis $B^*=\{b_1^*,\ldots,b_m^*\}$ von $V^*$ zu $B$ (erinnere:
$b_k^*(b_i)=\delta_{ik}$) gilt f√ºr $\rho=\eta(P):W\to V^*$:
\[\rho(c_j)=\sum_{i=1}^n P(b_i,c_j)\cdot b_i^*\]
D.h. $D_{B^*C}(\rho)=D_{BC}(P)$.
\end{comment}

\begin{proof}
Es gilt:
\begin{align*}
\rho(c_j)&=P(\cdot,c_j)\\
&=(b_i\mapsto P(b_i,c_j))\\
&=\sum_{i=1}^n P(b_i,c_j)\cdot b_i^*
\end{align*}
\end{proof}

\begin{example}
Sei $W=V^*$ und f√ºr alle $f\in V^*$ sei $P(v,f)=f(v)$. Nehme nun die Dualbasis 
$C=B*$ zur Basis $B$ von $V$. Dann gilt:
\[P(b_i,b_k^*)=b_k^*(b_i)=\delta{ik}\]
Also ist $D_{BB}(P)=I_m$
\end{example}

Wir spezialisieren nun $W=V$.

\begin{definition}
\index{symmetrisch!Paarung}
\index{Orthogonalbasis (OGB)}
\index{Orthonormalbasis (ONB)}
Sei $P$ eine Paarung von $V$ und $V$.
\begin{enumerate}[(a)]
\item $P$ hei√üt \textbf{symmetrisch}, falls f√ºr alle $v,w\in V$ gilt:
\[P(v,w)=P(w,v)\]
\item Eine Basis $B=\{b_1,\ldots,b_m\}$ hei√üt \textbf{Orthogonalbasis} (OGB) von $V$
bez√ºglich $P$, wenn f√ºr alle $i\ne j$ gilt:
\[P(b_i,b_j)=0\]
\item Eine Basis $B=\{b_1,\ldots,b_m\}$ hei√üt \textbf{Orthonormalbasis} (ONB) von $V$
bez√ºglich $P$, wenn $B$ OGB ist und f√ºr alle $i\in\{1,\ldots,m\}$ gilt:
\[P(b_i,b_i)=1\]
\end{enumerate}
\end{definition}

\begin{comment}
Falls eine OGB $B$ existiert, so ist die Fundamentalmatrix $D_{BB}(P)$ diagonal, insbesondere
symmetrisch, also ist $P$ symmetrisch.
\end{comment}

\begin{theo}
Sei $K$ ein K√∂rper mit $1+1\ne 0$ und $P$ eine symmetrische Bilinearform auf einem
$K$-VRm $V$ mit $\dim V=:n<\infty$. Dann existiert eine OGB von $V$ bzgl. $P$.
\end{theo}

\begin{proof}
Der beweis erfolgt durch vollst√§ndige Induktion nach der Dimension $n$.\\
F√ºr $n=1$ ist die Behauptung offensichtlich wahr, nehmen wir also als Induktionsvoraussetzung an,
dass sie f√ºr $n-1$ erf√ºllt sei.\\
Da f√ºr $P=0$ jede Basis Orthogonalbasis ist, l√§sst sich im Folgenden o.B.d.A annehmen,
dass $P\ne 0$ ist. Also existieren $v,w\in V$ mit $P(v,w)\ne 0$, es gilt:
\begin{align*}
P(v+w,v+w)&=P(v,v)+P(w,w)+P(v,w)+P(w,v)\\
&= P(v,v)+P(w,w)+2P(v,w)
\end{align*}
Daraus folgt:
\[P(v,v)\ne 0 \vee P(w,w)\ne 0 \vee P(v+w,v+w)\ne 0\]
Also existiert ein $b_1\in V$ mit $P(b_1,b_1)\ne 0$. Nun betrachte:
\begin{align*}
W&:=\{v\in V\mid P(v,b_1)=0\}\\
&=\Kern(P(\cdot,b_1))
\end{align*}
Nach Dimensionsformel ist $\dim W=n-1$ und $V=K\cdot b_1 \oplus W$. Da die 
Einschr√§nkung $P|_{W\times W}$ symmetrisch ist, existiert nach Induktionsvoraussetzung
eine OGB $\{b_2,\ldots,b_n\}$ von $W$ bzgl. $P|_{W\times W}$.\\
Da au√üerdem f√ºr alle $w\in W$ $P(w,b_1)=0$ ist, ist
$\{b_1,\ldots,b_n\}$ OGB von $V$ bzgl. $P$.
\end{proof}

\begin{comment}
\index{Fourierformel}
Die Basisdarstellung bzgl. eine ONB $B$ lautet:
\[v=\sum_{b\in B}P(v,b)\cdot b\]
\end{comment}

\begin{proof}
Leichte √úbung!
\end{proof}

\section{Multilineare Abbildungen}
Veralgemeinere nun die Bilinearit√§t und den Zielbereich.

\begin{definition}
\index{multilinear}
Seien $V_1,\ldots,V_n,W$ $K$-VRme und $M:V_1\times\ldots\times V_n\to W$ eine Abbildung.\\
$M$ hei√üt \textbf{(n-fach) multilinear}, falls f√ºr jedes $i\in\{1,\ldots,n\}$ bei fester
Wahl von $v_j\in V_j$ (f√ºr alle $j\ne i$) $M(v_1,\ldots,v_{i-1},\cdot,v_{i+1},\ldots,v_n):V_i\to W$
eine lineare Abbildubg ist.
\end{definition}

\begin{example}
Multilineare Abbildungen sind:
\begin{enumerate}
\item Die Determinantenabbildung:
\[\det:K^n\times\ldots\times K^n\to K\]
\item Die Skalarmultiplikation:
\[K\times V\to V,(\lambda,v)\mapsto \lambda\cdot v\]
\item Die Matrizenmultiplikation:
\[K^{p\times q}\times K^{q\times r}\times K^{r\times s}\to K^{p\times s},(A,B,C)\mapsto A\cdot B\cdot C\]
\end{enumerate}
\end{example}

\section{Tensorprodukte}
\begin{definition}
\index{universell!Abbildungseigenschaft (UAE)}\index{Abbildungseigenschaft!universelle (UAE)}
Seien $V,W$ $K$-VRme. Eine $K$-VRm $T$ mit einer bilinearen Abbildung $\tau:V\times W\to T$
hei√üt ein \textbf{Tensorprodukt} von $V$ und $W$, falls $\tau$ die folgende 
\textbf{universelle Abbildungseigenschaft} (UAE) erf√ºllt:\\
Zu jedem $K$-VRm $U$ und jeder bilinearen Abbildung $\beta:V\times W\to U$ existiert
genau eine lineare Abbildung $\Phi_\beta:T\to U$ derart, dass $\beta=\Phi_\beta\circ \tau$.\\
Schreibe: $T=:V\otimes_K W,\tau(v,w)=:v\otimes w$
\end{definition}

\begin{comment}
\begin{enumerate}
\item Falls $T$ existiert, so hat man eine Bijektion:
\[\Bil(V\times W,U)\stackrel{\sim}{\to}\Hom(T,U),\beta\mapsto\Phi_\beta\]
\item Sind $(T_1,\tau_1),(T_2,\tau_2)$ Tensorprodukte von $V$ und $W$, so existiert genau 
ein Isomorphismus $\Phi:T_1\to T_2$ mit $\tau_2=\Phi\circ\tau_1$.
\end{enumerate}
\end{comment}

\begin{task}
Beweise die Existenz von Tensorprodukten.
\end{task}

\begin{example}
\begin{enumerate}
\item Sei $V:=K^{n\times 1},W:=K^{m\times 1}, T:=K^{n\times m}$ und die bilineare
Abbildung:
\[\tau:K^n\times K^m\to T,(v,w)\mapsto v\cdot w^T\]
F√ºr die Standardbasen $\{e_i\}\subseteq V,\{e'_j\}\subseteq W$ ist $\tau(e_i,e'_j)=E_{ij}$
die Elementarmatrix. $D:=\{E_{ij}\mid i\in\{1,\ldots,n\},j\in\{1,\ldots,m\}\}$ ist
Basis von $T$.\\
Im folgenden wollen wir die UAE nachweisen. Sei dazu $\beta:V\times W\to U$ bilinear.
Dann erhalten wir eine lineare Abbildung $\Phi:K^{n\times m}\to U$ f√ºr jede Vorgabe einer
Abbildung $D\to U$ (vgl. lineare Fortsetzung). Insbesondere also auch f√ºr die Vorgabe:
\[\forall i\in\{1,\ldots,n\},j\in\{1,\ldots,m\}:\Phi(E_{ij}):=\beta(e_i,e'_j)\]
Damit gilt dann:
\begin{align*}
\beta(v,w)&=\beta\left(\sum_{i=1}^n \alpha_i e_i,\sum_{j=1}^m \gamma_j e'_j\right)\\
&=\sum_{i,j}\alpha_i\gamma_j\cdot\beta(e_i,e'_j)\\
&=\sum_{i,j}\alpha_i\gamma_j\cdot\Phi(E_{ij})\\
&=\Phi\left(\sum_{ij}\alpha_i\gamma_j\cdot E_{ij}\right)\\
&=\Phi\left(\tau\left(\sum_{i=1}^n\alpha_i e_i,\sum_{j=1}^m \gamma_j e'_j\right)\right)\\
&=\Phi(\tau(v,w))=(\Phi\circ\tau)(v,w)
\end{align*}
Wir haben also gezeigt, dass $\beta=\Phi\circ\tau$ gilt.\\
Falls f√ºr ein $\Phi':T\to U$ auch $\beta=\Phi'\circ\tau$ gilt, folgt insbesondere
$\beta(e_i,e'_j)=\Phi'(\tau(e_i,e'_j))$ und damit:
\[\Phi'(E_{ij}=\beta(e_i,e'_j)=\Phi(\tau(e_i,e'_j))=\Phi(E_{ij)}\]
D.h. $\Phi|_D=\Phi'|_D$, also ist $\Phi=\Phi'$ eindeutig.
\item Seien $V,W$ beliebige VRme mit endlichen Dimensionen $\dim V=n,\dim W=m$.\\
Die Existenz des Tensorproduktes folgt etwa durch Koordinatenisomorphismen und
Beispiel (1) F√ºr eine \textbf{koordinatenfreie Konstruktion} nehme $T:=\Hom(V^*,W)$ und
\[\tau:V\times W\to T,(v,w)\mapsto(V^*\to W,f\mapsto f(v)\cdot w)\]
Leichte √úbung: $(T,\tau)$ ist Tensorprodukt von $V,W$ und f√ºr Basen $B,C$ von $V,W$ gilt:
\[D:=\{b\otimes c\in T\mid b\in B,c\in C\}\]
ist Basis von $T=V\otimes_K W$.
\end{enumerate}
\end{example}

\begin{theo}
Sind $V,W$ beliebige $K$-VRme, so existiert ein Tensorprodukt von $V$ und $W$.
\end{theo}

\begin{proof}
Finde einen \(K\)-Vektorraum \(T\) und eine lineare Abbildung 
\(\tau:\,V\times W\to T\) mit der universellen Abbildungseigenschaft. Dazu 
benutze den \(K\)-Vektorraum\break\(F:=\Abb(V\times W,K)_{0}\).\\
Sei \(f:\,V\times W\to K\) eine Abbildung mit endlichem Tr\"ager\break 
\(\Supp(f):=\{(v,w)\mid f(v,w)\neq0\}\).\\
\(B:=\{f_{(v,w)}\mid(v,w)\in V\times W\}\) ist eine Basis von \(F\) (da f\"ur 
beliebiges \(f\in F\) gilt: \(f(x,y)=\sum_{(v,w)\in\Supp(f)}{f(v,w)\cdot f_{(v,w)}}\)).\\
Setze \(\vp:\,V\times W\to F,\,(v,w)\mapsto f_{(v,w)}\). Vorsicht: \(\vp\) ist
nicht bilinear!

F\"ur die Bilinearit\"at ben\"otigen wir den Untervektorraum \(R\leq F\), 
erzeugt von den ``fehlenden Relationen''.
%split?
\[
f_{(\alpha v_{1}+v_{2},\beta w_{1}+w_{2})}-\alpha\beta f_{(v_{1},w_{1})}-
    \beta f_{(v_{2},w_{1})}-\alpha f_{(v_{1},w_{2})}-f_{(v_{2},w_{2})}\,
    \forall\alpha,\beta\in K,v_{i}\in V,w_{i}\in W
\]
\index{Abbildung!kanonische}
Bilde den Faktorraum \(T:=\frac{F}{R}\) versehen mit der kanonischen Abbildung
\[
\pi:\,F\to T,\,f\mapsto f+R=:[f]
\]
Betrachte
\[
\tau:\,V\times W\to T,\,(v,w)\mapsto\pi\left(\vp(v,w)\right)=[f_{(v,w)}]
\]
Nun gilt offenbar Bilinearit\"at:
\begin{align*}
\left[f_{(\alpha v_{1}+v_{2},\beta w_{1}+w_{2})}\right]&=
    \alpha\beta\left[f_{(v_{1},w_{1})}\right]+
    \beta\left[f_{v_{2},w_{1})}\right]+
    \alpha\left[f_{(v_{1},w_{2})}\right]+
    \left[f_{(v_{2},w_{2})}\right]\\
\tau(\alpha v_{1}+v_{2},\beta w_{1}+w_{2})&=\alpha\beta\tau(v_{1},w_{1})+
    \beta\tau(v_{2},w_{1})+\alpha\tau(v_{1},w_{2})+\tau(v_{2},w_{2})
\end{align*}
\paragraph{Nachweis der universellen Abbildungseigenschaft:}{Sei wieder 
\(\beta:\,V\times W\to U\) bilinear gegeben. Da 
\(F=\langle B\rangle=\langle\Bil(\vp)\rangle\) und \(\pi\) surjektiv sind,
folgt \(T=\langle\Bil(\tau)\rangle\).\\
Jede lineare Abbildung \(\phi:\,T\to U\) ist eindeutig bestimmt durch 
\(\left.\phi\right|_{\Bil(\tau)}\), also ist durch die Forderung 
\(\beta=\phi\circ\tau\) \(\phi\) eindeutig bestimmt (falls existent).}
\paragraph{Existenz von \(\phi\):}{Zun\"achst definiere die lineare Abbildung
\[
\phi_{F}:\,F\to U
\]
durch Vorgabe auf der Basis \(B\).
\[
\phi_{F}\left(f_{(v,w)}\right):=\beta(v,w)
\]
Da \(\beta\) bilinear ist, folgt
\[
\phi_{F}\left(f_{(\alpha v_{1}+v_{2},\beta w_{1}+w_{2})}-
    \alpha\beta f_{(v_{1},w_{1})}-\beta f_{(v_{2},w_{1})}-
    \alpha f_{(v_{1},w_{2})}-f_{(v_{2},w_{2})}\right)
=0
\]
also \(R\leq\Kern\phi_{F}\).\\
Mit dem Homomorphiesatz folgt: Es existiert eine lineare Abbildung 
\(\phi:\frac{F}{R}=T\to U\) mit 
\[
\phi([f])=\phi_{F}(f)
\]
und
\[
\phi\left(\tau(v,w)\right)=\phi\left([\vp(v,w)]\right)
    =\phi_{F}\left(f_{(v,w)}\right)=\beta(v,w)
\]
}
\end{proof}

\begin{application}
Das Tensorprodukt wird zur Erweiterung des Skalarbereiches eines VRms genutzt.
Sei $V$ $K$-VRm, $L$ ein K√∂rper mit Teilk√∂rper $K\le L$. Insbesondere ist also
$L$ ein $K$-VRm (vgl. fr√ºher). Nach Satz 5 existiert das Tensorprodukt 
$L\otimes_K V=:V_L$ ($K$-VRm).\\
Im Folgenden wollen wir zeigen, dass $V_L$ ein $L$-Vektorraum ist. Dazu fehlt
die Skalarmultiplikation $L\times V_L\to V_L$, die wir mittels der UAE definieren.
F√ºr alle $l\in L$ ist:
\[\beta_l:L\times V\to V_L,(x,v)\mapsto lx\otimes v\]
bilinear, sodass $\beta_l(x,v)=\Phi_{\beta_l}(x\otimes v)$.\\
Nehme nun $\Phi_{\beta_l}$ als Skalarmultiplikation mit $l\in L$:
\[L\times V_L\to V_L,(l,u)\mapsto \Phi_{\beta_l}(u)\]
Leichte √úbung: Dies erf√ºllt die Axiome f√ºr eine Skalarverkn√ºpfung.
\end{application}

\begin{comment}
$V_L$ enth√§lt $V$ als $K$-Untervektorraum √ºber die Einbettung:
\[V\to V_L,v\mapsto 1\otimes v\]
F√ºr eine Basis $B$ von $V$ ist das Bild $\{1\otimes b\mid b\in B\}\subseteq V_L$
eine Basis des $L$-VRms $V_L$. Insbesondere ist
\[L\otimes_K K^n\stackrel{\sim}{=}L^n\]
eine Isomorphie von $L$-VRmen.
\end{comment}

\chapter{Metriken, Normen und Skalarprodukte}
\begin{definition}
\index{Metrik}
\index{Abstand}
\index{positivdefinit}
\index{Dreiecksungleichung}
Metriken abstrahieren Abst√§nde. Sei $X$ eine beliebige Menge. Eine Abbildung
$d:X\times X\to \mathbb{R}$ hei√üt eine \textbf{Metrik} oder ein \textbf{Abstand}
auf $X$, falls gilt:
\begin{enumerate}
\item $d$ ist \textbf{smmetrisch}, d.h. f√ºr alle $x,y\in X$ gilt:
\[d(x,y)=d(y,x)\]
\item $d$ ist \textbf{positivdefintit}, d.h. f√ºr alle $x,y\in X$ gilt:
\[d(x,y)\ge 0 \text{ und } (d(x,y)=0)\implies (x=y)\]
\item F√ºr alle $x,y,z\in X$ gilt die \textbf{Dreicksungleichung}:
\[d(x,y)+d(y,z)\ge d(x,z)\]
\end{enumerate}
\end{definition}

\begin{example}
\index{diskret!Metrik}\index{Metrik!diskrete}
\begin{enumerate}
\item Die \textbf{diskrete Metrik} $d_0$ auf $X$:
\[d_0(x,y)=\begin{cases}
1&,(x\ne y)\\
0&,(x=y)
\end{cases}
\]
\item $X=\mathbb{C}$ oder $\mathbb{R}$ oder $\mathbb{Q}$ mit Betrag $|\cdot|$ hat die
Metrik:
\[d(x,y)=|x-y|\]
\end{enumerate}
Auf Vektorr√§umen √ºber $K=\mathbb{R}$ entstehen nat√ºrliche Metriken aus sogenannten Normen.\\
Im Folgenden schreibe $\mathbb{K}$ f√ºr $\mathbb{R}$ oder $\mathbb{C}$.
\end{example}

\begin{definition}
\index{Norm}
\index{normiert!Raum}\index{Raum!normierter}
\index{Positivdefinitheit}
\index{Homogenit√§t}
\index{Dreiecksungleichung}
Sei $V$ ein $\mathbb{K}$-VRm. Eine Abbildung:
\[\|\cdot\|:V\to\mathbb{R},x\mapsto \|x\|\]
hei√üt eine \textbf{Norm}, falls f√ºr $x,y\in V,\alpha\in\mathbb{K}$ gilt:
\begin{enumerate}
\item Die Abbildung ist \textbf{positivdefinit}, d.h.:
\[\|x\|\ge 0 \wedge (\|x\|=0\iff x=0)\]
\item Die Abbildung ist \textbf{homogen}, d.h.:
\[\|\alpha x\| = |\alpha|\cdot \|x\|\]
\item Es gilt die \textbf{Dreiecksungleichung}:
\[\|x+y\|\le\|x\|+\|y\|\]
\end{enumerate}
Ist dies erf√ºllt, so ist $(V,\|\cdot\|)$ ein \textbf{normierter Raum}.
\end{definition}

\begin{example}
\begin{enumerate}
\item Der Raum $V=\mathbb{K}$ mit $x=(x_1,\ldots,x_n)$ und den Normen:
\begin{align*}
&\text{(a) }\|x\|_2:=\sqrt{\sum_{i=1}^n |x_i|^2}\\
&\text{(b) }\|x\|_{\max}:= \max_{i=1,\ldots,n}|x_i|\\
&\text{(c) }\|x\|_1:=\sum_{i=1}^n |x_i|
\end{align*}
\item Der Raum der beschr√§nkten Abbildungen $V=\Abb(M,\mathbb{K})$ mit einer 
beliebigen Menge $M$ und der Norm:
\[\|f\|_\infty := \sup_{m\in M}|f(m)|\]
\item Der Raum $V=C[a,b]$ der stetigen Abbildungen nach $\mathbb{K}$ mit der Norm:
\[\|f_1\|:=\int_a^b |f(t)|\text{ d}t\]
\end{enumerate}
\end{example}

\begin{comment}
\begin{enumerate}
\item Jeder normierte Raum $(V,\|\cdot\|)$ besitzt die Metrik:
\[d(x,y):=\|x-y\|\]
\item In der Linearen Algebra tauchen haupts√§chlich Normen auf, die mit
\textbf{Skalarprodukten} definiert werden.
\end{enumerate}
\end{comment}

\begin{definition}
\renewcommand{\labelenumi}{(\alph{enumi})}
\index{Sesqilinearform}
\index{Schiefsymmetrie}
\index{hermitesch!Form}\index{Form!hermitesche}
\index{symmetrisch!Bilinearform}\index{Bilinearform!symmetrische}
\index{Skalarprodukt}
Sei $V$ ein $\mathbb{K}$-VRm. F√ºr $\alpha\in\mathbb{K}$ sei $\overline\alpha$
die komplexe Konjugierte.
\begin{enumerate}
\item Eine Abbildung $s:V\times V\to\mathbb{K}$ hei√üt \textbf{Sesquilinearform}
("`sesqui"' bedeutet $1\frac12$), falls
\[s(\alpha x+y,z)=\alpha \cdot s(x,z)+s(y,z)\]
gilt, also $s(\cdot,z)$ linear ist und au√üerdem noch gilt:
\[s(x,\alpha y+z)=\overline\alpha \cdot s(x,y)+s(x,z)\]
\item Ist $s$ \textbf{schiefsymmetrisch}, d.h. es gilt:
\[s(y,x)=s(\overline{x,y})\]
so hei√üt es \textbf{hermitesche Form} ($\mathbb{K}=\mathbb{C}$) bzw.
\textbf{symmetrische Bilinearform} ($\mathbb{K}=\mathbb{R}$).
\item Eine schiefsymmetrische Sesquilinearform hei√üt \textbf{Skalarprodukt} auf $V$,
falls $s$ positivdefinit ist.
\end{enumerate}
\renewcommand{\labelenumi}{(\arabic{enumi})}
\end{definition}

\begin{comment}
\index{Darstellungsmatrix}
Ist $\dim V=n<\infty$ mit einer Basis $B=\{b_1,\ldots,b_n\}$, so ist eine
Sesquilinearform $s$ bestimmt durch die Werte $s(b_i,b_j)\in\mathbb{K}$, also
durch die \textbf{Darstellungsmatrix}
\[D_{BB}(s):=(s(b_i,bj))\in\mathbb{K}^{n\times n}\]
Jede beliebige Matrix $D=(d_{ij})\in\mathbb{K}^{n\times n}$ definiert ein
$s:=s_B^D$ mit:
\[s(\sum_{i=1}^n \alpha_i b_i,\sum_{j=1}^n \beta_j b_j)=\sum_{i=1}^n\sum_{j=1}^n \alpha_i\overline{\beta_j}\cdot d_{ij}\]
\end{comment}

\begin{definition}
\index{hermitesch}
\index{Positivdefinitheit}
$D$ hei√üt \textbf{hermitesch} (bzw. \textbf{positivdefinit}), wenn das zugeh√∂rige $s$
diese Eigenschaft hat.\\
Also gilt etwa:
\begin{align*}
&A=(a_{ij}) \text{ hermitesch}\\
\iff &\forall i,j=1,\ldots,n:a_{ij}=\overline{a_{ji}}\\
\iff &A=\overline{A}^T
\end{align*}
\end{definition}

\begin{example}
\index{Standardskalarproduk}
Das \textbf{Standardskalarprodukt} auf $V=\mathbb{K}^n$
\[D=I \implies s(\begin{pmatrix}\alpha_1\\\vdots\\\alpha_n \end{pmatrix},
\begin{pmatrix}\beta_1\\\vdots\\\beta_n \end{pmatrix})=\sum_{i=1}^n \alpha_i\overline{\beta_i}\]
ist hermitesch und positivdefinit.
\end{example}

\begin{theo}[Chauchy-Schwarzsche Ungleichung]
\index{Chauchy-Schwarzsche Ungleichung}
Ist $V$ VRm mit Skalarprodukt $\langle\cdot,\cdot\rangle$, so gilt f√ºr alle $x,y\in V$:
\[|\langle x,y\rangle|^2 \le \langle x,x\rangle \cdot \langle y,y\rangle\]
\end{theo}

\begin{proof}
Es gilt f√ºr alle $\alpha,\beta\in\mathbb{R}$:
\begin{align*}
0&\le \langle\alpha x+\beta y,\alpha x+\beta y\rangle\\
&=\alpha\langle x,\alpha x+\beta y\rangle+\beta\langle y,\alpha x+\beta y\rangle\\
&= \alpha^2\langle x,x\rangle +\alpha\beta(\langle x,y\rangle+\langle y,x\rangle)+
\beta^2\langle y,y\rangle
\end{align*}
Sei nun:
\begin{align*}
&F:=\langle x,x\rangle& &2G:=\langle x,y\rangle+\langle y,x\rangle& &H:=\langle y,y\rangle
\end{align*}
\textbf{Annahme:} $G^2>FH$\\
Dann hat $P(X):=FX^2+2GX+H\in\mathbb{R}[X]$ zwei verschiedene Nullstellen und es
existiert ein $\xi\in\mathbb{R}:P(\xi)<0$. Dies stellt einen Widerspruch zu obiger √úberlegung da
(mit $\alpha=\xi$ und $\beta=1$). Also gilt:
\[G^2\le FH\]
\textbf{Fall 1:} $\langle x,y\rangle \in\mathbb{R}$\\
Dann gilt $G=\langle x,y\rangle=\langle y,x\rangle$ und mit $G^2\le FH$ folgt
die Cauchy-Schwarzsche Ungleichung.\\
\textbf{Fall 2:} $\langle x,y\rangle \notin\mathbb{R}$\\
Ersetze $y$ durch $\zeta	 y$ mit $\zeta\in\mathbb{C}^\times,|\zeta|=1$.
W√§hle $\zeta:=\frac{\langle x,y\rangle}{|\langle x,y\rangle|}$. Dann gilt:
\begin{align*}
\langle x,\zeta y\rangle &= \overline{\zeta}\langle x,y\rangle\\
&=\frac{\langle\overline{x,y}\rangle}{|\langle x,y \rangle |}\cdot \langle  x,y\rangle\\
&=\frac{|\langle x,y \rangle |^2}{|\langle x,y \rangle |}\\
&=|\langle x,y \rangle |\in\mathbb{R}
\end{align*}
Nach Fall 1 folgt daraus:
\begin{align*}
|\langle x,y \rangle |^2&=|\langle x,\zeta y \rangle |^2\\
&\le \langle x,x\rangle\cdot\langle\zeta y,\zeta y\rangle\\
&=\langle x,x\rangle\cdot \zeta\overline\zeta\cdot\langle y,y\rangle\\
&=\langle x,x\rangle\cdot \langle y,y\rangle
\end{align*}
\end{proof}

\begin{comment}
Im Spezialfall $V=\mathbb{K}^n$ mit dem Standardskalarprodukt $\langle\cdot,\cdot\rangle$
gilt nach der Cauchy-Schwarzschen Ungleichung:
\[|\sum_{i=1}^n \xi_i\cdot\overline{\eta_i}|^2\le (\sum_{i=1}^n |\xi_i|^2)(\sum_{j=1}^n |\eta_j|^2)\]
\end{comment}

\begin{theo}
Jeder VRm $V$ mit einem Skalarprodukt ist normiert durch die Norm:
\[\|x\|:=\sqrt{\langle x,x\rangle}\]
\end{theo}

\begin{proof}
\begin{enumerate}
\item Es ist klar, das $\|x\|\in\mathbb{R}$ und $\|x\|\ge 0$ ist. Au√üerdem gilt:
\begin{align*}
\|x\|=0 &\implies \langle x,x\rangle =0\\
&\implies x=0
\end{align*}
\item  Es gilt:
\begin{align*}
&\langle x,y\rangle +\langle y,x\rangle\le 2\|x\|\cdot\|y\|\\
\iff &\langle x,x\rangle\langle x,y\rangle +\langle y,x\rangle\langle y,y\rangle
\le \langle x,x\rangle 2\|x\|\cdot\|y\|+\langle y,y\rangle\\
\iff &\langle x+y,x+y\rangle \le (\|x\|+\|y\|)^2\\
\iff &\|x+y\|\le \|x\|+\|y\|
\end{align*}
\item Es gilt:
\[\|\alpha x\|^2=\langle \alpha x,\alpha x\rangle = \alpha\overline\alpha
\langle x,x\rangle = |\alpha|^2\cdot\|x\|^2\]
\end{enumerate}
\end{proof}

\begin{comment}
\index{Parallelogrammgleichung}
\begin{enumerate}
\item Mit Hilfe der Norm lautet die Cauchy-Schwarzsche Ungleichung:
\[|\langle x,y\rangle|\le \|x\|\cdot\|y\|\]
\item Damit eine Norm von einem Skalarprodukt stammt, ist offenbar notwendig,
dass sie die \textbf{Parallelogrammgleichung} erf√ºllt:
\[\forall x,y\in V: \|x+y\|^2+\|x-y\|^2=2(\|x\|^2+\|y\|^2)\]
Denn falls die Norm $\|\cdot\|$ von einem Skalarprodukt $\langle\cdot,\cdot\rangle$
kommt, gilt:
\begin{align*}
\|x+y\|^2+\|x-y\|^2 &= \langle x+y,x+y\rangle +\langle x-y,x-y\rangle\\
&= \|x\|^2+\langle x,y\rangle +\langle y,x\rangle+\|y\|^2 + 
\|x\|^2-\langle x,y\rangle -\langle y,x\rangle+\|y\|^2\\
&= 2(\|x\|^2+\|y\|^2)
\end{align*}
Tats√§chlich kommt eine Norm genau dann von einem Skalarprodukt, wenn sie die
Parallelogrammgleichung erf√ºllt. Dies wird jedoch ohne Beweis angegeben.
\end{enumerate}
\end{comment}

\chapter{Orthogonalsysteme}
\index{Orthogonalsysteme}
\section{Winkel und Orthogonalit\"at}
\index{Winkel}\index{orthognal}
\begin{prerem}
Sei \(V\) ein Vektorraum mit Skalaprodukt \(\SKP\) und zugeh\"origer Norm 
\(\lVert\cdot\rVert\), dann gilt nach Cauchy-Schwarz:
\[
\forall x,y\in V\setminus\{0\}:\quad\frac{\lvert\langle x,y\rangle\rvert}{\lVert x\rVert\cdot\lVert y\rVert}\leq 1
\]
\end{prerem}
\begin{definition}
\begin{enumerate}
\item Sei \(\mathbb{K}=\mathbb{R}\). F\"ur \(x,y\in V\setminus\{0\}\) sei 
\(\phi=\angle(x,y)\in[0,\pi]\) diejenige (eindeutig bestimmte) Zahl mit
\[
\cos\phi=\frac{\lvert\langle x,y\rangle\rvert}{\lVert x\rVert\cdot\lVert y\rVert}
\]
\(\phi\) hei\ss t der \textbf{Winkel} zwischen \(x\) und \(y\).
\item \(x,y\) hei\ss en \textbf{orthogonal} oder senkrecht zueinander, falls
\(\langle x,y\rangle=0\) gilt.\\
Schreibe: \(x\bot y\).
\item Teilmengen \(M,N\subseteq V\) hei\ss en orthogonal, falls gilt:
\[
\forall x\in M\forall y\in N:\quad x\bot y
\]
Schreibe: \(M\bot N\).
\item Eine Teilmenge \(B\subseteq V\) hei\ss t \textbf{Orthogonalsystem} (OGS),
falls f\"ur \(x,y\in B\) gilt: 
\[
x\neq y\implies x\bot y
\]
\item Ein Orthogonalsystem \(B\) hei\ss t \textbf{Orthonormalsystem} (ONS) wenn
gilt:
\[
\forall x\in B:\quad\lVert x\rVert=1
\]
\item Eine Basis \(B\) von \(V\) hei\ss t \textbf{Orthogonalbasis} (OGB), bzw.
\textbf{Orthonormalbasis} (ONB), falls \(B\) ein Orthogonalsystem, bzw.
Orthonormalsystem, ist.
\end{enumerate}
\end{definition}
\begin{example}
\begin{enumerate}
\item Sei \(V=\mathbb{K}^{n}\) mit Standardskalarprodukt \(\SKP\) und 
\(S:=\{e_{1},\ldots,e_{n}\}\) Standardbasis.\\
Dann ist \(S\) eine Orthonormalbasis und jede Teilmenge \(T\subseteq S\) ist
ein Orthonormalsystem.
\item Sei \(I:=[a,b]\) ein Intervall.\\
Sei 
\(V:=\{p\in\Abb(I,\mathbb{C})\mid\exists P\in\mathbb{C}[T]:\,p(t)=P(t)\}\).\\
\(w:I\to\mathbb{R}_{\geq0}\) sei stetig und mit der Eigenschaft \(w(t)=0\) nur
f\"ur endlich viele \(t\in I\).

Wir erhalten ein Skalarprodukt auf \(V\):
\[
\langle p,q\rangle_{w}:=\int\limits_{I}{w(t)p(t)\overline{q(t)}\mathrm{d}t}
\]
Eine Basis von \(V\) ist \(\{p_{n}(t)=:t^{n}\mid n\in\mathbb{N}_{0}\}\).

Gesucht ist eine Orthonormalbasis und ein Verfahren zu ihrer Bestimmung.
\end{enumerate}
\end{example}
\begin{comment}
Jedes Orthogonalsystem \(B\) mit \(0\not\in B\) ist linear unabh\"angig.
\end{comment}
\begin{proof}
Es ist
\[
\sum_{b\in B}{\alpha_{b}\cdot b}=0
\]
Dann gilt f\"ur alle \(c\in B\):
\begin{align*}
0&=\langle 0,c\rangle\\
&=\left\langle\sum_{b}{\alpha_{b}b},c\right\rangle\\
&=\sum_{b}{\alpha_{b}\langle b,c\rangle}\\
&\overset{b=0\forall b\neq c}{=}\alpha_{c}\underbrace{\langle c,c\rangle}_{\neq c}\\
&\implies\,\alpha_{c}=0
\end{align*}
\end{proof}

\section{Das E. Schmidtsche Orthogonalisierungsverfahren}
\index{E. Schmidt!Orthogonalisierungsverfahren}\index{Gram-Schmidt}
\begin{theo}
Sei \(V\) ein Vektorraum mit Skalarprodukt \(\SKP\) und sei 
\(M:=\{x_{0},x_{1},\ldots\}\) eine abz\"ahlbare Teilmenge von \(V\).
\begin{enumerate}
\item Es existiert ein Orthogonalsystem \(\{y_{0},y_{1},\ldots\}\) derart, 
da\ss \ gilt:
\begin{equation}
\label{eq: Gram-Schmidt; lineare Huelle}
\forall n:\quad\langle y_{0},y_{1},\ldots,y_{n}\rangle=\langle x_{0},\ldots,x_{n}\rangle\quad\text{(gleiche lineare H\"ulle)}
\end{equation}
\item Falls \(M\) linear unabh\"angig ist, so sind alle \(y_{i}\neq0\) und
\(B:=\{z_{0},z_{1},\ldots\}\) mit
\[
z_{i}:=\frac{1}{\lVert y_{i}\rVert}y_{i}
\]
ist ein Orthonormalsystem mit 
\[
\forall n:\quad\langle z_{0},z_{1},\ldots,z_{n}\rangle=\langle x_{0},x_{1},\ldots,x_{n}\rangle
\]
\end{enumerate}
\end{theo}
\begin{proof}
\begin{enumerate}
\item Wir beschreiben einen Algorithmus zum Auffinden der \(y_{n}\).\\
Start: \(y_{0}:=x_{0}\). Angenommen: alle \(y_{m}\) f\"ur \(m<n\) sind bereits
gefunden. Setze
\[
y_{n}:=x_{n}-\sum_{i=0}^{n-1}{\frac{\langle x_{n},y_{i}\rangle}{\langle y_{i},y_{i}\rangle}}y_{i}
\]
(nur \"uber \(i\) mit \(y_{i}\neq0\) summieren).\\
Damit folgt:
\begin{align*}
y_{n}&\in\langle\underbrace{y_{0},y_{1},\ldots,y_{n-1}}_{=\langle x_{0},\ldots,x_{n-1}\rangle},x_{n}\rangle=\langle x_{0},\ldots,x_{n}\rangle\\
x_{n}&\in\langle y_{0},y_{1},\ldots,y_{n}\rangle
\end{align*}
Daraus folgt \eqref{eq: Gram-Schmidt; lineare Huelle}.

Rest: F\"ur alle \(m<n:\,y_{n}\bot y_{m}\). Damit:
\begin{align*}
\langle y_{n},y_{m}\rangle&=\langle x_{n},y_{m}\rangle-\sum_{i=0}^{n-1}{\frac{\langle x_{n},y_{i}\rangle}{\langle y_{i},y_{i}\rangle}}\langle y_{i},y_{m}\rangle\\
&=\langle x_{n},y_{m}\rangle-\sum_{i=0}^{n-1}{\frac{\langle x_{n},y_{i}\rangle}{\langle y_{i},y_{i}\rangle}}\delta_{im}\langle y_{i},y_{i}\rangle\\
&=\langle x_{n},y_{m}\rangle-\langle x_{n},y_{m}\rangle\\
&=0
\end{align*}
\item \checkmark \ Leicht selbst zu verifizieren.
\end{enumerate}
\end{proof}
\begin{example}
Sei \(V=\mathbb{R}^{3}\) mit dem Standardskalarprodukt, 
\(M:=\left\{
\begin{pmatrix}1\\0\\1\end{pmatrix},
\begin{pmatrix}1\\1\\0\end{pmatrix},
\begin{pmatrix}0\\1\\1\end{pmatrix}
\right\}\).
Dann:
\begin{align*}
y_{0}&=x_{0},\quad\lVert y_{0}\rVert=\sqrt{2}\\
y_{1}&=x_{1}-\frac{\langle x_{1},y_{0}\rangle}{\langle y_{0},y_{0}\rangle}y_{0}
    =\begin{pmatrix}1\\1\\0\end{pmatrix}-\frac{1}{2}\begin{pmatrix}1\\0\\1\end{pmatrix}
    =\frac{1}{2}\begin{pmatrix}1\\2\\-1\end{pmatrix},
    \quad\lVert y_{1}\rVert=\sqrt{\frac{3}{2}}\\
y_{2}&=x_{2}-\frac{\langle x_{2},y_{0}\rangle}{\langle y_{0},y_{0}\rangle}y_{0}-
    \frac{\langle x_{2},y_{1}\rangle}{y_{1},y_{1}\rangle}y_{1}
    =\frac{2}{3}\begin{pmatrix}-1\\1\\1\end{pmatrix}
\end{align*}
\end{example}

Auswirkungen (des Orthogonalisierungsverfahrens) auf Matrizen:\\
Sei \(V\cong\mathbb{K}^{n}\) mit Standardskalarprodukt \(s\) und Basis
\(B:=\{b_{1},\ldots,b_{n}\}\).
Das Orthogonalisierungsverfahren liefert eine Orthogonalbasis 
\(C=\{c_{1},\ldots,c_{n}\}\).
\begin{align*}
c_{\nu}&=b_{\nu}-\sum_{i=1}^{n-1}{\frac{\SKP}{\SKP}\cdot c_{i}}=\ldots
    =\sum_{i=1}^{\nu}{\alpha_{i\nu}b_{i}}
    \longrightarrow A=M_{BC}=\left(\alpha_{i\nu}\right)=
    \begin{pmatrix}1&&*\\&\ddots&\\0&&1\end{pmatrix}\\
\frac{c_{\nu}}{\lVert c_{\nu}\rVert}
    &=\sum_{i=1}^{\nu}{\frac{\alpha_{i\nu}}{\lVert c_{i}\rVert}b_{i}}=z_{\nu}
    \longrightarrow M_{BZ}=
	\begin{pmatrix}*&&*\\&\ddots&\\0&&*\end{pmatrix}
\end{align*}
\begin{remind}[Darstellungsmatrix]
\[
D_{BB}(s)=\left(s\left(b_{\nu},b_{\mu}\right)\right)\in\mathbb{K}^{n}\\
\]
Da \(C\) eine Orthogonalbasis ist, folgt
\(s\left(c_{\nu},c_{\mu}\right)=\delta_{\nu\mu}\lVert c_{\nu}\rVert^{2}\), also
\[
D_{CC}(s)=\diag\left(\ldots,\lVert c_{\nu}\rVert^{2},\ldots\right)
\]
Falls \(Z\) eine Orthonormalbasis ist, so folgt \(D_{ZZ}(s)=I\).

Generell f\"ur beliebige Basen \(B,C\) und \(A=M_{BC}\):
\begin{align*}
D_{CC}(s)&=\left(s\left(c_{\nu},c_{\mu}\right)\right)\\
&=\left(s\left(\sum_{i=1}^{n}{\alpha_{i\nu}},\sum_{j}{\alpha_{j\mu}b_{j}}\right)\right)\\
&=\left(\sum_{i}{\sum_{j}{\alpha_{i\nu}\overline{\alpha_{i\mu}}\cdot s(b_{i},b_{j})}}\right)\\
&=A^{\top}\left(s(b_{i},b_{j})\right)\overline{A}
\end{align*}
\end{remind}
\begin{definition}
F\"ur beliebige \(D\in\mathbb{K}^{n\times n}\) setze \(D^{*}:=\overline{D}^{\top}\) (die sogenannte \textbf{Adjungierte}).
\[
D_{CC}(s)=A^{\top}D_{BB}(s)\overline{A}
\]
Speziell f\"ur jede Orthonormalbasis \(C\):
\[
D_{CC}(s)=I,
\]
das folgt wegen \(M_{BC}^{-1}=M_{CB}\).\\
Es ist 
\[
D_{BB}(s)=D^{*}D
\]
f\"ur \(D:=\overline{M}_{CB}\), wobei \(D\) obere Dreiecksmatrix ist.
\end{definition}
\begin{theo}
F\"ur \(P\in\mathbb{K}^{n\times n}\) ist \"aquivalent:
\begin{enumerate}
\item \(P\) ist hermitesch (symmetrisch) und positiv definit
\item Es gibt ein \(A\in\GL_{n}(\mathbb{K})\) mit \(P=A^{*}A\).
\end{enumerate}
\end{theo}
\begin{proof}
\begin{enumerate}
\item \(\implies\,(2)\):\\
Sei \(V=\mathbb{K}^{n},\,B=\{e_{1},\ldots,e_{n}\}\) die Standardbasis.\\
\(P\) definiert ein Skalarprodukt:
\begin{align*}
s(x,y)&=(\overline{\eta}_{1},\ldots,\overline{\eta}_{n})\cdot P\cdot
    \begin{pmatrix}\xi_{1}\\\vdots\\\xi_{n}\end{pmatrix}\\
P&=\left(s(e_{i},e_{j})\right)=D_{BB}(s)
\end{align*}
% Okay, das hier ist leicht seltsam -- mein Aufschrieb ist an der Stelle etwas
% wirr und unverstaendlich... Fuer einen Hinweis bin ich dankbar ;-) P.
Das Schmidtsche Orthogonalisierungsverfahren liefert eine Orthonormalbasis und
damit \(P=D^{*}D\).
\item\(\implies\,(1)\):\\
\(P=A^{*}A\) ist hermitesch; zu zeigen: \(P^{*}=P\)
\begin{align*}
P^{*}&=\left(A^{*}\cdot A\right)^{*}\\
&=\overline{\left(A^{*}\cdot A\right)}^{\top}\\
&=\overline{\left(\overline{A}^{\top}\cdot A\right)}^{\top}\\
&=\left(A^{\top}\cdot\overline{A}\right)^{\top}\\
&=\overline{A}^{\top}\cdot A\\
&=A^{*}A\\
&=P
\end{align*}
Daraus folgt: \(s(x,y)\) ist hermitesche Form. F\"ur alle \(x\in\mathbb{K}^{n}\)
gilt:
\begin{align*}
s(x,x)&=\overline{x}^{\top}\cdot P\cdot x\\
&=\overline{x}^{\top}\left(\overline{A}^{\top}\cdot A\right)x\\
&=\left(\overline{A}\overline{x}\right)^{\top}Ax\\
&=s_{0}(Ax,Ax)\\
&\geq0
\end{align*}
Weiterhin:
\begin{align*}
&s_{0}(Ax,Ax)=0\\
\Longleftrightarrow&Ax=0\\
\overset{A\text{ inv.}}{\Longleftrightarrow}&x=0\\
\implies&s\text{ positiv definit}
\end{align*}
\end{enumerate}
\end{proof}

Falls speziell \(B\) und \(C\) Orthonormalbasen sind, folgt:
\[
D_{BB}(s)=I=D_{CC}(s)
\]
und \(D:=\overline{M}_{CB}\).
\begin{conclusion}
Die Basiswechselmatrix \(A=M_{BC}\) einer Orthonormalbasis \(C\) in eine andere
Orthonormalbasis \(B\) geh\"ort zur \textbf{orthogonalen Gruppe}
\[
O(n):=\left\{A\in\GL_{n}(\mathbb{R})\mid A^{\top}\cdot A=I\right\}\quad
    \text{f\"ur } \mathbb{K}=\mathbb{R}
\]
beziehungsweise zur \textbf{unit\"aren Gruppe}
\[
U(n):=\left\{A\in\GL_{n}(\mathbb{C})\mid A^{\top}\cdot\overline{A}=I\right\}
    \quad\text{f\"ur } \mathbb{K}=\mathbb{C}
\]
\end{conclusion}
\begin{comment}
\(O(n)\), beziehungsweise \(U(n)\), ist eine Untergruppe von 
\(\GL_{n}(\mathbb{R})\), beziehungsweise \(\GL_{n}(\mathbb{C})\).
\end{comment}
\begin{conclusion}[Iwasawa-Zerlegung]
\index{Iwasawa-Zerlegung}
Jede Matrix \(g\in\GL_{n}(\mathbb{R})\) hat eine eindeutige Produktzerlegung
\[
g=k\cdot b
\]
mit \(k\in O(n)\) und \(b\in B(n):=\left\{
    \begin{pmatrix}\beta_{1}&&*\\&\ddots&\\0&&\beta_{n}\end{pmatrix}\mid
    \beta_{\nu}>0\right\}\).
Das hei\ss t:
\[
\GL_{n}(\mathbb{R})=O(n)\cdot B(n)
\]
Analog gilt: 
\[
\GL_{n}(\mathbb{C})=U(n)\cdot B(n)_{\mathbb{C}}
\]
mit
\[
B(n)_{\mathbb{C}}:=\left\{
    \begin{pmatrix}\beta_{1}&&*\\&\ddots&\\0&&\beta_{n}\end{pmatrix}\in
	\GL_{n}(\mathbb{C})\mid\beta_{\nu}\in\mathbb{R}_{>0}
    \right\}
\]
\end{conclusion}
\begin{proof}
F\"ur \(\mathbb{K}=\mathbb{R}\,g\in\GL_{n}(\mathbb{R})\) folgt: Die Spalten
\(b_{1},\ldots,b_{n}\) sind eine Basis von \(\mathbb{R}^{n}\).\\
Das Schmidtsche Orthogonalisierungsverfahren liefert eine Orthonormalbasis
\(\{c_{1},\ldots,c_{n}\}\) mit \"Ubergangsmatrix \(A=M_{BC}\in B(n)\). Denn:
\[
c_{\nu}:=\sum_{i=1}^{\nu}{\alpha_{i\nu}b_{i}}
\]
besagt \(g\cdot A=(c_{1},\ldots,c_{n})\) und \(k=(c_{1},\ldots,c_{n})\in O(n)\),
da \(k^{\top}\cdot k=\left(\langle c_{i},c_{j}\rangle\right)=I\).
\end{proof}

\section{Orthogonale Projektion und orthogonales Komplement}
\index{Projektion!orthogonale}\index{Komplement!orthogonales}
\begin{theo}[Satz von Pyhtogoras]
\index{Pythagoras!Satz von}
F\"ur \(x,y\in V\) mit \(x\bot y\) gilt:
\[
\lVert x+y\rVert^{2}=\lVert x\rVert^{2}+\lVert y\rVert^{2}
\]
\end{theo}
\begin{proof}
\begin{align*}
\lVert x+y\rVert^{2}&=\langle x+y,x+y\rangle\\
&=\langle x,x\rangle+\underbrace{\langle x,y\rangle}_{=0}+
    \underbrace{\langle y,x\rangle}_{=0}+\langle y,y\rangle\\
&=\lVert x\rVert^{2}+\lVert y\rVert^{2}
\end{align*}
\end{proof}
Ist \(\{x_{1},\ldots,x_{N}\}\) ein Orthogonalsystem, so folgt
\[
\left\lVert\sum_{\nu=1}^{N}{x_{\nu}}\right\rVert^{2}=\sum_{\nu=1}^{N}\lVert x_{\nu}\rVert^{2}
\]
Der Beweis folgt leicht mit vollst\"andiger Induktion.
\begin{theo}
Sei \(U\leq V\) mit \(\dim V<\infty\).
\begin{enumerate}
\item F\"ur alle \(x\in V\) existiert genau ein \(y\in U\) mit 
\(d:=\lVert x-y\rVert=\min\{\lVert x-u\rVert\mid u\in U\}\).
\item Dieses \(y\in U\) ist auch charakterisiert durch: \(x-y\bot U\).\\
Schreibe: \(y=:\Pi_{U}(x)\).
\item Die Abbildung \(\Pi_{U}\in\End(V)\) ist stetig; es gilt 
\(\Pi_{U}^{2}=\Pi_{U}\) und \(\lVert\Pi_{U}(x)\rVert\leq\lVert x\rVert\).\\
\index{Abstand}\index{Projektion!orthogonale}\index{Lot}\index{Lotfu\ss punkt}
\(d\) hei\ss t \textbf{Abstand} von \(x\) und \(U\), \(y=\Pi_{U}(X)\) die
\textbf{orthogonale Projektion} von \(x\) auf \(U\), \(z:=x-y\) hei\ss t 
\textbf{Lot} von \(x\) auf \(U\), \(y\) \textbf{Lotfu\ss punkt}.
\end{enumerate}
\end{theo}
% \(V=\mathbb{R}^{3},\,U=\langle u\rangle\)
% Hier kommt noch eine Zeichnung hin.
\begin{proof}
\begin{enumerate}
\item W\"ahle eine Orthonormalbasis \(S=\{e_{i}\mid i=1,\ldots,r\}\) in \(U\).
Setze \(y=\Pi_{U}(x):=\sum_{i=1}^{r}\langle x,e_{i}\rangle e_{i}\).
\begin{thesis}
\(\forall u'\in U:\quad x-y\bot y-u'\)
\end{thesis}
\begin{align*}
\langle x-y,y-u'\rangle&=\underbrace{\langle x,y\rangle-\langle y,y\rangle}_{\overset{!}{=}0}+\underbrace{\langle y,u'\rangle-\langle x,u'\rangle}_{\overset{!}{=}0}\\
\langle x,y\rangle&=\left\langle x,\sum_{i}{\langle x,e_{i}\rangle e_{i}}\right\rangle
    =\sum_{i}{\overline{\langle x,e_{i}\rangle}\langle x,e_{i}\rangle}
% <y,y> !?
\end{align*}
\(u'\) in Basisdarstellung: Mit \(u'=\sum_{j}{\alpha_{j}e_{j}}\) folgt
\begin{align*}
\langle y,u'\rangle&=\left\langle\sum_{i}{\langle x,e_{i}\rangle e_{i}},\sum_{j}{\alpha_{j}e_{j}}\right\rangle\\
&=\sum_{i}{\langle x,e_{i}\rangle\overline{\alpha}_{i}}
\end{align*}
Weiterhin gilt:
\begin{align*}
\langle x,u'\rangle&=\left\langle x,\sum_{j}{\alpha_{j}e_{j}}\right\rangle\\
&=\sum_{j}{\overline{\alpha}_{j}\langle x,e_{j}\rangle}
\end{align*}
Mit Pythagoras folgt:
\begin{align*}
\lVert x-u'\rVert^{2}&=\lVert x-y+y-u'\rVert^{2}\\
&=\lVert x-y\rVert^{2}+\underbrace{\lVert y-u'\rVert^{2}}_{\geq0}\\
&\geq\lVert x-y\rVert^{2}
\end{align*}
Es ist also \(\lVert x-u'\rVert\geq\lVert x-y\rVert\), wobei Gleichheit genau
f\"ur \(y-u'=0\) gilt. Damit folgt die Eindeutigkeit von \(y\).
\item Sei \(y\in U\) und \(x-y\bot U\). Dann gilt 
\(\langle x,e_{i}\rangle=\langle y,e_{i}\rangle\) f\"ur alle \(i\).\\
Es folgt:
\begin{align*}
y&=\sum_{i}{\langle y,e_{i}\rangle e_{i}}\\
&=\sum_{i}{\langle x,e_{i}\rangle e_{i}}\\
&=\Pi_{U}(x)
\end{align*}
\item Aus \(x-y\bot y\) folgt mit Pythagoras:
\begin{align*}
\lVert x\rVert^{2}&=\lVert x-y\rVert^{2}+\lVert y\rVert^{2}\\
&\geq\lVert y\rVert^{2}\\
&=\left\lVert\Pi_{U}(x)\right\rVert^{2}
\end{align*}
Es folgt: \(\Pi_{U}\) ist (Lipschitz-)stetig.\\
\(\Pi_{U}^{2}=\Pi_{U}\) ist leicht selbst zu verifizieren.
\end{enumerate}
\end{proof}
\begin{definition}
\index{Komplement!orthogonales}\index{Orthogonalraum}
Sei \(M\subseteq V\) Teilmenge. Der Vektorraum
\[
M^{\bot}:=\left\{y\in V\mid y\bot M\right\}
\]
hei\ss t \textbf{Orthogonalraum} oder \textbf{orthogonales Komplement} von 
\(M\).
\end{definition}
\begin{lemma}
\begin{enumerate}
\item \(M_{1}\subseteq M_{2}\implies M_{1}^{\bot}\geq M_{2}^{\bot}\)
\item \(\langle M\rangle^{\bot}=M^{\bot}\)
\item Aus \(M_{i}\subseteq V,\,(i=1,\ldots,n)\) folgt 
\[
\left(\bigcup_{i=1}^{n}M_{i}\right)^{\bot}=\bigcap_{i=1}^{n}M_{i}^{\bot}
\]
\item Aus \(U_{i}\leq V\) (Teilr\"aume) folgt
\[
\left(\bigcap_{i=1}^{n}U_{i}\right)^{\bot}\geq\sum_{i=1}^{n}{\left(U_{i}^{\bot}\right)}
\]
\item \(\langle M\rangle\leq\left(M^{\bot}\right)^{\bot}\) und
\(M^{\bot}=\left(\left(M^{\bot}\right)^{\bot}\right)^{\bot}\).
\item Im Spezialfall \(\dim V<\infty\) gilt:
\begin{enumerate}
\item Mit \(U\leq V\) folgt \(V=U\oplus U^{\bot}\) (insbesondere \(\dim U+\dim U^{\bot}=\dim V\)) und \(\left(U^{\bot}\right)^{\bot}=U\)
\item Mit \(U_{i}\leq V\) folgt 
\(\left(\bigcap_{i=1}^{n}U_{i}\right)^{\bot}=\sum_{i=1}^{n}{\left(U_{i}^{\bot}\right)}\)
\end{enumerate}
\end{enumerate}
\end{lemma}
\begin{proof}
\"Ubung!
\end{proof}

\chapter{Normale Endomorphismen}
\index{Endomorphismus}\index{normaler Endomorphismus}
\section{Die adjungierte lineare Abbildung}
\index{lineare Abbildung}\index{adjungierter Homomorphismus}\index{Adjungierte}
Seien \(V,\,W \mathbb{K}\)-Vektorr\"aume mit Skalarprodukt 
\(\langle\cdot,\cdot\rangle_{V},\,\langle\cdot,\cdot\rangle_{W}\)
\begin{lemma}
Sei \(\phi\in\Hom(V,W)\). Falls \(\Psi\in\Hom(W,V)\) mit der Eigenschaft
\[
\langle\phi(x),y\rangle_{W}=\langle x,\Psi(y)\rangle_{V}\,\forall x\in V,\,
y\in W,
\]
so ist \(\Psi\) hierdurch eindeutig bestimmt.
\end{lemma}
\begin{proof}
Sei \(\Psi':W\to V\) ein Homomorphismus mit derselben Eigenschaft\\
\(\implies\) F\"ur \(\Omega:=\Psi-\Psi'\in\Hom(W,V)\) gilt:
\begin{align*}
\forall x\in V,\,y\in W: \langle x,\Omega(y)\rangle_{V}&=
\langle x,\Psi(y)-\Psi'(y)\rangle_{V}\\
&=\langle x,\Psi(y)\rangle_{V}-\langle x,\Psi'(y)\rangle_{V}\\
&=\langle\phi(x),y\rangle_{W}-\langle\phi(x),y\rangle_{W}\\
&=0
\end{align*}
\(\implies \langle\Omega(y),\Omega(y)\rangle_{V}=0\quad\implies
\Omega(y)=0\,\forall y\)\\
Also: \(\Omega=0\), d.h. \(\Psi =\Psi'\).
\end{proof}

\begin{definition}
Falls \(\Psi\) existiert wie oben, so hei\ss t \(\Psi\) der zu \(\phi\) 
adjungierte Homomorphismus.\\
Schreibe: \(\Psi =:\phi^{*}\qquad\Hom^{a}(V,W):=\{\phi\in\Hom(V,W)\mid\phi^{*}\text{existiert}\}\)
\end{definition}

\begin{example}
\(V=\mathbb{K}^{n},\,W=\mathbb{K}^{m}\) mit Standardskalarprodukt.\\
\(A\in\mathbb{K}^{n\times m},\,\phi:=\Lambda_{A}:x\mapsto A\cdot x\)
\[
\langle\phi(x),y\rangle_{W}=\langle Ax,y\rangle_{W}=\overline{y}^{T}Ax=
(y^{*}A)x=(A^{*}y)^{*}=\langle x,A^{*}y\rangle_{V}=\langle x,\Lambda_{A^{*}}(y)\rangle
\]
Das hei\ss t: \((\Lambda_{A})^{*}=\Lambda_{A*}\). Insbesondere existiert die 
Adjungierte.
\end{example}
\begin{proposition}
\begin{enumerate}
\item \(\Hom^{a}(V,W)\leq\Hom(V,W)\)
\item F\"ur die Abbildung \(*:\,\Hom^{a}(V,W)\to\Hom(W,V),\,\phi\mapsto\phi^{*}\)
gilt:
\[
(\alpha\phi+\beta\Psi)^{*}=\overline{\alpha}\phi^{*}+\overline{\beta}\Psi^{*}
\]
Die Abbildung ist \textbf{semilinear}.
\item Aus \(\phi\in\Hom^{a}(V,W),\,\Theta\in\Hom^{a}(W,U)\) folgt
\(
\Theta\circ\phi\in\Hom^{a}(V,U)
\)
und
\(
(\Theta\circ\phi)^{*}=\phi^{*}\circ\Theta^{*}
\)
\item Aus \(\phi\in\Hom^{a}(V,W)\) folgt \(\phi^{*}\in\Hom^{a}(W,V)\) und
\((\phi^{*})^{*}=\phi\), sowie \(\Kern\phi=\Bil(\phi^{*})^{\bot}\).
\end{enumerate}
\end{proposition}
\begin{proof}
\begin{enumerate}
\item +(2) % ja, das ist h‰sslich; kommt Zeit kommt bessere Lˆsung
Sei \(\phi,\Psi\in\Hom^{a}(V,W),\,\alpha,\beta\in\mathbb{C}\).\\
\(\overline{\alpha}\phi^{*}+\overline{\beta}\Psi^{*}\) ist die Adjungierte zu
\(\alpha\phi+\beta\Psi\), denn
\begin{align*}
\langle(\alpha\phi+\beta\Psi)(x),y\rangle
    &=\alpha\underbrace{\langle\phi(x),y\rangle}_{\langle x,\phi^{*}(y)\rangle}
    +\beta\underbrace{\langle\Psi(x),y\rangle}_{\langle x,\Psi^{*}(y)\rangle}\\
&=\langle x,\overline{\alpha}\phi^{*}(y)+\overline{\beta}\Psi^{*}(y)\rangle
\end{align*}
\item[(3)] F\"ur alle \(x\in V,\,y\in U\) gilt:
\begin{align*}
\langle\Theta\circ\phi(x),y\rangle&=\langle\Theta(\phi(x)),y\rangle\\
&=\langle\phi(x),\Theta^{*}(y)\rangle\\
&=\langle x,\phi^{*}(\Theta^{*}(y))\rangle
\end{align*}
\item[(4)] Es gilt
\begin{align*}
\langle\phi^{*}(y),x\rangle&=\overline{\langle x,\phi^{*}(y)\rangle}\\
&=\overline{\langle\phi(x),y\rangle}\\
&=\langle y,\phi(x)\rangle
\end{align*}
Das hei\ss t \(\phi^{*}\) hat die Adjungierte \(\left(\phi^{*}\right)^{*}=\phi\)

Weiterhin gilt:
\begin{align*}
x\in\Kern(\phi)&\Longleftrightarrow\phi(x)=0\\
&\Longleftrightarrow\forall y\in W:\,\underbrace{\langle\phi(x),y\rangle}_{\langle x,\phi^{*}(y)\rangle}=0\\
&\Longleftrightarrow x\bot\phi^{*}(w)
\end{align*}
\end{enumerate}
\end{proof}

Sei \(V\) ein Vektorraum mit Skalarprodukt \(\langle\cdot,\cdot\rangle,
\,\phi\in\End(V)\) mit \(\langle\phi(x),y\rangle=
\langle x,\phi^{*}(y)\rangle\).
\begin{lemma}
Sei \(\dim V<\infty,\,\phi\in\End(V)\). Dann gilt:
\[
\lambda\in\Spec(\phi)\implies\overline{\lambda}\in\Spec(\phi^{*})
\]
\end{lemma}
\begin{proof}
Sei \(u\neq0,\,\phi(u)=\lambda\cdot u\). Dann gilt f\"ur alle \(y\in V\):
\[
0=\langle(\phi-\lambda\id)(u),y\rangle=\langle u,e(\phi-\lambda\id)^{*}(y)\rangle
\]
Nach Proposition gilt \((\phi-\lambda\id)^{*}=\phi^{*}-\overline{\lambda}\id\).
\\
Dann ist \(0=\langle u,\underbrace{(\phi^{*}-\overline{\lambda}\id)(y)}_{\neq u}\rangle\)
(wegen der positiven Definitheit und \(u\neq0\)).

Daraus folgt: 
\begin{align*}
\phi^{*}-\overline{\lambda}\id\text{ ist nicht surjektiv}&\Longleftrightarrow
    \phi^{*}-\overline{\lambda}\id\text{ ist nicht injektiv}\\
&\Longleftrightarrow\exists v\neq0:\,\phi^{*}(v)=\overline{\lambda}v\\
&\implies\overline{\lambda}\in\Spec(\phi^{*})
\end{align*}
\end{proof}

\section{Der Spektralsatz}
\index{Spektralsatz}\index{Spektrum}

\begin{proposition}
Sei \(\phi\in\End^{a}(V)\)
\begin{enumerate}
\item F\"ur \(\lambda,\mu\in\Spec(\phi)\) mit \(\lambda\neq\mu\) gilt:
\[
E_{\lambda}(\phi)\bot E_{\mu}(\phi)
\]
\item Folgende Aussagen sind \"aquivalent:
    \begin{enumerate}
    \item\(\phi\circ\phi^{*}=\phi^{*}\circ\phi\)
    \item\(\forall x,y\in V:\,\langle\phi(x),\phi(y)\rangle=\langle\phi^{*}(x),\phi^{*}(y)\rangle\)\\
    \(\phi\) hei\ss t \textbf{normal}.
    \end{enumerate}
\item Ist \(\phi\) normal, dann folgt \(\Kern(\phi)=\Kern(\phi^{*})\), 
insbesondere \(E_{\lambda}(\phi)=E_{\overline{\lambda}}(\phi^{*})\).
\end{enumerate}
\end{proposition}
\begin{proof}
\begin{enumerate}
\item Seien \(u\in E_{\lambda}(\phi),\,v\in E_{\mu}(\phi)\). Dann gilt
\begin{align*}
\lambda\cdot\langle u,v\rangle&=\langle\lambda u,v\rangle\\
&=\langle\phi(u),v\rangle\\
&=\langle u,\phi^{*}(v)\rangle\\
&=\langle u,\overline{\mu}v\rangle\\
&=\mu\langle u,v\rangle\\
\end{align*}
Mit \(\lambda\neq\mu\) folgt \(\langle u,v\rangle=0\)
\end{enumerate}
\end{proof}

\begin{theo}[Spektralsatz]
Sei \(\dim V<\infty,\,\langle\cdot,\cdot\rangle\) Skalarprodukt mit 
\(\phi\in\End(V)\) normal.\\
Im Fall \(\mathbb{K}=\mathbb{R}\) habe das charakteristische Polynom 
\(f_{\phi}(T)\) nur reelle Nullstellen. Dann existiert eine Orthonormalbasis
aus Eigenvektoren von \(\phi\).
\end{theo}
\begin{proof}
Sei \(n:=\dim V,\,\lambda_{1}\in\Spec(\phi),\,b_{1}\neq0\in E_{\lambda_{1}}(\phi)\). Ohne Beschr\"ankung der Allgemeinheit sei \(\lVert b_{1}\rVert=1\).\\
Betrachte das orthogonale Komplement \(U:=b_{1}^{\top}\). Es gilt
\[
V=\langle b_{1}\rangle\oplus U,
\]
wobei \(\phi(U)\subseteq U,\,\phi^{*}(U)\subseteq U\) ist, denn f\"ur alle 
\(u\in U\) gilt
\begin{align*}
\langle\phi(u),b_{1}\rangle&=\langle u,\phi^{*}(b_{1})\rangle\\
&=\langle u,\overline{\lambda_{1}}b_{1}\rangle\\
&=\lambda_{1}\underbrace{\rangle u,b_{1}\rangle}_{=0}=0
\end{align*}
Daraus folgt \(\phi(u)\bot b_{1}\), das hei\ss t \(\phi(U)\bot b_{1}\), damit
folgt \(\phi(U)\subseteq U\).\\
F\"ur \(\phi^{*}\) ist die Vorgehensweise analog.\\
Insbesondere ist \(\left.\phi\right|_{U}\in\End(U)\).

Ferner gilt \(\left(\left.\phi\right|_{U}\right)^{*}=\left.\phi^{*}\right|_{U}\), also
\begin{align*}
\left.\phi\right|_{U}\left.\phi^{*}\right|_{U}&=\left.\left(\phi\phi^{*}\right)\right|_{U}\\
% das hier ist von der Ausrichtung noch nicht optimal...
&\overset{\phi\text{ normal}}{=}\left.\left(\phi^{*}\phi\right)\right|_{U}\\
&=\left.\phi^{*}\right|_{U}\left.\phi\right|_{U}
\end{align*}
Also ist \(\phi\) normal.

Vollst\"andige Induktion nach \(n\):\\
\(n-1 \leadsto n\): \(U\) hat eine Orthonormalbasis \(\{b_{2},\ldots,b_{n}\}\)
aus Eigenvektoren von \(\left.\phi\right|_{U}\).\\
Dann ist \(\{b_{1},b_{2},\ldots,b_{n}\}\) die gesuchte Orthonormalbasis.
\end{proof}
\begin{lemma}[Transfer zu Matrizen]
F\"ur beliebiges \(\phi\in\End(V)\) sei \(s_{\phi}\) die Sesquilinearform
\[
s_{\phi}(x,y):=\langle\phi(x),y\rangle
\]
\(B\) sei eine Orthonormalbasis von \(V\). Dann gilt:
\begin{enumerate}
\item\(D_{BB}(\phi^{*})=D_{BB}(\phi)^{*}\)
\label{Lemma: 18.2; 1; Beh. 1}
\item\(D_{BB}(s_{\phi})=D_{BB}(\phi)^{\top}\)
\label{Lemma: 18.2; 1; Beh. 2}
\item\(\phi\) ist normal, genau dann wenn f\"ur \(A:=D_{BB}(\phi)\) gilt:
\label{Lemma: 18.2; 1; Beh. 3}
\[
A\cdot A^{*}=A^{*}\cdot A
\]
\end{enumerate}
\end{lemma}
\begin{proof}
Sei \(B=\{b_{1},\ldots,b_{n}\}\).\\
Erinnere: \(D_{BB}(\phi)=(x_{ij})\) ist 
definiert durch \(\phi(b_{ij})=\sum_{i=1}^{n}{\alpha_{ij}b_{i}}\).\\
Es gilt
\begin{align*}
s_{\phi}(b_{j},b_{k})&=\langle\phi(b_{j}),b_{k}\rangle\\
&=\sum_{i=1}^{n}{\alpha_{ij}\underbrace{\langle b_{i},b_{k}\rangle}_{=\delta_{ik}}}\\
&=\alpha_{kj}
\end{align*}
Damit folgt die Behauptung \eqref{Lemma: 18.2; 1; Beh. 2}.

Sei \(D_{BB}(\phi^{*})=(\beta_{ij})\), das hei\ss t
\begin{align*}
\overline{\alpha_{ji}}&=\overline{\langle\phi(b_{i}),b_{j}\rangle}\\
&=\langle b_{j},\phi(b_{i})\rangle\\
&=\langle\phi^{*}(b_{j}),b_{i}\rangle\\
&=\beta_{ij}
\end{align*}
Damit folgt die Behauptung \eqref{Lemma: 18.2; 1; Beh. 1}.

Es bleibt noch Behauptung \eqref{Lemma: 18.2; 1; Beh. 3} zu zeigen:
\[
\phi\cdot\phi^{*}\Longleftrightarrow
\underbrace{D_{BB}(\phi\phi^{*})}_{=AA^{*}}=
\underbrace{D_{BB}(\phi^{*}\phi)}_{=A^{*}A}
\]
\end{proof}
\begin{corollary}[zum Spektralsatz]
F\"ur \(\lambda\in\Spec(\phi)\) sei \(U_{\lambda}:=E_{\lambda}(\phi)\) und
\(\Pi_{\lambda}:=\Pi_{U_{\lambda}}\) (orthogonale Projektion). Dann gilt f\"ur
\(p(T)\in\mathbb{K}[T]\):
\[
p(\phi)=\sum_{\lambda\in\Spec(\phi)}{p(\lambda)\cdot\Pi_{\lambda}}
\]
und
\[
\phi^{*}=\sum_{\lambda}{\overline{\lambda}\cdot\Pi_{\lambda}}
\]
\end{corollary}
\begin{proof}
Da \(U_{\lambda}\bot U_{\mu}\) f\"ur \(\lambda\neq\mu\) folgt \(\Pi_{\lambda}\Pi_{\mu}=\delta_{\lambda\mu}\Pi_{\lambda}\).\\
Spektralsatz: Aus \(V=\underset{\lambda}{\bigoplus}U_{\lambda}\) folgt 
\(\id_{V}=\sum_{\lambda}{\Pi_{\lambda}}\).\\
Aus \(\left.p(\phi)\right|_{U_{\lambda}}=p(\lambda)\cdot\id_{U_{\lambda}}\)
folgt \(p(\phi)=\sum_{\lambda}{p(\lambda)\Pi_{\lambda}}\).\\
\(\left.\phi^{*}\right|_{U_{\lambda}}=\overline{\lambda}\cdot\id_{U_{\lambda}}\)
liefert
\begin{align*}
\phi^{*}&=\phi^{*}\cdot\id_{U_{\lambda}}\\
&=\phi^{*}\cdot\sum_{\lambda}{\Pi_{\lambda}}\\
&=\sum_{\lambda}{\phi^{*}\Pi_{\lambda}}\\
&=\sum_{\lambda}{\overline{\lambda}\Pi_{\lambda}}
\end{align*}
\end{proof}
\begin{theo}
Seien \(\phi,\,\Psi\in\End(V)\) normal und \(\phi\cdot\Psi=\Psi\cdot\phi\).\\
Falls in \(V\) eine Orthonormalbasis aus Eigenvektoren existiert und eine
Orthonormalbasis aus Eigenvektoren zu \(\Psi\), dann existiert eine
Orthonormalbasis aus gemeinsamen Eigenvektoren zu \(\phi\) und \(\Psi\).
\end{theo}
\begin{proof}
Seien \(V=\underset{\lambda}{\bigoplus}U_{\lambda},\,U_{\lambda}:=E_{\lambda}(\phi)\).\\
Zeige: \(\Psi(U_{\lambda})\subseteq U_{\lambda}\) und \(\left.\Psi\right|_{U_{\lambda}}\) sind diagonalisierbar.

Dazu:
\begin{align*}
u\in U_{\lambda}&\implies\phi(u)=\lambda u\\
&\implies\Psi(\phi(u))=\Psi(\lambda u)=\lambda\Psi(u)\\
&\Longleftrightarrow\phi(\Psi(u))=\lambda\Psi(u)\quad\implies\Psi(u)\in U_{\lambda}
\end{align*}
Analog: \(\phi(E_{\mu}(\Psi))\subseteq E_{\mu}(\Psi)\).\\
Da \(V=\underset{\mu}{\bigoplus}E_{\mu}(\Psi)\), gilt insbesondere f\"ur alle
\(u\in U_{\lambda}:\,u=\sum_{\mu}{x_{\mu}}\in E_{\mu}(\Psi)\). Es gilt sogar:
jedes \(x_{\mu}\in U_{\lambda}\), denn:
\[
\phi(x_{\mu}=:x'_{\mu}\in E_{\mu}(\Psi)
\]
\begin{align*}
\lambda{\sum_{\mu}}^{\oplus}x_{\mu}&=\lambda u\\
&=\phi(u)\\
&=\sum_{\mu}{\phi(x_{\mu}})\\
&={\sum_{\mu}}^{\oplus}{x'_{\mu}}
\end{align*}
Da die Summe direkt ist, folgt f\"ur alle \(\mu\)
\[
\lambda\cdot x_{\mu}=x'_{\mu}=\phi(x_{\mu}),
\]
das hei\ss t \(x_{\mu}\in U_{\lambda}\).

Insgesamt gezeigt:
\[
U_{\lambda}=\underset{\mu}{\bigoplus}E_{\mu}(\Psi)\cap U_{\lambda}
\]
(d.h. \(\left.\Psi\right|_{U_{\lambda}}\) ist diagonalisierbar). Damit folgt
\[
V=\underset{\lambda}{\bigoplus}\underset{\mu}{\bigoplus}E_{\mu}(\Psi)\cap E_{\lambda}(\phi)
\]
\end{proof}

\section{Selbstadjungierte Endomorphismen}
\index{Endomorphismus!selbstadjungiert}\index{Matrix!hermitesch}
\index{Spektralradius}

\begin{definition}
\(\phi\in\End(V)\) hei\ss t \textbf{selbstadjungiert}, falls \(\phi^{*}=\phi\).
\end{definition}
\begin{comment}
\begin{enumerate}
\item \(\phi\) ist selbstadjungiert impliziert \(\phi\) ist normal.
\item Ist \(\dim V<\infty,\, B\) Orthonormalbasis und \(A:=D_{BB}(\phi)\), dann
ist \(\phi\) selbstadjungiert genau dann wenn \(A=A^{*}\), d.h. \(A\) ist 
hermitesch.
\end{enumerate}
\end{comment}
\paragraph{Hintergrund:}{Viele Problem in Physik und Technik f\"uhren auf 
hermitesche Matrizen.}
\begin{theo}
\begin{enumerate}
\item \(A\in\mathbb{C}^{m\times m}\) mit \(A=A^{\top}\) impliziert 
    \(\Spec(A)\subseteq\mathbb{R}\) (oder: das charakteristische Polynom hat nur
reelle Nullstellen).
\item F\"ur hermitesche \(A\) gilt:
\begin{center}
\(A\) ist positiv definit\(\Longleftrightarrow\forall\lambda\in\Spec(A):\,\lambda>0\)
\end{center}
\end{enumerate}
\end{theo}
\begin{proof}
\begin{enumerate}
\item Sei \(\lambda\in\Spec(A)\) und \(v\neq0\) mit \(Av=\lambda v\). Dann:
\begin{align*}
\lambda\langle v,v\rangle&=\langle\lambda v,v\rangle\\
&=\langle Av,v\rangle\\
&=\langle v,A^{*}v\rangle\\
&=\langle v,Av\rangle\\
&=\langle v,\lambda v\rangle\\
&=\overline{\lambda}\underbrace{\langle v,v\rangle}_{=\lVert v\rVert^{2}\neq0}
\end{align*}
Also gilt \(\lambda=\overline{\lambda}\), das hei\ss t \(\lambda\in\mathbb{R}\).
\item \(A\) ist nach Definition genau dann positiv definit wenn 
\(s_{A}(x,y)=x^{\top}A\overline{y}\) positiv definit ist.\\
% In der Vorlesung wurde an dieser Stelle an das komplexe Skalarprodukt
% erinnert, ist es sinnvoll/notwendig das hier auch zu tun?
F\"ur eine Orthonormalbasis \(\{b_{1},\ldots,b_{n}\}\) aus Eigenvektoren von
\(A=A^{*}\) gilt
\[
Ab_{i}=\lambda b_{i}
\]
und Basisdarstellung
\[
\overline{x}=\sum_{i=1}^{m}{\alpha_{i}b_{i}}\leadsto x=\sum_{i=1}^{m}{\overline{\alpha_{i}}\overline{b_{i}}}
\]
und somit
\begin{align*}
s_{A}(x,x)&=x^{\top}A\overline{y}\\
&=\sum_{i=1}^{m}{\overline{\alpha_{i}}\overline{b_{i}}}\sum_{j=1}^{m}{\alpha_{j}\underbrace{Ab_{j}}_{\lambda_{j}b_{j}}}\\
&=\sum_{i,j}{\overline{\alpha_{i}}\alpha_{j}\lambda_{j}\overline{b_{i}}^{\top}b_{j}}\\
&=\sum_{i,j}{\overline{\alpha_{i}}\alpha_{j}\lambda_{j}\underbrace{\overline{\langle b_{i},b_{j}\rangle}}_{=\delta_{ij}}}\\
&=\sum_{i=1}^{m}\lvert\alpha_{i}\rvert^{2}\lambda_{i}
\end{align*}
Also: \(s_{A}(x,x)=\sum_{i=1}^{m}{\lvert\alpha_{i}\rvert^{2}\lambda_{i}}\).\\
Dann folgt:\\
\[
s_{A}(x,x)\geq0\,\forall x\Longleftrightarrow\forall\lambda_{i}\geq0
\]
und
\[
s_{A}(x,x)=0\implies x=0
\]
genau dann, wenn alle \(\lambda_{i}\) gr\"o\ss er Null sind.
\end{enumerate}
\end{proof}
\begin{comment}
F\"ur selbstadjungierte, reelle \(A\) ist die Extravoraussetzung im Spektralsatz
immer erf\"ullt.
\end{comment}
\begin{corollary}
Ist \(V\) ein \(\mathbb{R}\)-Vektorraum mit Skalarprodukt, \(\dim V<\infty\) und
\(\phi\in\End(V)\) selbstadjungiert, so besitzt \(V\) eine Orthonormalbasis aus
Eigenvektoren zu \(\phi\).
\end{corollary}
\begin{definition}
Sei \(V\) ein \(\mathbb{C}\)-Vektorraum und \(\phi\in\End(V)\).\\
Dann hei\ss t \(\rho(\phi):=\sup\{\lvert\lambda\rvert\mid\lambda\in\Spec(\phi)\}\)
der \textbf{Spektralradius} von \(\phi\). F\"ur \(A\in\mathbb{C}^{m\times m}\)
setze \(\rho(A):=\rho(\Lambda_{A})\).
\end{definition}

\begin{comment}
Auf \(\mathbb{K}^{m\times n}\) ist durch
\[
\lVert A\rVert:=\sup\{\lVert A\rVert\mid x\in\mathbb{K}^{n},\lVert x\rVert\leq1\}
\]
eine Norm definiert.
\end{comment}
\begin{theo}
Es gilt \(\lVert A\rVert=\sqrt{\rho(A^{*}A)}\).\\
Falls \(m=n\) und \(A\) normal ist, gilt sogar \(\lVert A\rVert=\rho(A)\).
\end{theo}
\begin{proof}
\(A^{*}A\) ist selbstadjungiert, das hei\ss t es gilt 
\((A^{*}A)^{*}=A^{*}\cdot\left(A^{*}\right)^{*}=A^{*}A\).\\
Dann existiert eine Orthonormalbasis \(\{b_{1},\ldots,b_{n}\}\) aus 
Eigenvektoren, etwa \(A^{*}Ab_{i}=\mu_{i}b_{i}\) mit \(\mu_{i}\in\mathbb{R}\).\\
Dann gilt:
\begin{align*}
\lVert Ax\rVert^{2}&=\langle Ax,Ax\rangle\\
&=\langle x,A^{*}Ax\rangle\\
&\overset{x=\sum_{i=1}^{n}{\alpha_{i}b_{i}}}{=}=\left\langle x,\sum_{i=1}^{n}{\alpha_{i}\mu_{i}b_{i}}\right\rangle\\
&=\sum_{i=1}^{n}\lvert\alpha_{i}\rvert^{2}\underbrace{\overline{\mu_{i}}}_{=\mu_{i}}
\end{align*}
Au\ss erdem:
\begin{align*}
\lVert Ax\rVert^{2}&\leq\sum_{i}\lvert\alpha_{i}\rvert^{2}\underbrace{\max\{\lvert\mu_{i}\rvert\}}_{=\rho(A^{*}A)}\\
&=\rho(A^{*}A)\lVert x\rVert^{2}
\end{align*}
Sei \(x=\sum_{i}{\alpha_{i}b_{i}}\) die Basisdarstellung. Dann ist 
\(\lVert Ax\rVert^{2}=\sum_{i}{\lvert\alpha_{i}\rvert^{2}\mu_{i}}\), also alle
\(\mu_{i}\geq0\).\\
Weiterhin: \(A^{*}Ab_{i}=\mu_{i}b_{i}\) und \(\rho(A^{*}A)=\mu_{\max}=\mu_{i_{0}}\),
dazu \(b_{i_{0}}\). Mit \(x:=b_{i_{0}}\) folgt \(\lVert Ax\rVert^{2}=\mu_{\max}\).\\
\textbf{Speziell f\"ur normales \(A\)} (\(m=n\)):\\
Es gilt \(E_{\lambda}(A)=E_{\overline{\lambda}}(A^{*})\). Dann:
\[
\mu_{i}=\lambda_{i}\cdot\overline{\lambda_{i}}=\lvert\lambda_{i}\rvert^{2}
\]
und damit folgt 
\[
\lVert A\rVert=\lvert\mu_{\max}\rvert=\rho(A)
\]
\end{proof}
\begin{caution}
Im allgemeinen ist \(\lVert A\rVert\neq\rho(A)\).\\
Beispiel: 
\[
A=\begin{pmatrix}0&1\\0&0\end{pmatrix}
\] 
mit \(\rho(A)=0\) aber \(\lVert A\rVert=1\).
Es ist
\[
A^{*}=\begin{pmatrix}0&0\\1&0\end{pmatrix},\,A^{*}A=\begin{pmatrix}0&0\\0&1\end{pmatrix}
\]
\end{caution}

\chapter{Isometrien}

\begin{task}
Studiere alle linearen Abbildungen, die \textbf{Abst√§nde} von Punkten nicht √§ndern.
Z.B. Drehungen um einen Punkt im $\mathbb{R}^2$.
\end{task}

\section{Charakterisierung und orthogonale Gruppe}
\begin{definition}
\index{Morphismus}\index{Isometrie}\index{Automorphismus}\index{Automorphismengruppe}
Seien $V_1,V_2\ \mathbb{K}$-VRme mit Sesquilinearformen $s_1,s_2$.
\begin{enumerate}[(a)]
\item Ein \textbf{Morphismus von $\mathbb{K}$-VRmen mit Sesquilinearform} ist
$\Phi\in \Hom(V_1,V_2)$ mit:\\
\[\forall x,y\in V_1:s_2(\Phi(x),\Phi(y))=s_1(x,y)\]\\
Schreibe: $\Phi:(V_1,s_1)\to (V_2,s_2)$.
\item Ist $\Phi$ zus√§tzlich bijektiv, so hei√üt $\Phi$ eine \textbf{(lineare) Isometrie}.
\item Eine Isometrie $\Phi:(V,s)\to (V,s)$ hei√üt \textbf{Automorphismus} von s.\\
Die Gruppe $\Aut(s)\le\Aut(V)$ hei√üt die \textbf{Automorphismengruppe} von s.
\end{enumerate}
\end{definition}

\begin{example}
\index{Lorenzgruppe}
In der Relativit√§tstheorie wichtig ist die \textbf{Lorenzgruppe} $\Aut(s)$ zu\\
\[s:\mathbb{R}^4 \times \mathbb{R}^4 \to\mathbb{R}, (x,y)\mapsto x^T
\begin{pmatrix}
1&0&\cdots&0\\
0&\ddots&\ddots&\vdots\\
\vdots&\ddots&1&0\\
0&\cdots&0&-c
\end{pmatrix}
y\]\\ 
f√ºr $c:=$Lichtgeschwindigkeit.
\end{example}

\begin{definition}
\index{orthogonal!Gruppe}\index{Gruppe!orthogonale}
\index{orthogonal!Abbildung}\index{Abbildung!orthogonale}
\index{unit√§r!Gruppe}\index{Gruppe!unit√§re}
\index{unit√§r!Abbildung}\index{Abbildung!unit√§re}
Im Folgenden sei $s$ stets SKP.\\
\textbf{Fall $\mathbb{K}=\mathbb{R}$:}\\
$O(V,s):=\Aut(s)$ hei√üt \textbf{orthogonale Gruppe}. Die Elemente der Gruppe
hei√üen \textbf{orthogonale Abb. bzgl. s}.\\
\textbf{Fall $\mathbb{K}=\mathbb{C}$:}\\
$U(V.s):=\Aut(s)$ hei√üt \textbf{unit√§re Gruppe}. Die Elemente der Gruppe hei√üen
\textbf{unit√§re Abb. bzgl. s}.
\end{definition}

\begin{comment}
Eine wichtige Isometrie ist: abstrakter VRm $\cong$ Standardraum
\end{comment}

\begin{theo}
Sei $V$ VRm mit SKP $s$, $\dim(V)=n$ und ONB $B$. Dann ist die Koordinatendarstellung:\\
\[D_B:(V,s)\to(\mathbb{K}^n,\langle\cdot,\cdot\rangle)\] eine Isometrie.
\end{theo}

\begin{proof}
Sei $B=\{b_1,\ldots,b_n\}, x,y\in V$ mit $x=\sum_{i=1}^n{\alpha_i b_i},
y=\sum_{i=1}^n{\beta_i b_i}$. Dann gilt:
\begin{align*}
s(x,y)&=\sum_{i,j}{\alpha_i \overline{b_j}\cdot s(b_i,b_j)}\\
&= \sum_{i=1}^n{\alpha_i \overline{b_i}}\\
&= \langle
\begin{pmatrix}
\alpha_1\\
\vdots\\
\alpha_n
\end{pmatrix},
\begin{pmatrix}
\beta_1\\
\vdots\\
\beta_n
\end{pmatrix} 
\rangle\\
&= \langle D_B(x),D_B(y)\rangle
\end{align*}
\end{proof}

\begin{comment}
\begin{enumerate}
\index{L√§ngentreue}\index{Winkeltreue}
\item Sei $\Phi: V_1\to V_2$ Morphismus von SKP-R√§umen, dann ist $\Phi$ \textbf{l√§ngentreu}.
\[\iff\|x\|_1 = \|\Phi(x)\|_2\]
\textbf{Winkeltreue} f√ºr $K=\mathbb{R}$ bedeutet: 
\[\frac{\langle x_1,y_1\rangle_1}{\|x_1\|_1\|y_1\|_1} = \frac{\langle\Phi(x_1),
\Phi(y_1)\rangle_2}{\|\Phi(x_1)\|_2\|\Phi(y_1)\|_2}\]
\item $\Phi:(V,s)\to(V,s)$ Endomorphismus von SKP-R√§umen und $\dim(V)<\infty
\implies \Phi$ ist Isomorphismus und Automorphismus, also orthogonal und unit√§r. 
\end{enumerate}
\end{comment}

\begin{theo}[Isometriekriterium]
Sei $V$ VRm mit SKP $s=\langle\cdot,\cdot\rangle$ und sei $\Phi\in\Aut(V)$.\\
Folgende Aussagen sind √§quivalent:
\begin{enumerate}
\item $\Phi$ ist Isometrie (d.h. $\Phi\in\Aut(s)$).
\item $\Phi\in\End^a(V)$ und $\Phi^*=\Phi^{-1}$.
\item $\forall x\in V: \|x\|=\|\Phi(x)\|$
\item $\forall y\in V: (\|y\|=1)\implies(\|\Phi(y)\|=1)$ (Einheitssph√§renabbildung).
\end{enumerate}
\end{theo}

\begin{proof}
Die √Ñquivalenz ergibt sich aus folgendem Ringschluss:
\begin{enumerate}
\item[(1)$\implies$(2)] Es gilt $\forall x,y\in V$, $z:=\Phi(y)$:
\begin{align*}
&\Phi \text{ Isometrie}\\
&\iff \forall x,y\in V:\langle\Phi(x),\Phi(y)\rangle =\langle x,y\rangle\\
&\stackrel{\Phi^{-1}\text{ ex.}}{\iff} \forall x,z\in V:\langle\Phi(x),z\rangle
=\langle x,\Phi^{-1}(z)\rangle
\end{align*}
Nach Definition der Adjungierten folgt daraus $\Phi^{-1} = \Phi^*$.
\item[(2)$\implies$(3)] Es gilt f√ºr alle $x\in V$:
\[\|\Phi(x)\|^2=\langle\Phi(x),\Phi(x)\rangle\stackrel{(2)}{=}
\langle x,\Phi^*\Phi(x)\rangle=\langle x,x\rangle\]
\item[(3)$\iff$(4)] \checkmark
\item[(3)$\implies$(1)] Es gilt f√ºr alle $x,y,\in V,\alpha\in K:$
\begin{align*}
\langle\alpha x+y,\alpha x+y\rangle &= \langle\Phi(\alpha x+y),\Phi(\alpha x+y)\rangle\\
\iff\langle \alpha x,y\rangle +\langle y,\alpha x\rangle &= \langle\Phi(\alpha x),
\Phi(y)\rangle + \langle\Phi(y),\Phi(\alpha x)\rangle\\
\iff\alpha\langle x,y\rangle +\overline{\alpha}\overline{\langle x,y\rangle} &=
\alpha\langle\Phi(x),\Phi(y)\rangle + \overline{\alpha}\overline{\langle\Phi(x),\Phi(y)\rangle}
\end{align*}
\textbf{Fall $K=\mathbb{R}$:}\\ 
Mit $\alpha:=\frac12:\langle x,y\rangle =\langle\Phi(x),\Phi(y)\rangle$\\
\textbf{Fall $K=\mathbb{C}$:}\\ 
Mit $\alpha:=\frac12:\Real\langle x,y\rangle =\Real\langle\Phi(x),\Phi(y)\rangle$\\
Mit $\alpha:=\frac i2:\Imag\langle x,y\rangle =\Imag\langle\Phi(x),\Phi(y)\rangle$
\end{enumerate}
\end{proof}

\begin{corollary}
Sei $\dim(V)=n<\infty$, $B$ ONB von $V$ und $\Phi\in\End(V)$.\\
Folgende Aussagen sind √§quivalent:
\begin{enumerate}
\item $\Phi$ ist Isometrie.
\item Es gilt f√ºr alle $x\in V:\|\Phi(x)\|=\|x\|$
\item $\Phi(B)$ ist ONB.
\item Es gilt $D_{BB}(\Phi)^{-1} = D_{BB}(\Phi^*)$, d.h. $D_{BB}(\Phi)$ ist unit√§r bzw. orthogonal.
\item Die Spalten (bzw. Zeilen) von $D_{BB}(\Phi)$ bilden eine ONB von $\mathbb{K}^n$ bzgl.
dem Standard-SKP.
\item Es existiert eine ONB $C$ von $V$ mit $D_{BC}(\Phi)=I_n$.
\end{enumerate}
\end{corollary}

\begin{proof}
Jede der Aussagen impliziert $\Phi\in\Aut(V)$.\\
Sei $B:=\{b_1,\ldots,b_n\}$.
\begin{enumerate}
\item[(1)$\iff$(2)$\iff$(4)] Klar nach Isometriekriterium.
\item[(4)$\iff$(5)]Es gilt:
\begin{align*}
&D_{BB}(\Phi)^{-1} = D_{BB}(\Phi^*)\\
&	\implies D_{BB}(\Phi)\cdot D_{BB}(\Phi^*) = I_n\\
&\iff\{\text{Zeilen von }\Phi\}\text{ sind ONB bezgl. Standardform}\\
&\implies D_{BB}(\Phi^*)\cdot D_{BB}(\Phi) = I_n\\
&\iff\{\text{Spalten von }\Phi\}\text{ sind ONB bezgl. Standardform}
\end{align*}
\item[(3)$\implies$(2)]Da f√ºr alle $b_i,b_j\in B$ gilt:
\[\langle\Phi(b_i),\Phi(b_j)\rangle =\delta_{ij}=\langle b_i,b_j\rangle\]
Folgt f√ºr alle $x=\sum_{i=1}^n{\alpha_i b_i}\in V:$
\begin{align*}
\langle\Phi(x),\Phi(x)\rangle
&=\sum_{i,j}{\alpha_i\overline{\alpha_j}\langle\Phi(b_i),\Phi(b_j)\rangle}\\
&=\sum_{i,j}{\alpha_i\overline{\alpha_j}\langle b_i,b_j\rangle}\\
&=\langle x,x\rangle
\end{align*}
Also ist $\|\Phi(x)\|=\|x\|$ und $\Phi$ l√§ngenerhaltend.
\item[(1)$\implies$(3)] Da $\Phi$ Isometrie ist, gilt:
\[\implies \langle\Phi(b_i),\Phi(b_j)\rangle=\langle b_i,b_j\rangle =\delta_{ij}\]
D.h. $\Phi(B)$ ist ONB.
\item[(3)$\implies$(6)] Es existiert eine ONB $C=\{c_1,\ldots,c_n\}$, sodass gilt:
\[D_{BC}(\Phi) = I_n\]
Daraus folgt: $D_{BB}(\Phi)=D_{BC}(\Phi)\cdot M_{CB}=M_{CB}=:(\gamma_{ij})$\\
Also gilt f√ºr alle $b_j\in B$:
\[b_j=\sum_k{\gamma_{kj}\cdot c_k}\]
Daraus folgt:
\begin{align*}
\delta_{ij}&=\langle b_j,b_i\rangle\\
&=\langle\sum_k{\gamma_{kj}\cdot c_k},\sum_l{\gamma_{li}\cdot c_l}\rangle\\
&=\sum_{k,l}{\gamma_{kj}\cdot\overline{\gamma_{li}}\cdot\langle c_k,c_l\rangle}\\
&=\sum_k{\gamma_{kj}\cdot\overline{\gamma_{ki}}}\\
&=\sum_k{\overline{\gamma_{ki}}\cdot\gamma_{kj}}-(\overline{M}_{CB}^T\cdot M_{CB})_{ij}
\end{align*}
Es gilt also $M_{CB}^* = M_{CB}^{-1}$.
\end{enumerate}
\end{proof}

\section{Normalformen f√ºr Isometrien und normale Endomorphismen}
Sei $V$ VRm mit SKP $\langle\cdot,\cdot\rangle, \dim(V)=n<\infty$.

\subsection{Fall $\mathbb{K}=\mathbb{C}$}
\begin{lemma}
Ein Endomorphismus $\Phi$ ist genau dann unit√§r, wenn er normal ist und alle Eigenwerte 
Betrag 1 haben.
\end{lemma}

\begin{proof}
Da $\Phi$ unit√§r ist, also $\Phi^*=\Phi^{-1}$ gilt, ist $\Phi$ normal. 
Nach Spektralsatz existiert dann eine ONB $B=\{b_1,\ldots,b_n\}$ aus Eigenvektoren von $\Phi$.
Also gilt: 
\[\Phi(b_i)=\lambda_i b_i \text{ mit } \lambda_i\in\mathbb{C}\]
Mit dem Korollar folgt:\\
\begin{align*}
&\Phi \text{ unit√§r}\\
&\iff \Phi(B) \text{ ONB}\\
&\iff \delta_{ij}=\langle\Phi(b_i),\Phi(b_j)\rangle=\langle\lambda_i b_i,\lambda_j b_j\rangle
=|\lambda_i|^2\cdot\delta_{ij}\\
&\iff |\lambda_i|^2=1\\
&\iff |\lambda_i|=1
\end{align*}
\end{proof}

\begin{conclusion}
\index{Normalform}
$D_{BB}(\Phi)=\diag(\lambda_1,\ldots,\lambda_n)$ mit $|\lambda_i|=1$ hei√üt \textbf{Normalform}
der unit√§ren Abb. $\Phi$ und ist bis auf die Reihenfolge der Eigenwerte eindeutig bestimmt.
\end{conclusion}

\begin{corollary}
\index{unit√§r!Basiswechsel}\index{Basiswechsel!unit√§rer}
Ist $A\in\mathbb{C}^{n\times n}$ normal, so existieren $M\in U_n$ und $\lambda_i\in\mathbb{C}$,
sodass gilt:
\begin{align*}
M^{-1}\cdot A\cdot M = \diag(\lambda_1,\ldots,\lambda_n)
\end{align*}
D.h. jedes normale $A$ erlangt durch \textbf{unit√§ren Basiswechsel} Normalform.\\
Falls $A$ unit√§r ist, so existiert $\Phi_j\in\mathbb{R}$, sodass gilt:
\begin{align*}
\lambda_j=e^{i\Phi_j}=\cos\Phi_j+i\sin\Phi_j
\end{align*}
\end{corollary}


\chapter{Affine R√§ume}

Man m√∂chte vom Anschauungsraum $\mathbb{R}^3$ abstrahieren:\\
\begin{itemize}
\item statt $\mathbb{R}$ \textbf{beliebige} K√∂rper $K$
\item statt Dimension $3$ \textbf{beliebige} Dimensionen $< \infty$
\end{itemize}

\begin{task}
Finde die "`richtige"' Verallgemeinerung der vertrauten \textbf{geometrischen} 
Begriffe, sodass bekannte geometrische S√§tze richtig bleiben.
\end{task}

Im Folgenden sei $K$ stets ein beliebiger K√∂rper.

\section{Grunbegriffe}
\begin{definition}
\index{affin!Raum}\index{Raum!affiner}
\index{Richtungsvektorraum}
\index{Translation}
\index{Punkt}
\index{Translationsvektor}
Sei $V$ $K$-VRm mit $\dim(V)=n<\infty$.
\begin{enumerate}[(a)]
\item Eine Menge $A \ne \emptyset$ hei√üt \textbf{affiner Raum mit Richtungsvektorraum $V$},
falls $(V,+)$ auf $A$ operiert, d.h. es existiert eine Paarung "`$+$"' genannt
\textbf{Translation} $V \times A \to A$, $(x,P) \mapsto x+P$, mit der Eigentschaft:
\[\forall P,Q\in A\exists_1 x\in V: Q=x+P\]
\item Elemente von $A$ hei√üen \textbf{Punkte}.\\
Der zu gegebenen Punkten $P$, $Q$ eindeutig bestimmte Vektor $x$ mit $Q=x+P$ hei√üt
der \textbf{Translationsvektor von $P$ nach $Q$}.\\
Schreibe: $x:=\overrightarrow{PQ}$
\item $\dim(A) := \dim(V)$ hei√üt \textbf{Dimension von $A$}.
\end{enumerate}
\end{definition}

\begin{comment}
\begin{enumerate}
\item Vorsicht in (1) wird das Zeichen "`+"' f√ºr verschiedene Verkn√ºpfungen benutzt.
\item Es gilt f√ºr $P,Q,R,\in A:$
\begin{align*}
\overrightarrow{PP}&=0\\
\overrightarrow{PQ}+\overrightarrow{QR} &= \overrightarrow{PR}\\
\overrightarrow{QP}&=-\overrightarrow{PQ}
\end{align*} 
\item $A$ besteht aus genau einer Bahn:
\[\forall P\in A: A=V+P:=\{x+P\mid x\in V\}\]
\end{enumerate}
\end{comment}

\begin{example}
\index{affin!Standardraum}\index{Standardraum!affiner}
Der \textbf{affine Standardraum} $\mathbb{A}_n(K)$ ist definiert als  Punktmenge
$\mathbb{A}:=K^n$ und $V:=K^n$, mit Translation $:=$ Addition in $K^n$, d.h.
f√ºr $P,Q\in K^n$ gilt:
\[\overrightarrow{PQ}=Q-P\]
\end{example}

\begin{definition}
\index{affin!Teilraum}\index{Teilraum!affiner}
\index{linear!Variet√§t}\index{Variet√§t!lineare}
\index{Gerade}
\index{Ebene}
\index{Hyperebene}
Eine Teilmenge $B \ne \emptyset$ eines affinen Raumes A hei√üt \textbf{(affiner) Teilraum}
oder \textbf{lineare Variet√§t} von $A$, falls ein VRm $U_B \le V$ existiert, sodass
$B$ affiner Raum ist, mit Richtungsvektorraum $U_B$ (unter der in $A$ gegebenen
Operation).\\
Auch $B = \emptyset$ werde affiner Teilraum genannt.\\
Spezielle affine Teilr√§ume B sind:
\begin{enumerate}[(a)]
\item \textbf{Gerade} $\iff \dim(B) = 1$
\item \textbf{Ebene} $\iff \dim(B) = 2$
\item \textbf{Hyperebene} $\iff \dim(B) = \dim(A)-1$
\end{enumerate}
\end{definition}

\begin{lemma}
\index{Verbindungsgerade}
\begin{enumerate}
\item Ist $B\ne \emptyset$ affiner Teilraum, dann gilt:
\[U_B=\{\overrightarrow{PQ}\mid P,Q\in B\}\]
\item Sind $\emptyset\ne B \subseteq C$ affine Teilr√§ume und $\dim(B)=\dim(C)$, dann ist $B=C$.
\item Durch zwei Punkte $P\ne Q$ in $A$ geht genau eine Gerade.
\[PQ := K \cdot \overrightarrow{PQ}+P = \{\lambda \cdot \overrightarrow{PQ}+P\mid\lambda\in K\}\le A\]
Diese wird die \textbf{Verbindungsgerade} von $P$ und $Q$ genannt.
\item Drei Punkte $P,Q,R \in A$ liegen genau dann auf \textbf{einer} Geraden, wenn gilt,
dass $\overrightarrow{PQ}$ und $\overrightarrow{QR}$ linear abh√§ngig sind.
\end{enumerate}
\end{lemma}

\begin{proof}
\begin{enumerate}
\item 
\begin{enumerate}
\item["`$\supseteq$"']\checkmark
\item["`$\subseteq$"'] Da $B$ affiner Teilraum mit Richtung $U_B$ ist, gilt f√ºr alle $P,Q\in B$:
\[\exists_1 x\in B: x=\overrightarrow{PQ} \iff x+P = Q\]
\end{enumerate}
\item Aus (1) folgt mit $B\subseteq C$, dass $U_B\subseteq U_C$ gilt. Da diese die
gleiche Dimension haben muss dann schon $U_B=U_C$ gelten. F√ºr $P\in B\cap C$ gilt dann:
\[B=U_B+P=U_C+P=C\]
\item Es ist klar, dass $P$ und $Q$ auf der Geraden $PQ$ liegen, daher muss lediglich die
Eindeutigkeit gezeigt werden.\\
Sei $B$ eine Gerade mit $P,Q\in B$ und $U:=U_B$. Da $P\ne Q$ ist, 
ist $\overrightarrow{PQ}\in U$ nicht der Nullvektor. Da au√üerdem $\dim U=1$ ist, gilt:
\[U=K\cdot\overrightarrow{PQ}\]
Daraus folgt:
\[B=U+P=PQ\]
\item Sei $x:=\overrightarrow{PQ}$ und $y:=\overrightarrow{QR}$. Es existiert genau dann
eine Gerade $B$ mit $P,Q,R\in B$, wenn gilt:
\[\exists\text{ VRm }U: \dim U=1, x,y\in U\]
Also genau dann, wenn $x$ und $y$ linear abh√§ngig sind.
\end{enumerate}
\end{proof}

\begin{theo}[Teilraumkriterium]
Sei $A$ affiner Raum mit Richtung $V$ und sei $\emptyset \ne B\subseteq A$. Dann 
sind equivalent:
\begin{enumerate}
\item $B$ ist affiner Teilraum.
\item Es existieren $P\in A$ und $U\le V$, sodass gilt:
\[B=U+P\]
\item Falls $|K| >2$, so ist auch equivalent:
\[\forall P,Q\in B: P\ne Q \implies PQ \subseteq B\]
\item Falls $A=\mathbb{A}_n(K)$, so ist auch equivalent, dass $B$ L√∂sungsmenge eines LGS ist.
\end{enumerate}
\end{theo}

\begin{proof}
Die √Ñquivalenz ergibt sich aus folgendem Ringschluss:
\begin{itemize}
\item[(1)$\implies$(2)] Ist $B$ affiner Teilraum, so gilt:
\[\exists U\le V:\forall P\in U:B=U+P\]
\item[(2)$\implies$(1)] $B=U+P$ ist affiner Teilraum, denn $U$ operiert auf $B$
und f√ºr $Q,R\in B:$ gilt:
\[\exists x,y\in U: Q=x+P,R=y+P \text{ und}\] 
\[\exists_1 \text{ Translation } \overrightarrow{QR}=y-x\in U\]
Daraus folgt, dass $U$ affiner Teilraum ist.
\item[(1)$\implies$(3)] Sei $B$ affiner Teilraum mit $P,Q\in B, P\ne Q$. Dann gilt:
\begin{align*}
&\overrightarrow{PQ}\in U_B\\
&\implies\forall \lambda\in K:\lambda\cdot\overrightarrow{PQ}+P\in B\\
&\implies PQ\subseteq B
\end{align*}
\item[(3)$\implies$(2)] Setze $U:=\{\overrightarrow{PQ}\mid P,Q\in B\}\subseteq V$.\\
\textbf{Zeige zun√§chst:} F√ºr alle $P\in B$ gilt:
\[U+P\subseteq B\] 
D.h. f√ºr alle $y\in U$ gilt:
\[y+P\in B\]
\begin{enumerate}
\item["`$\subseteq$"'] Sei also $0\ne y\in U$, dann existiert ein $Q\ne R\in B$, sodass gilt: 
\[ y=\overrightarrow{QR}\] 
Setze $z:=\overrightarrow{PQ}$.\\
\textbf{Fall $y,z$ linear abh√§ngig:}\\
Aus dem Lemma folgt, dass $P,Q,R$ auf der Geraden $QR=\{\lambda\cdot y+P\mid \lambda\in K\}
\stackrel{(3)}{\subseteq} B$ liegen. Insbesondere gilt: 
\[y+P\in B\]
\textbf{Fall $y,z$ linear unabh√§ngig:}\\
W√§hle $\lambda\in K\setminus\{0,1\}$. Betrachte $S:=\frac{\lambda}{\lambda-1}y+P$, 
$N:=\lambda z+P$.\\
Dann ist $N\in PQ\subseteq B$.\\
Annahme: $N=R$.
Dann gilt:
\begin{align*}
N&=\lambda z+p\\
&=R\\
&=y+z+P
\end{align*}
Daraus folgt, dass $y$ und $z$ linear abh√§ngig sind. $\lightning$
Es gilt also $N\ne R$. Ferner gilt, dass $S,N,R$ auf einer Geraden liegen, denn:
\[\overrightarrow{NR} = y+z-\lambda z = y+(1-\lambda)z \text{ und}\]
\[\overrightarrow{SN} = \lambda z-\frac{\lambda}{1-\lambda}y=\frac{\lambda}{\lambda-1}
((\lambda-1)z-y)\]
sind linear abh√§ngig.\\
Aus $N,R\in B$ folgt:
\[S\in NR \stackrel{(3)}{\subseteq}B\]
Au√üerdem gilt: $S\ne P$, also $SP\in B$ und damit $y+P\in B$\\
Es gilt sogar: $B=U+P$, da f√ºr alle $Q\in B$ gilt:
\[Q=\overrightarrow{PQ}+P\in U+P\]
\item["`$\supseteq$"'] \checkmark
\end{enumerate}
\textbf{Es bleibt zu zeigen:} $U\le V$ (Untervektorraum)\\
Seien $x,y\in U,\alpha\in K$. O.B.d.A l√§sst sich $x\ne 0$ annehmen, etwa $x=\overrightarrow{PQ},
P,Q\in B$. Dann gilt:\\
\[\alpha x+P\in PQ \subseteq B \implies \alpha x\in U\]
Also gen√ºgt es zu zeigen, dass $x+y$ in $U$ liegt. Sei $P':=x+P$.\\
Dann gilt mit $x=\overrightarrow{PQ}$ und $y+P\in U+P\subseteq B$:\\
\begin{align*}
&(x+y)+P=x+(y+P)\in U+P'\subseteq B\\
&\implies x+y\in U
\end{align*}
\end{itemize}
\end{proof}

\section{Eigentschaften affiner R√§ume}
\begin{lemma}
Sei $I\ne\emptyset$ Indexmenge und $(B_i)_{i\in I}$ eine Familie affiner Teilr√§ume von $A$.\\
Dann ist $B:= \bigcap_{i\in I} B_i$ affiner Teilraum von $A$ mit Richtung
$U_B=\bigcap_{i\in I} U_{B_i}$, falls $B\ne\emptyset$.
\end{lemma}

\begin{proof}
Sei $B\ne\emptyset$, dann existiert ein $P\in\bigcap_{i\in I}B_i$.
Setze $U:=\bigcap_{i\in I}U_{B_i} \le V$.\\
Dann gilt f√ºr ein $Q\in A$:\\
\begin{align*}
Q\in U+P &\iff \forall i\in I: Q\in U_{B_i}+P\\
&\iff Q\in\bigcap_{i\in I}B_i\\
&\iff Q\in B
\end{align*}
Daraus folgt: $B=U+P$
\end{proof}

\begin{definition}
\index{affin!H√ºlle}\index{H√ºlle!affine}
Sei $M$ Teilmenge von $A$, $C$ die Menge aller affinen Teilr√§ume von $A$, die $M$ enthalten.\\
Dann hei√üt:
\[[M]:=\bigcap_{B\in C}B\]
die \textbf{affine H√ºlle} von $M$.\\
F√ºr $M=\{P_1,\ldots,P_m\}$ schreibe: $[P_1,\ldots,P_m]:=[M]$.
\end{definition}

\begin{example}
Sei $P\ne Q$, dann ist $[P,Q]=PQ$ die Gerade durch $P$ und $Q$.
\end{example}

\begin{lemma}
\index{allgemein!Lage}\index{Lage!allgemeine}
Seien $P_0,\ldots,P_m\in A$ und sei $x_i:=\overrightarrow{P_0P_i}\in V$ f√ºr alle $i\in\{1,\ldots,m\}$.\\
Dann gilt:
\[[P_0,\ldots ,P_m]=\langle x_1,\ldots ,x_m \rangle +P_0\]
Insbesondere ist $\dim{[P_0,\ldots,P_m]}\le m$.\\
Falls gilt: $\dim{[P_0,\ldots,P_m]}=m$ sagt man, $P_0,\ldots,P_m$ sind in \textbf{allgemeiner Lage}.
\end{lemma}

\begin{proof}
\begin{enumerate}
\item["`$\subseteq$"'] F√ºr alle $i\in\{1,\ldots,m\}$ gilt:
\[P_i=x_i+P_0\subseteq\langle x_1,\ldots,x_m\rangle+P_0\]
\item["`$\supseteq$"'] Sei $\sum_{i=1}^m{\alpha_i x_i+P_0}\in\langle x_1,\ldots,x_m\rangle+P_0$,
und sei $B\supseteq\{P_0,\ldots,P_m\}$ beliebiger affiner Teilraum. Dann gilt:
\begin{align*}
&\forall i\in\{1,\ldots,m\}: x_i=\overrightarrow{P_0P_i}\in U_B\\
&\implies \sum_{i=1}^m{\alpha_i x_i}\in U_B\\
&\implies \sum_{i=1}^m{\alpha_i x_i+P_0}\in U_B+P_0=B
\end{align*}
Da dies f√ºr einen beliebigen affinen Teilraum $B$ gilt, der $\{P_0,\ldots,P_m\}$ enth√§lt, gilt dies f√ºr alle
solche Teilr√§ume. Sei $C$ die Menge aller affinen Teilr√§ume die $\{P_0,\ldots,P_m\}$ enthalten. Dann folgt:
\begin{align*}
&\forall B\in C: \sum_{i=1}^m{\alpha_i x_i+P_0}\in B\\ 
&\iff \sum_{i=1}^m{\alpha_i x_i+P_0}\in\bigcap_{B\in C}B\\
&\iff \sum_{i=1}^m{\alpha_i x_i+P_0}\in[P_0,\ldots,P_m]
\end{align*}
\end{enumerate}
\end{proof}

\begin{theo}
Seien $A_1:=U_1+P_1,A_2:=U_2+P_2$ affine Teilr√§ume von A. Dann gilt:
\begin{enumerate}
\item $U_{[A_1\cup A_2]}=U_1+U_2+\langle\overrightarrow{P_1P_2}\rangle$
\item $A_1\cap A_2\ne\emptyset \implies \dim([A_1\cup A_2])=\dim{A_1}+\dim{A_2}-\dim{(A_1\cap A_2)}\\
A_1\cap A_2=\emptyset \implies \dim([A_1\cup A_2])=\dim{A_1}+\dim{A_2}-\dim{(U_1\cap U_2)}+1$
\end{enumerate}
\end{theo}

\begin{proof}
\begin{enumerate}
\item Sei $y:=\overrightarrow{P_1P_2}$ und $U:=U_1+U_2+\langle y\rangle$.\\
\textbf{Zu Zeigen:} $U+P_1=[A_1\cup A_2]$, d.h. $U_{[A_1\cup A_2]}=U$
\begin{enumerate}
\item["`$\subseteq$"'] F√ºr einen beliebigen affinen Raum $B\supseteq A_1\cup A_2$ gilt: $U_B\ge U_1,U_2,
\langle y\rangle$.\\
Also gilt f√ºr $x=x_1+x_2+\alpha y\in U$ mit $x_1\in U_1, x_2\in U_2$:
\begin{align*}
&x=x_1+x_2+\alpha y\in U_B\\
&\implies x+P_1\in U_B+P_1=B\\
&\implies x+P_1\in \bigcap B=[A_1\cup A_2]
\end{align*}
\item["`$\supseteq$"'] \textbf{Zu zeigen:} $A_1\cup A_2\subseteq U+P_1$\\
\begin{align*}
A_1&=U_1+P_1\subseteq U+P_1\\
A_2&=U_2+P_2=U_2+y+P_1\subseteq U+P_1
\end{align*}
\end{enumerate}
\item 
\textbf{Fall $A_1\cap A_2\ne\emptyset$:} Nach Lemma gilt $U_{A_1\cap A_2}=U_1\cap U_2$,
und dass $P_1=P_2$ w√§hlbar ist.\\ 
Daraus folgt $U=U_1+U_2$ (mit $y=0$). Also gilt: $[A_1\cup A_2]=U_1+U_2+P_1$ mit:
\begin{align*}
\dim{[A_1+A_2]}&=\dim{(U_1+U_2)}\\
&=\dim{U_1}+\dim{U_2}-\dim{(U_1\cap U_2)}\\
&=\dim{A_1}+\dim{A_2}-\dim{(A_1\cap A_2)}
\end{align*}
\textbf{Fall $A_1\cap A_2=\emptyset$}: Annahme: $y\in U_1+U_2$.\\
Dann ist $y=x_1+x_2$ f√ºr ein $x_1\in U_1,x_2\in U_2$. Daraus folgt:
\[x_1+P_1 = -x_2+y+P_1=-x_2+P_2\in A_1\cap A_2\ \lightning\]
Also ist $y\notin U_1+U_2$. Daraus folgt:
\[\dim{U}=\dim{(U_1+U_2)}+1\]
Der restliche Beweis erfolgt analog zum ersten Fall.
\end{enumerate}
\end{proof}

\begin{definition}
\index{Parallelit√§t}
Affine Teilr√§ume $B,C$ von $A$ hei√üen \textbf{parallel}, wenn gilt:
\[U_B\le U_C \text{ oder }U_C\le U_B\]
Schreibe: $B\parallel C$.
\end{definition}

\begin{example}
Man denke nicht nur an parallele Geraden oder Ebenen, sondern etwa auch an Gerade $\parallel$ Ebene.
\end{example}

\begin{comment}
\begin{enumerate}
\item Auf den Teilr√§umen einer festen Dimension ist Parallelit√§t eine √Ñquivalenzrelation.
\item Aus $B\parallel C$ folgt: $(B\subseteq C) \vee (B\supseteq C) \vee (B\cap C=\emptyset)$
\item F√ºr alle $P\in A$ und alle affinen Teilr√§ume $B\ne\emptyset$ existiert genau ein affiner Teilraum
$C$ mit:
\begin{enumerate}[(a)]
\item $P\in C$
\item $B\parallel C$
\item $\dim{C}=\dim{B}$
\end{enumerate}
\end{enumerate}
\end{comment}

\begin{proof}
\begin{enumerate}
\item Leichte √úbung!
\item Sei $P\in B\cap C$ und o.B.d.A $U_B\le U_C$. Dann gilt:
\[B=U_B+P\le U_C+P=C\]
\item Es muss $C=U_B+P$ gelten, da aus b) und c) folgt: $U_C=U_B$
\end{enumerate}
\end{proof}

\begin{theo}
Sei $A$ affiner Raum mit $\dim{A}=n>1$, $G\subseteq A$ Gerade und $H$ Hyperebene in $A$.\\
Dann gilt:
\begin{enumerate}
\item $G\cap H=\emptyset \implies G\parallel H$
\item $G\not\parallel H \implies \exists P: G\cap H=\{P\}$
\end{enumerate}
\end{theo}

\begin{comment}
$\dim{G\cap H}\le\dim{G}=1 \implies G\cap H=\begin{cases}
\emptyset\\
\text{Punkt}\\
\text{Gerade}
\end{cases}$
\end{comment}

\begin{proof}
\begin{enumerate}
\item Sei $G\cap H=\emptyset$, dann ist $G\cup H$ echte Obermenge von $H$. Es gilt also:
\[H \subsetneq G\cup H \subseteq [G\cup H]\]
Daraus folgt f√ºr die Dimensionen:
\begin{align*}
&n-1=\dim H < dim[G\cup H]\le n\\
&\implies \dim[G\cup H]=n\\
&\implies [G\cup H]=A
\end{align*}
Aus der Dimensionsformel f√ºr die affine H√ºlle folgt:
\begin{align*}
n&=\dim[G\cup H]\\
&= \dim G+\dim H -\dim(U_G\cap U_H)+1\\
&= n-\dim(U_G\cap U_H)+1
\end{align*}
Daraus folgt:
\begin{align*}
&\dim(U_G\cap U_H)=1=\dim U_G\\
&\implies U_G\cap U_H = U_G\\
&\implies U_G \subseteq U_H\\
&\implies G\parallel H
\end{align*}
\item Aus (1) folgt, dass $G\cap H$ nicht die leere Menge ist, wenn $G$ und $H$ nicht
parallel sind.\\
Sei nun $G':=G\cap H$ eine Gerade. Dann gilt:
\begin{align*}
&G'\subseteq G\\
&\implies G'=G\\
&\implies G\subseteq H\\
&\implies G\parallel H
\end{align*}
Also kann $G\cap H$ auch keine Gerade sein, wenn $G$ und $H$ nicht parallel sind. Mit der
Vorbemerkung folgt daraus, dass $G\cap H$ ein Punkt sein muss.
\end{enumerate}
\end{proof}

\chapter{Affine Koordinaten und affine Abbildungen}
\section{Grundbegriffe}
\begin{definition}
\index{affin!Koordinatensystem}\index{Koordinatensystem!affines}
\index{Ursprung}
\index{Koordinatenvektor}
\index{Koordinatendarstellung}
Sei $A$ ein affiner Raum mit Richtungs-VRm V der Dimension n.
\begin{enumerate}[(a)]
\item Sei $\mathcal{B}$ die Menge aller Basen von V. Ein Paar $\mathcal{K}:=(\mathcal{O},B)
\in A\times\mathcal{B}$ hei√üt \textbf{affines Koordinatensystem}, wobei $\mathcal{O}$ der
\textbf{Ursprung} hei√üt.
\item  Durch die Koordinatendarstellung $D_B:V\to K^n$ zur Basis $B$ definiert:
\[D_\mathcal{K}:A\to K^n,P\mapsto D_B(\overrightarrow{\mathcal{O}P})\]
den \textbf{Koordinatenvektor} $D_\mathcal{K}(P)$ von P bez√ºglich $\mathcal{O}$.
\item Die Abbildung $D_\mathcal{K}:A\to\mathbb{A}^n(K)$ hei√üt \textbf{Koordinatendarstellung}
zum Koordinatensystem $\mathcal{K}$.
\end{enumerate}
\end{definition}

\begin{task}
Was entspricht Homomorphismen von VRmen bei affinen R√§umen?
\end{task}

\begin{definition}
\index{affin!Abbildung}\index{Abbildung!affine}
\index{Morphismus!affiner R√§ume}
Seien $A,B$ affine R√§ume mit Richtungen $V,W$.
Eine Abbildung $\varphi:A\to B$ hei√üt \textbf{affine Abbildung} oder \textbf{Morphismus affiner R√§ume},
falls ein $\Phi\in\Hom(V,W)$ existiert, sodass gilt:
\[\forall x\in V,\forall P\in A: \varphi(x+P)=\Phi(x)+\varphi(P)\]
Schreibe: $\Homaff(A,B):=\{\varphi:A\to B\mid\varphi$ affin $\}$.
\end{definition}

\begin{example}
\begin{enumerate}
\item  Die Identit√§t $\id_A:A\to A$ ist affin mit zugeh√∂rigem $\Phi=\id_V$.
\item F√ºr \textbf{festes} $Q\in B$ ist die konstante Abbildung $\varphi_Q:A\to B,
P\mapsto Q$ affin, mit der Nullabbildung als zugeh√∂rigem Homomorphismus.
\end{enumerate}
\end{example}

\begin{comment}
\begin{enumerate}
\item $\varphi:A\to B$ mit zugeh√∂rigem $\Phi\in\Hom(V,W)$ ist genau dann affin, wenn gilt:
\[\exists P_0\in A:\forall x\in V: \varphi(x+P_0)=\Phi(x)+\varphi(P_0)\]
\item Ist $\varphi\in\Homaff(A,B)$, so ist der zugeh√∂rige Homomorphismus \mbox{$\Phi=:\Lambda_\varphi$}
eindeutig bestimmt.
\item Die Hintereinanderausf√ºhrung affiner Abbildungen ist affin, d.h.:
\[\Homaff(A,B)\times\Homaff(B,C)\to \Homaff(A,C), (\varphi,\psi)\mapsto\psi\circ\varphi\]
\item $\varphi\in\Homaff(A,B)$ ist genau dann injektiv (bzw. surjektiv), wenn $\Lambda_\varphi$
injektiv (bzw. surjektiv) ist.
\item Ist $\varphi\in\Homaff(A,B)$ bijektiv, so existiert $\varphi^{-1}\in\Homaff(B,A)$.
\end{enumerate}
\end{comment}

\begin{definition}
\index{Isomorphismus!affiner R√§ume}
\index{Affinit√§t}
\index{affin!Automorphismus}\index{Automorphismus!affiner}
\index{affin!Gruppe}\index{Gruppe!affine}
Ein bijektives $\varphi\in\Homaff(A,B)$ hei√üt \textbf{Isomorphismus affiner R√§ume} oder \textbf{Affinit√§t}.\\
Ist zus√§tzlich $A=B$, so hei√üt $\varphi\in\Homaff(A,A)$ \textbf{Automorphismus}. Diese Automorphismen
bilden die Gruppe $\Autaff(A)$, genannt die \textbf{affine Gruppe} von $A$.
\end{definition}

\begin{proof}
\begin{enumerate}
\item Sei $P\in A$ beliebig und $y:=\overrightarrow{P_0P}$. Dann gilt f√ºr alle $x\in V$:
\begin{align*}
\varphi(x+P) &= \varphi(x+y+P_0)\\
&= \Phi(x+y)+\varphi(P_0)\\
&= \Phi(x)+\Phi(y)+\varphi(P_0)\\
&= \Phi(x)+\varphi(y+P_0)\\
&= \Phi(x)+\varphi(P)
\end{align*}
\item Sei $\varphi\in\Homaff(A,B)$ gegeben, dann gilt f√ºr alle $P\in A,x\in V$:
\begin{align*}
&\varphi(x+P)=\Phi(x)+\varphi(P)\\
&\implies \Phi(x)=\overrightarrow{\varphi(P)\varphi(x+P)}
\end{align*}
Also ist $\Phi$ durch $\varphi$ eindeutig bestimmt.
\item Sei $\varphi\in\Homaff(A,B)$, $\psi\in\Homaff(B,C)$. Dann gilt f√ºr alle $P\in A,x\in V$:
\begin{align*}
\psi\circ\varphi(x+P) &= \psi(\varphi(x+P))\\
&= \psi(\Lambda_\varphi(x)+\varphi(P))\\
&= \Lambda_\psi(\Lambda_\varphi(x))+\psi(\varphi(P))\\
&= \Lambda_\psi\circ\Lambda_\varphi(x)+\psi\circ\varphi(P)
\end{align*}
Also ist $\psi\circ\varphi$ affin mit zugeh√∂rigem Homomorphismus $\Lambda_{\psi\circ\varphi}=
\Lambda_\psi\circ\Lambda_\varphi$.
\item Es gilt f√ºr $\varphi\in\Homaff(A,B)$:
\begin{align*}
\varphi \text{ injektiv }&\iff (\varphi(P)=\varphi(Q) \implies P=Q)\\
&\iff (\varphi(\overrightarrow{QP}+Q)=\varphi(Q) \implies P=Q)\\
&\iff (\Lambda_\varphi(\overrightarrow{QP})+\varphi(Q)=\varphi(Q) \implies P=Q)\\
&\iff (\Lambda_\varphi(\overrightarrow{QP})=0 \implies \overrightarrow{QP}=0)\\
&\iff \Lambda_\varphi \text{ ist injektiv}
\end{align*}
Der Beweis f√ºr Surjektivit√§t erfolgt analog.
\item Leichte √úbung!
\end{enumerate}
\end{proof}

\begin{theo}
Seien $A,B$ affine Teilr√§ume mit Richtungen $V,W$.
Zu $(P_0,Q_0)\in A\times B$ und $\Phi\in\Hom(V,W)$ existiert genau eine affine Abbildung
$\varphi:A\to B$ mit $\Lambda_\varphi=\Phi$ und $\varphi(P_0)=Q_0$.
\end{theo}

\begin{proof}
Es ist $A=V+P_0$. Definiere $\varphi(x+P_0):=\Phi(x)+Q_0$, so ergibt sich nach Bemerkung (1)
eine affine Abbildung mit $\varphi(P_0)=Q_0$. Dies legt $\varphi$ bereits eindeutig fest.
\end{proof}

\begin{theo}
Die Koordinatenabbildung $D_\mathcal{K}:A\to\mathbb{A}^n(K)$ zu einem Koordinatensystem 
$\mathcal{K}=(\mathcal{O},B)$ ist ein affiner Isomorphismus (mit zugeh√∂riger linearer Abbildung
$D_B:V\to K^n$).
\end{theo}

\begin{proof}
Es gilt:
\begin{align*}
D_\mathcal{K}(x+\mathcal{O})&\stackrel{Def.}{=} D_B(x)\\
&= D_B(x)+0\\
&= D_B(x)+D_\mathcal{K}(\mathcal{O})
\end{align*}
Nach dem letzten Satz existiert genau eine affine Abbildung, die dies tut.
Dass es sich bei $D_\mathcal{K}$ um eine Isometrie handelt, wurde bereits fr√ºher eingesehen,
da $D_B$ Isometrie ist.
\end{proof}

\begin{corollary}
Affine R√§ume √ºber festen K√∂rper sind genau dann isomorph, wenn ihre Dimension gleich ist.
\end{corollary}

\begin{theo}[Erhaltung von Teilr√§umen]
Sei $\varphi\in\Homaff(A,B)$ und $C\subseteq A$.
Falls $C$ affiner Teilraum  mit Richtung $U:=U_C$ ist, so ist $\varphi(C)\subseteq B$
affiner Teilraum mit Richtung $\Lambda_\varphi(U)$.\\
Ist $\varphi$ Isomorphismus, so gilt:
\begin{enumerate}
\item $C\subseteq A$ ist genau dann affiner Teilraum, wenn $\varphi(C)\subseteq B$ affiner Teilraum ist.
\item Es gilt $\dim C = \dim \varphi(C)$ f√ºr jeden affinen Teilraum $C$.
\item Sind $C,C'\subseteq A$ affine Teilr√§ume, so gilt:
\[\varphi([C\cup C'])=[\varphi(C)\cup\varphi(C')]\]
und:
\[\varphi(C\cap C')=\varphi(C)\cap\varphi(C')\]
\item $C\parallel C' \implies \varphi(C)\parallel\varphi(C')$
\end{enumerate}
\end{theo}

\begin{proof}
Sei $\varphi\in\Homaff(A,B), P\in C$ (d.h. $C=U+P$). Nach Teilraumkriterium gilt dann:
\[\varphi(C)=\Phi(U)+\varphi(P)\]
Daraus folgt, dass $\varphi(C)$ affiner Teilraum ist.
\begin{enumerate}
\item Leichte √úbung!
\item Leichte √úbung!
\item Sogar f√ºr beliebige Teilmengen $C,C'\subseteq A$ gilt, wenn $\varphi$ bijektiv ist:
\[\varphi(C\cap C')=\varphi(C)\cap\varphi(C')\]
F√ºr alle affinen Teilr√§ume $D$, die $C\cup C'$ enhalten, gilt:
\[\varphi(D)\supseteq\varphi(C)\cup\varphi(C')\]
Also gilt insbesondere auch f√ºr $D:=[C\cup C']$:
\[\varphi([C\cup C'])\supseteq\varphi(C)\cup\varphi(C')\]
Daraus folgt (f√ºr jede affine Abbildung, also insbesondere auch f√ºr $\varphi^{-1}$):
\[\varphi([C\cup C'])\supseteq[\varphi(C)\cup\varphi(C')]\]
Insgesamt folgt:
\begin{align*}
[C\cup C']&\supseteq\varphi^{-1}([\varphi(C)\cup\varphi(C')])\\
&\supseteq[\varphi^{-1}(\varphi(C))\cup\varphi^{-1}(\varphi(C'))]\\
&= [C\cup C']
\end{align*}
Daraus folgt die Gleichheit.
\item Leichte √úbung!
\end{enumerate}
\end{proof}

\subsection{Grundaufgaben im affinen Standardraum $\mathbb{A}_n(K)$}
Seien $P_0,\ldots,P_m,Q_0,\ldots,Q_s\in K^n$ und $B:=[P_0,\ldots,P_m], C:=Q_0,\ldots,Q_s$
gegeben. Ziel ist es $[B\cup C]$ und $B\cap C$ zu berechnen.\\

Mit $x_i:=\overrightarrow{P_0P_i}=P_i-P_0$ gilt:
\[B=\langle x_1,\ldots,x_m\rangle+P_0\]
Analog gilt mit $z_j:=\overrightarrow{Q_0Q_i}=Q_i-Q_0$:
\[C=\langle z_1,\ldots,z_s\rangle+Q_0\]
Daraus folgt dann mit $y:=\overrightarrow{P_0Q_0}$:
\[[B\cup C]=\langle x_1,\ldots,x_m,z_1,\ldots,z_s,y\rangle+P_0\]

\begin{enumerate}
\item Finde mit dem Gau√ü-Algorithmus eine Basis $\{b_1,\ldots,b_r\}$ von $U$, dann gilt:
\[[B\cup C]=[b_1+P_0,\ldots,b_r+P_0,P_0]\]
mit erzeugenden Punkten in allgemeiner Lage.
\item Interpretiere $B$ als L√∂sungsmenge $\mathcal{L}(A,b)$ eines LGS $Ax=b$.\\
Sei $x_0=P_0\in K^n$, dann liefert der Spezialfall $B=C$ in (1):
\[B=U+x_0\]
wobei ${b_1,\ldots,b_r}$ Basis von $U$ ist.\\
Ziel ist es nun, eine Matrix $A\in K^{n-r\times n}$ zu finden, mit $U=\Kern(\Lambda_A)$.
Dazu betrachte die Matrix:
\[M:=
\begin{pmatrix}
b_1&\cdots&b_r
\end{pmatrix}\]
Offensichtlich gilt $\rank(M)=r$.\\
Betrachte nun die Rechtsmultiplikation:
\[ P_M:K^n\to K^r,y\mapsto yM\]
Dann hat der Kern von $\rho_M$ Dimension $n-r$ und eine Basis aus Zeilenvektoren
$\{c_1,\ldots,c_{n-r}\}$. Damit l√§sst sich nun die Matrix $A$ wie folgt definieren:
\[A:=
\begin{pmatrix}
c_1\\
\vdots\\
c_{n-r}
\end{pmatrix}\]
Da der Rang von A offensichtlich $n-r$ ist, ist die Dimension des Kerns genau $r$, und es gilt:
\begin{align*}
&\forall t\in\{1,\ldots,n-r\}: c_tM=0\\
&\iff\forall t\in\{1,\ldots,n-r\},j\in\{1,\ldots,r\}: c_t\cdot b_j=0\\
&\iff\forall j\in\{1,\ldots,r\}: Ab_j=0
\end{align*}
Also ist $U$ Unterraum von $\Kern(\Lambda_A)$ und aus der Gleichheit der Dimensionen
beider R√§ume folgt dann:
\[B=\mathcal{L}(A,b)\]
\item Durchschnittsberechnung:\\
Finde mit Hilfe von (2) Matrizen $A,A'$ und $b,b'\in K^n$, sodass $B=\mathcal{L}(A,b),
C=\mathcal{L}(A',b')$ ist. Dann gilt:
\[B\cap C = \mathcal{L}(D,d)\text{ mit }D:=
\begin{pmatrix}
A\\
A'
\end{pmatrix}, d=
\begin{pmatrix}
b\\
b'
\end{pmatrix}\]
Es gen√ºgt nun das LGS $Dx=d$ zu l√∂sen, um $B\cap C$ zu erhalten. 
\end{enumerate}

\begin{example}
Betrachte den affinen Raum $\mathbb{A}_3(\mathbb{F}_2)=\{0,1\}^3$. Gegeben seien die
Ebenen:
\begin{align*}
&E:=\langle 
\begin{pmatrix}
1\\0\\0\\
\end{pmatrix},
\begin{pmatrix}
0\\1\\0
\end{pmatrix}\rangle +
\begin{pmatrix}
0\\0\\0
\end{pmatrix}=[e_1,e_2,0]\\
&F:=\langle 
\begin{pmatrix}
0\\0\\1\\
\end{pmatrix},
\begin{pmatrix}
1\\0\\0
\end{pmatrix}\rangle +
\begin{pmatrix}
1\\1\\1
\end{pmatrix}=[e_2,e_1+e_2,e_2+e_3]
\end{align*}
Zur Bestimmung von $E\cap F$ werden zun√§chst die zu $E$ und $F$ geh√∂rigen Gleichungssysteme
aufgestellt:
\begin{align*}
&E=\{x\in\mathbb{F}_2^3\mid x_3=0\}=\mathcal{L}((0,0,1),0)\\
&F=\Kern(\Lambda_{(0,1,0)})+
\begin{pmatrix}
1\\1\\1
\end{pmatrix} = \mathcal{L}((0,1,0),1)
\end{align*}
Daraus folgt:
\[E\cap F=\mathcal{L}(
\begin{pmatrix}
0&0&1\\
0&1&0
\end{pmatrix},
\begin{pmatrix}
0\\1
\end{pmatrix})=\{e_2,e_1+e_2\}\]
\end{example}

\begin{theo}[Satz von Pappos]
In einem affinen Raum $A$ mit Dimension 2 seien $G,G'$ verschiedene Geraden
mit $G\cap G'=\{O\}\in A$. Ferner seien $P_1,P_2,P_3\in G\setminus\{O\}$
und $Q_1,Q_2,Q_3\in G'\setminus\{O\}$, sodass gilt:
\[ P_1Q_3\parallel P_3Q_1\text{ und }P_1Q_2\parallel P_2Q_1\]
Daraus folgt:
\[ P_2Q_3\parallel P_3Q_2\]
\end{theo}

\begin{proof}
Da $Q_3\notin G$ ist, sind $O,P_1,Q_3$ in allgemeiner Lage. Daraus erhalten
wir folgendes Koordinatensystem: 
\[\mathcal{K}:=(O,\{\overrightarrow{OP_1},\overrightarrow{OQ_3}\})\]
Da die Koordinatendarstellung $D_{\mathcal{K}}:A\stackrel{\sim}{\to}\mathbb{A}_2(K)$ 
Parallelit√§ten und Schnittpunkte erh√§lt, k√∂nnen wir o.B.d.A annehmen:
\[A=\mathbb{A}_2(K) \text{ und }O=\begin{pmatrix}0\\0\end{pmatrix}\]
Dann gilt:
\begin{align*}
&P_1=\overrightarrow{OP_1}=\begin{pmatrix}\lambda_1\\0\end{pmatrix}=\begin{pmatrix}1\\0\end{pmatrix}
& &P_2=\begin{pmatrix}\lambda_2\\0\end{pmatrix}
& &P_3=\begin{pmatrix}\lambda_3\\0\end{pmatrix}\\
&Q_3=\overrightarrow{OQ_3}=\begin{pmatrix}0\\\mu_1\end{pmatrix}=\begin{pmatrix}0\\1\end{pmatrix}
& &Q_2=\begin{pmatrix}0\\\mu_2\end{pmatrix}
& &Q_3=\begin{pmatrix}0\\\mu_3\end{pmatrix}
\end{align*}
Wobei $\lambda_2,\lambda_3,\mu_2,\mu_3\ne 0$ sind. Daraus folgt f√ºr die Richtungen:
\begin{align*}
&\forall i,j\in \{1,2,3\}:U_{P_iQ_j}=\langle\overrightarrow{P_iQ_j}\rangle =\langle 
\begin{pmatrix}\lambda_i\\-\mu_j\end{pmatrix}\rangle\\
&\implies U_{P_1Q_3}=\langle \begin{pmatrix}1\\-1\end{pmatrix}\rangle
\end{align*}
Nach Vorraussetzung ist $\lambda_3=\mu_1$ und es existiert ein $\rho\in K^\times$, sodass gilt:
\[ \begin{pmatrix}\lambda_2\\-\mu_1 \end{pmatrix}=\rho\begin{pmatrix}1\\-\mu_2\end{pmatrix}\]
Daraus folgt mit $\lambda_3=\rho\mu_2=\lambda_2\mu_2$:
\begin{align*}
U_{P_2Q_3}&=\langle \begin{pmatrix}\lambda_2 \\-\mu_3 \end{pmatrix}\rangle\\
&=\langle \begin{pmatrix} \lambda_2\mu_2\\-\mu_2 \end{pmatrix}\rangle\\
&=\langle \begin{pmatrix} \lambda_3\\-\mu_2 \end{pmatrix}\rangle\\
&= U_{P_3Q_2}
\end{align*}
Also sind $P_2Q_3$ und $P_3,Q_2$ parallel.
\end{proof}

\section{Koordinatenwechsel und Darstellung affiner Abbildungen}
\begin{lemma}
Seien $\mathcal{K}=(O,B)$ und $\mathcal{L}=(Q,C)$ Koordinatensysteme des affinen Raums
$A$ mit Richtung $V$. Sei $M_{CB}:=D_{CB}(\id_V)$ die Basiswechselmatrix.\\
Dann rechnen sich Koordinaten eines Punktes $P$ bzgl. $\mathcal{K}$ in die
Koordinaten bzgl. $\mathcal{L}$ wie folgt um:
\[D_\mathcal{L}(P)=M_{CB}\cdot(D_\mathcal{K}(P)-D_\mathcal{K}(Q)\]
\end{lemma}

\begin{proof}
Es gilt:
\begin{align*}
D_\mathcal{L}(P)&=D_C(\overrightarrow{QP})\\
&=M_{CB}\cdot D_B(\overrightarrow{QP})\\
&=M_{CB}\cdot D_B(\overrightarrow{OP}-\overrightarrow{OQ})\\
&=M_{CB}\cdot (D_B(\overrightarrow{OP})-D_B(\overrightarrow{OP}))\\
&=M_{CB}\cdot(D_\mathcal{K}(P)-D_\mathcal{K}(Q)
\end{align*}
\end{proof}

\begin{application}
Ist ein beliebiges Koordinatensystem $\mathcal{L}=(Q,B)$ gegeben, so l√§sst sich ein 
Punkt $P$ einfach in das Koordinatensystem $\mathcal{K}=(0,S)$ von $\mathbb{A}_n(K)$ 
mit Standardbasis $S$ √ºberf√ºhren. Schreibe dazu $B$ als:
\[B=\begin{pmatrix}b_1&\cdots &b_n\end{pmatrix}\in K^{(n\times n)}\]
Dann ist $M_{SB}=B$ und es gilt:
\[D_\mathcal{L}(P)=M_{BS}(P-Q)=B^{-1}(P-Q)\]
\end{application}

\begin{lemma}
\begin{enumerate}
\item Die Abbildung $\psi:K^n\to K^m$ ist genau dann affin, wenn gilt:
\[\exists A\in K^{m\times n},a\in K^m:\Psi(x)=Ax+a\]
Schreibe daher kurz: $\psi=:(A,a)$
\item Ist ferner $C\in K^{t\times m},c\in K^r$, so gilt:
\[(C,c)\circ(A,a)=(CA,Ca+c)\]
\item Ist $m=n$ und $A\in\GL_n(K)$, so ist $(A,a)$ bijektiv und es gilt:
\[(A,a)^{-1}=(A^{-1},-A^{-1}a)\]
\end{enumerate}
\end{lemma}

\begin{proof}
\begin{enumerate}
\item Die Abbildung $\psi$ ist genau dann affin, wenn ein $\Lambda_\vp=\Lambda_A\in\Homaff
(K^n,K^m)$ f√ºr ein $A\in K^{m\times n}$, sodass gilt:
\[\psi(x)=\psi(x+0)=\Lambda_\vp(x)+\psi(0)\]
Die Behauptung folgt mit $a:=\psi(0)$.
\item Leichte √úbung!
\item Leichte √úbung!
\end{enumerate}
\end{proof}

\begin{definition}
Seien $A,A'$ affine R√§ume mit Koordinatensystemen $\mathcal{K}=(O,B),\mathcal{K'}=(O',B')$
und zugeh√∂rigen Koordinatenisomorphismen $D_{\mathcal{K}},D_{\mathcal{K'}}$. Definiere:
\[D{\mathcal{K'K}}(\vp):=D_{\mathcal{K'}}\circ \vp\circ D_{\mathcal{K}}^{-1}\in\Homaff(K^n,K^m)\]
\end{definition}

\begin{lemma}
Es gilt:
\[D_{\mathcal{K'K}}(\vp)=(D_{B'B}(\Lambda_\vp),D_{B'}(\overrightarrow{O'\vp(O)}))\]
\end{lemma}

\begin{proof}
Sei $P\in A$ beliebig, so entspricht es $D_\mathcal{K}(P)\in K^n$. Dann gilt:
\begin{align*}
D_{\mathcal{K'K}}(\vp)(D_\mathcal{K}(P)) &\stackrel{Def.}{=} D_\mathcal{K'}(\vp(P))\\
&\stackrel{Def.}{=} D_{B'}(\overrightarrow{O'\vp(P)})\\
&= D_{B'}(\overrightarrow{O'\vp(O)}+\overrightarrow{\vp(O)\vp(P)})\\
&= D_{B'}(\overrightarrow{O'\vp(O)})+D_{B'}(\overrightarrow{\vp(O)\vp(P)})\\
&= D_{B'}(\overrightarrow{O'\vp(O)})+D_{B'}(\Lambda_\vp (\overrightarrow{OP}))\\
&= D_{B'B}(\Lambda_\vp)\cdot D_B(\overrightarrow{OP})+D_{B'}(\overrightarrow{O'\vp(O)})\\
&= (D_{B'B}(\Lambda_\vp),D_{B'}(\overrightarrow{O'\vp(O)}))(D_\mathcal{K}(P))
\end{align*}
Da also beide Abbildungen auf einen beliebigen Punkt $P$ die selbe Wirkung haben, 
m√ºssen sie gleich sein.
\end{proof}

\begin{comment}
Das Zusammenf√ºgen von kommutativen Diagrammen liefert f√ºr einen weiteren affinen Raum
$A''$ mit Koordinatensystem $\mathcal{K''}=(O'',B'')$ und einer affinen Abbildung $\Psi:
A'\to A''$:
\[D_{\mathcal{K''K}}(\psi\circ\vp)=D_{\mathcal{K''K'}}(\psi)\circ D_{\mathcal{K'K}}(\vp)\]
\end{comment}

\begin{corollary}
\begin{enumerate}
\item Speziell f√ºr eine affine Abbildung $\vp:A\to A$ und zwei Koordinatensysteme
$\mathcal{K,L}$ gilt:
\[D_{\mathcal{LL}}(\vp)=D_{\mathcal{LK}}(\id)\circ D_{\mathcal{KK}}(\vp)\circ D_{\mathcal{KL}}(\id)\]
\item Insbesondere gilt f√ºr $\vp=\id$ gilt:
\[D_{\mathcal{LL}}(\vp)=D_{\mathcal{KK}}(\vp)\]
\item F√ºr $\mathbb{A}_n(K)$ mit Standardkoordinatensystem $\mathcal{K}=(0,S)$, sei
$D_{\mathcal{KL}}(\id)=:(M,b)$. Dann gilt f√ºr $\vp=(A,a)=D_{\mathcal{KK}}(\vp)$:
\[D_{\mathcal{LL}}(\vp)=(M^{-1}AM,M^{-1}((A-I)b+a))\]
\end{enumerate}
\end{corollary}

\begin{proof}
\begin{enumerate}
\item Folgt aus zweimaligem anwenden der obigen Bemerkung.
\item Folgt aus (1).
\item Es gilt:
\[D_{\mathcal{LK}}(\id)=(M,b)^{-1}=(M^{-1},-M^{-1}b)\]
Der restliche Beweis ergibt sich aus (1).
\end{enumerate}
\end{proof}

\section{Geometrische Eigenschaften von affinen Abbildungen}
Wir haben gesehen, dass Koordinaten f√ºr den Umgang mit affinen Abbildungen \textbf{n√ºtzlich}
sind. Nun stellen wir die Frage, inwiefern Koordinaten \textbf{n√∂tig} sind, d.h.
welche Eigenschaften von der Koordinatenwahl abh√§ngen.

\begin{definition}
\renewcommand{\labelenumi}{(\alph{enumi})}
\index{Fixpunkt}
\index{Fixraum}
\index{Fixrichtung}
Sei $A$ affiner Raum und $\vp\in\Homaff(A,A)$.
\begin{enumerate}
\item $P\in A$ hei√üt \textbf{Fixpunkt} von $\vp$, falls gilt:
\[\vp(P)=P\]
\item Ein affiner Teilraum $\emptyset\ne B\subseteq A$ hei√üt \textbf{Fixraum} 
von $\vp$, falls gilt:
\[\vp(B)\subseteq B\]
\item Ein Untervektorraum $U$ des Richtungsvektorraums $U_A$ hei√üt \textbf{Fixrichtung}
von $\vp$, falls gilt:
\[\Lambda_\vp(U)\subseteq U\]
\end{enumerate}
\renewcommand{\labelenumi}{(\arabic{enumi})}
\end{definition}

\begin{example}
\index{Translation}
\index{Streckung}
\begin{enumerate}
\item Sei $x\in V:=U_A$ fest und eine \textbf{Translation} 
\[\vp=\tau_x:A\to A,P\mapsto x+P\] 
gegeben, dann gilt:
\begin{enumerate}
\item F√ºr alle $U\le V$ ist $U$ Fixrichtung, da $\Lambda_\vp=\id_V$ ist.
\item F√ºr $x\ne 0$ existieren keine Fixpunkte.
\item F√ºr eine Fixgerade $G$ muss gelten:
\begin{align*}
&\vp(G)=x+G\subseteq G\\
\iff &x\in U_G
\end{align*}
Also ist die Menge aller Fixgeraden f√ºr $X\ne 0$:
\[\{Kx+P\mid P\in A\}\]
Beachte dass eine Fixgerade hier \textbf{keinen} Fixpunkt enth√§lt.
\end{enumerate}
\item Seien $\mu\in K\setminus\{0\}$ und $P\in A$ fest und eine \textbf{Streckung}
\[\vp:A\to A,x+P\mapsto \mu x+P\]
mit Zentrum $P$ und Streckungsfaktor $\mu$ gegeben.\\
Da im Fall $\mu=1$ $\vp=\id=\tau_0$ gilt, wollen wir im Folgenden $\mu\ne 1$ annehmen.
\begin{enumerate}
\item Die Menge der Fixpunkte ist gleich $\{P\}$.
\item F√ºr alle $U\le V$ ist $U$ Fixrichtung.
\item Fixgeraden sind genau die Geraden, die $P$ enthalten.
\end{enumerate}
\end{enumerate}
\end{example}

\begin{lemma}
F√ºr $A\in K^{n\times n},a\in K^n$ und $\vp=(A,a)$ gilt:
\begin{enumerate}
\item Die Fixpunkte bilden den affinen Teilraum $\mathcal{L}(A-I,-a)$.
\item Genau dann, wenn $1$ kein Eigenwert von $A$ ist, ist die Menge der Fixpunkte
einelementig.
\item $B$ ist genau dann Fixraum von $\vp$, wenn $U_B$ Fixrichtung ist und ein
Punkt $P\in B$ mit $\vp(P)\in B$ existiert.
\end{enumerate}
\end{lemma}

\begin{proof}
\begin{enumerate}
\item Es ist $\vp=Ax+a$, also gilt:
\begin{align*}
\vp(x)=x &\iff Ax+a=x\\
&\iff Ax-x=-a\\
&\iff (A-I)x=-a\\
&\iff x\in\mathcal{L}(A-I,-a)
\end{align*}
\item Ist $1$ kein Eigenwert von $\vp$, so existiert $(A-I)^{-1}$, daraus folgt f√ºr 
einen Fixpunkt $x$:
\[x=(A-I)^{-1}(-a)\]
Also ist $x$ eindeutig bestimmt.
\item $B=U+P$ ist genau dann Fixraum, wenn gilt:
\begin{align*}
\vp(B)\subseteq B &\iff \vp(U+P)\subseteq U+P=B\\
&\iff \Lambda_\vp(U)+\vp(P)\subseteq U+P\\
&\iff \vp(P)\in B\wedge \Lambda_\vp(U)\subseteq U
\end{align*}
Also ist $U$ Fixrichtung.
\end{enumerate}
\end{proof}

\section{Geometrische Charakterisierung von Affinit√§ten}
\begin{definition}
\index{Geradentreue}
Sei $A$ ein affiner Raum mit einer (nicht notwendigerweise affinen) Abbildung
$\vp:A\to A$. $\vp$ hei√üt \textbf{geradentreu}, wenn f√ºr $G\subseteq A$ gilt:
\[G \text{ Gerade } \iff \vp(G) \text{ Gerade}\]
\end{definition}

\begin{example}
\begin{enumerate}
\item Affinit√§ten sind geradentreu.
\item Die Abbildung:
\[\vp:\mathbb{A}_2(\mathbb{C})\to\mathbb{A}_2(\mathbb{C}), (\alpha,\beta)\mapsto
(\overline\alpha,\overline\beta)\]
ist geradentreu, aber \textbf{nicht} affin.
\end{enumerate}
\end{example}

\textbf{\color{Red}Hier fehlt noch der Mitschrieb vom 18.6.!}

\begin{proof}
\textbf{3. Schritt:} Zu Zeigen: $\forall T\in U_0:$ T Fixpunkt!\\
\[\exists \alpha,\beta\in K_0: T=\alpha P\beta Q\]
\[\{T\}=\underbrace{(KP+\underbrace{\beta Q}_{Fixpunkt})}_{\parallel [O,P]}\cap \underbrace{(KQ+\underbrace{\alpha P}_{Fixpunkt})}_{\parallel [O,Q]}\]
\end{proof}

\chapter{Euklidische Punktr√§ume}

Hier sei stets $K=\mathbb{R}$. Neu in diesem Paragraphen sind \textbf{Abst√§nde} zwischen 
Punkten im affinen Raum.

\section{Grundbegriffe}

\begin{definition}
\index{euklidisch!Raum}\index{Raum!euklidischer}
\index{Abstand}
\renewcommand{\labelenumi}{(\alph{enumi})}
\begin{enumerate}
\item $(E,\langle\cdot,\cdot\rangle)$ mit einem affinen Raum $E$ √ºber $\mathbb{R}$
und einem Skalarprodukt $\langle\cdot,\cdot\rangle$ auf dem Richtungs-VRm $V=U_E$ 
von $E$ hei√üt \textbf{euklidischer Raum}.
\item Der \textbf{Abstand} von $P,Q\in E$ ist definiert als:
\[d(P,Q):=\|\overrightarrow{PQ}\| \left(=\sqrt{\langle\overrightarrow{PQ},\overrightarrow{PQ}\rangle}\right)\]
\end{enumerate}
\renewcommand{\labelenumi}{(\arabic{enumi})}
\end{definition}

\begin{example}
Der \textbf{euklidische Standardraum} $E=\mathbb{A}_n(\mathbb{R})=\mathbb{R}^n$ mit Standardskalarprodukt
\[d(\begin{pmatrix}x_1\\\vdots\\x_n\end{pmatrix},\begin{pmatrix}y_1\\\vdots\\y_n\end{pmatrix})
=\sqrt{\sum_{i=1}^n(x_i-y_i)^2}\]
\end{example}

\begin{comment}
Der Abstand $d$ eines euklidischen Raums $E$ definiert eine Metrik auf $E$ (Positivdefinitheit, Symmetrie
und Dreiecksungleichung).
\end{comment}

\begin{definition}
\index{Koordinatensystem!cartesisches}\index{cartesisch!Koordinatensystem}
\index{L√§ngentreue}
\index{Bewegung}
\index{Isometrie}
\renewcommand{\labelenumi}{(\alph{enumi})}
\begin{enumerate}
\item Ein Koordinatensystem $\mathcal{K}=(O,B)$ auf dem euklidischen Raum $E$ hei√üt \textbf{cartesisch},
falls $B$ Orthonormalbasis (bzgl $\langle\cdot,\cdot\rangle$) ist.
\item Seien $E,F$ euklidische R√§ume und $\vp:E\to F$ eine beliebige Abbildung. $\vp$ hei√üt
\textbf{l√§ngentreu}, falls gilt:
\[\forall P,Q\in E: d(\vp(P),\vp(Q))=d(P,Q)\] 
\item $\vp$ hei√üt \textbf{isometrisch}, falls $\vp$ affin und l√§ngentreu ist.\\
$\vp$ hei√üt \textbf{Bewegung} von $E$, falls $\vp\in\Autaff(E)$ und isometrisch ist.
Ist ferner $\det(\Lambda_\vp)=1$, so hei√üt $\vp$ eine \textbf{eigentliche Bewegung}.
\end{enumerate}
\renewcommand{\labelenumi}{(\arabic{enumi})}
\end{definition}

\begin{comment}
Die Menge aller Bewegungen (schreibe $\Autdist(E)$) ist eine Gruppe mit Untergruppe
der Menge aller eigentlichen Bewegungen (schreibe $\Aut^+_\text{dist}(E)$).
\end{comment}

\begin{lemma}
Seien $E,F$ euklidische R√§ume und $\vp\in\Homaff(E,F)$. Falls $\Lambda_\vp$ ein 
Morphismus von Skalarproduktr√§umen ist, so ist $\vp$ isometrisch.
\end{lemma}

\begin{proof}
Sei $\Phi :=\Lambda_\vp$, dann gilt $\langle\Phi(x),\Phi(y)\rangle
=\langle x,y\rangle$ und es folgt:
\begin{align*}
d(\vp(P),\vp(Q))&=\|\overrightarrow{\vp(P)\vp(Q)}\|\\
&=\|\Phi(\overrightarrow{PQ})\|\\
&=\|\overrightarrow{PQ}\|\\
&= d(P,Q)
\end{align*}
\end{proof}

\begin{corollary}
Sei $\mathcal{K}=(O,B)$ cartesisches Koordinatensystem eines euklisischen Raums $E$. Dann
ist die Koordinatendarstellung $D_\mathcal{K}:E\to \mathbb{R}^n$ ein isometrischer affiner
Isomorphismus.\\
Daher gen√ºgt es meistens, den euklidischen Standardraum zu behandeln.
\end{corollary}

\begin{proof}
Es ist $D_\mathcal{K}(P)=D_B(\overrightarrow{OP})$ mit $B$ ONB. Daraus folgt:
\[D_B:V\stackrel{\sim}{\to}\mathbb{R}^n\] 
d.h. $D_B$ ist Isometrie von $V$ in den $\mathbb{R}^n$.
\end{proof}

\begin{comment}
Im Standardraum gilt:
\[\Autdist(\mathbb{R}^n)=\{(A,a)\in\Homaff(\mathbb{R}^n,\mathbb{R}^n)\mid A\in O_n\}\]
\end{comment}

\begin{definition}
\index{orthogonal!Teilr√§ume}
$A,B$ affine Teilr√§ume eines euklidischen Raumes $E$ hei√üen \textbf{orthogonal}, falls
$U_A \bot U_B$.
\end{definition}

\begin{task}
Bestimme den \textbf{Abstand} zwischen zwei Teilr√§umen $A,B$. Dieser ist wie folgt definiert:
\[d(A,B):=\min\{d(P,Q)\mid P\in A,Q\in B\}\]
\end{task}

\begin{method}
Lot f√§llen! (Dabei gen√ºgt es $E=\mathbb{R}^n$ zu betrachten.)
\end{method}

\begin{definition}
\index{gemeinsam!Lot}\index{Lot!gemeinsames}
\index{Lotfu√üpunkt}
Eine Gerade $G$ hei√üt \textbf{gemeinsames Lot} von $A,B$ mit \textbf{Lotfu√üpunkten} $P^+$ 
und $Q^+$, falls gilt:
\begin{align*}
G&\bot A &G&\bot B\\
G\cap A&=\{P^+\} &G\cap B&=\{Q^+\} 
\end{align*}
\end{definition}

\begin{theo}
Seien $A,B$ affine Teilr√§ume von $\mathbb{R}^n$ mit $A\ne\emptyset\ne B$. Aus $\dim(U_A+U_B)<n$ folgt, dass
ein gemeinsames Lot $G$ mit Lotfu√üpunkten $P^+,Q^+$ und $d(A,B)=d(P^+,Q^+)$ existiert.
\end{theo}

\begin{proof}
Falls $G$ existiert, so gilt f√ºr alle $P\in A,Q\in B$:
\[d(P,Q)=\|\overrightarrow{PQ}\|=\|\underbrace{\overrightarrow{PP^+}}_{=:x\in U_A}+\underbrace{\overrightarrow{P^+Q^+}}_{=:y\in U_G}+\underbrace{\overrightarrow{Q^+Q}}_{=:z\in U_B}\|\]
wobei nach Vorraussetzung $y\bot y$ und $y \bot z$, also auch $y \bot (x+z)$ ist.
Nach Pythagoras gilt:
\[\|y+(x+z)\|^2=\|y\|^2+\|x+z\|^2\ge \|y\|^2\]
Mit Wurzelziehen folgt daraus:
\[d(P,Q)\ge \|y\|=d(P^+,Q^+)\]
Also ist $d(P^+,Q^+)=d(A,B)$, falls $G$ existiert.\\
Schreibe:
\begin{align*}
&A=\sum_{i=1}^r \mathbb{R}\cdot x_i+x_0 &&B=\sum_{j=1}^s \mathbb{R}\cdot y_j +y_0
\end{align*}
Es gelten folgende notwendige Bedingungen f√ºr $P^+,Q^+$:	
\begin{enumerate}
\item $P^+=\sum_{i}\lambda_i x_i+x_0$ mit $\lambda_i\in\mathbb{R}$.
\item $Q^+=\sum_{j}\mu_i y_j+y_0$ mit $\mu_j\in\mathbb{R}$.
\item $\forall i\in\{1,\ldots,r\}\langle x_i,P^+-Q^+\rangle = 0$
\item $\forall j\in\{1,\ldots,s\}\langle y_j,P^+-Q^+\rangle = 0$
\end{enumerate}
Daraus erhalten wir ein LGS f√ºr die unbestimmten $\lambda_i,\mu_j$, dessen
L√∂sung $P^+$ und $Q^+$ ergibt.
Das LGS ist genau dann l√∂sbar, wenn gilt:
\[\exists P^+-Q^+:\sum_i \lambda_ix_i+x_0-\sum_j \mu_jy_j+y_0\in (U_A+U_B)^\bot\]
Wegen $\mathbb{R}^n=(U_A+U_B)\oplus(U_A+U_B)^\bot$ ist sicher
$x_0-y_0\in\langle x_i,y_j\rangle+(U_A+U_B)^\bot$, also ist das LGS l√∂sbar.\\
Nach Vorraussetzung existiert ein $z\ne 0$ mit $z\in(U_A+U_B)^\bot$\\
Nehme:
\begin{align*}
G:=
\begin{cases}
[P^+,Q^+] &,P^+\ne Q^+\\
\mathbb{R}\cdot z+P^+ &,P^+=Q^+
\end{cases}
\end{align*}
\end{proof}

\begin{comment}
Sei $\{b_1,\ldots,b_t\}$ ONB von $(U_A+U_B)^\bot$. Dann gilt mit $\beta_\tau=\langle x_0-y_0, b_\tau\rangle$:
\[P^+-Q^+=\sum_{\tau=1}^t \beta_\tau\cdot b_\tau\]
Dann erhalten wir zwei Methoden zur Abstandsbestimmung:
\begin{enumerate}
\item L√∂se das LGS in $\lambda_i,\mu_j$!
\item Bestimme eine ONB $\{b_1,\ldots,b_t\}$ von $(U_A+U_B)\bot$, dann gilt:
\[d(A,B)\left(=\|P^+-Q^+\|\right) =\sqrt{\sum_{\tau=1}^t \langle x_0-y_0,b_\tau\rangle^2}\]
Diese Methode kommt \textbf{ohne} Berechnung von $P^+,Q^+$ aus.
\end{enumerate}
\end{comment}

\section{Bewegungen im $\mathbb{R}^2$}
\begin{task}
Klasseneinteilung von $\Autdist(\mathbb{R}^2)$.
\end{task}

\begin{method}
Die folgende Methode funktioniert analog zu der bei Affinit√§ten.\\ 
$\vp=(A,a)$ (bzgl. Standardkoordinatensystem $\mathcal{K}=(O,B)$) wird in ein 
anderes Koordinatensystem $\mathcal{L}=(P,B)$ umgerechnet:
\[D_{\mathcal{L}\mathcal{L}}(\vp)=\left((M^{-1}AM),M^{-1}((A-I)b+a)\right)=:(A',b')\]
wobei $(M,b):=D_{\mathcal{K}\mathcal{L}}(\id)$ mit $M=M_{SB}$ den Wechsel \textbf{cartesischer}
Koordinatensysteme beschreibt, so da\ss \ \((A',b')\) einfache Gestalt erh\"alt 
(``Normalform'').\\
\(A'\) hat folgende Form:\\
\(A'=D_{\alpha}=
\begin{pmatrix}
\cos\alpha&&-\sin\alpha\\
\sin\alpha&&\cos\alpha
\end{pmatrix}\) (Drehung) oder \(A'=C:=
\begin{pmatrix}
1&&0\\
0&&-1
\end{pmatrix}\) (Spiegelung)
\begin{itemize}
\item Fall \(D_{\alpha}\) mit \(0<\alpha <2\pi\):\\
Es gilt: \(1\not\in\Spec(A) \implies \vp\) hat genau einen Fixpunkt 
\(P\,\Longleftrightarrow\,(A-I)P+a=0\) wobei \((A-I)\) invertierbar ist.

W\"ahle Koordinatensystem \(\mathcal{L}:=(P,B)\,\rightarrow\,(A',b')=(D_{\alpha},0)\)
\item Fall \(A'=I\):\\
Sei \(\vp=(I,a)\) eine Translation, \(a\neq 0\).\\
W\"ahle \(\mathcal{L}:=(0,(b_{1},b_{2}))\) mit \(b_{1}:=\frac{a}{||a||}\). Dann
gilt:
\[
M_{SB} = (b_{1},b_{2}),\quad M_{SB}^{-1}(b_{1},b_{2})=(e_{1},e_{2})
\]
also \(b'=M_{SB}^{-1}a=\lambda_{e_{1}}\).\\
Dann ist \(D_{\mathcal{L}\mathcal{L}}(\vp)=(I,\lambda_{e_{1}})\) mit 
\(\lambda:=||a||>0\).
\item Fall \(A'=C\): analog
\end{itemize}
\end{method}

\begin{theo}
\index{Normalform}\index{Drehung}\index{Translation}\index{Spiegelung}
Zu \(\vp\in\Autdist(\mathbb{R}^{2})\) existiert ein cartesisches 
Koordinatensystem \(\mathcal{L}\) so, da\ss \ \(D_{\mathcal{L}\mathcal{L}}(\vp)\)
eine der folgenden Normalformen hat:
\begin{enumerate}
\item\((I,0) = \id\)
\item\((I,\lambda_{e_{1}})\quad\) Translation \((\lambda > 0)\), keine Fixpunkte
\item\((D_{\alpha})\quad\) Drehungen \((0<\alpha<2\pi)\), genau ein Fixpunkt 
\(O\).
\item\((C,0)\quad\)Spiegelung an einer Achse, die Achse ist die Menge der 
Fixpunkte
\item\((C,\lambda_{e_{1}})\quad\) Gleitspiegelung, kein Fixpunkt, genau eine
Fixgerade
\end{enumerate}
Eigentliche Bewegungen sind die Identit\"at, Translationen und Drehungen.
\end{theo}

\section{Geometrische Kennzeichnung von Bewegungen}
\index{Bewegung}

Betrachte zun\"achst generell eine l\"angentreue Abbildung 
\(\Psi:\mathbb{R}^{n}\to\mathbb{R}^{m}\) (nicht notwendig affin).
\begin{lemma}
Zu \(\lambda\in\mathbb{R},\,P\neq Q\in\mathbb{R}^{n}\) existiert genau ein
Punkt \(R\in\mathbb{R}^{n}\) mit
\begin{align*}
d(P,R)&=|\lambda|\cdot d(P,Q)\\
d(Q,R)&=|1-\lambda|\cdot d(P,Q)
\end{align*}
n\"amlich \(R:=\lambda y+P\) f\"ur \(y:=\overrightarrow{PQ}\).
\end{lemma}
\begin{proof}
\begin{align*}
d(P,R)&=||\lambda y|| = |\lambda|||y||=|\lambda|\cdot d(P,Q)\\
d(Q,R)&=||y+P-(\lambda y + P)||=|1-\lambda|||y||=|1-\lambda|\cdot d(P,Q)
\end{align*}

Sei \(S\) ein weiterer Punkt mit \(d(P,S)=d(P,R),\,d(Q,S)=d(Q,R)\). Etwa
\(S=x+R\).
Ohne Beschr\"ankung der Allgemeinheit sei \(P=0\) (nach Koordinatenwechsel),
also
\[
Q=y,\,R=\lambda y,\,S=x+\lambda y
\]
\(\implies ||R||=d(0,R)=d(0,S)=||S||\), also 
\[
\langle\lambda y,\lambda y\rangle = \langle x+\lambda y,x+\lambda y\rangle
\implies\langle x,x\rangle+2\lambda\langle x,y\rangle =0
\]
und
\[
||Q-R||=||Q-S||\implies ||y-\lambda y||=||y-\lambda y-x|| 
\overset{\text{analog}}{\implies}
\langle x,x\rangle+(2\lambda -2)\langle x,y\rangle =0
\]
Insgesamt: \(\langle x,y\rangle =0,\,\langle x,x\rangle=0\), also \(x=0\), d.h.
\(R=S\).
\end{proof}

\begin{corollary}
Ist \(\Psi:\mathbb{R}^{n}\to\mathbb{R}^{m}\) l\"angentreu, so gilt f\"ur alle
\(P,\,Q\in\mathbb{R}^{n},\,\lambda\in\mathbb{R}\):
\[
\Psi(\lambda\cdot\overrightarrow{PQ}+P)=\lambda\overrightarrow{\Psi(P)\Psi(Q)}+\Psi(P)
\]
Insbesondere ist \(\Psi\) geradentreu f\"ur \(n=m\).
\end{corollary}
\begin{proof}
Klar f\"ur \(P=Q\).\\
Sei nun \(y:=\overrightarrow{PQ}\neq 0,\,R:=\lambda y+P\). Da \(\Psi\) 
l\"angentreu, folgt nach Lemma
\begin{align*}
d(\Psi(P),\Psi(R))&=|\lambda|\cdot d(\Psi(P),\Psi(Q))\\
d(\Psi(Q),\Psi(R))&=|1-\lambda|d(\Psi(P),\Psi(Q))
\end{align*}
Lemma anwenden auf die Bildpunkte \(P':=\Psi(P),\,Q':=\Psi(Q),\,R':=\Psi(R)\)
liefert \(R'=\lambda\overrightarrow{P'Q'}+P'\).
\end{proof}

\begin{corollary}
\(\Psi(\mathbb{R}^{n})\) ist affiner Teilraum von \(\mathbb{R}^{n}\).
\end{corollary}
\begin{proof}
Nach dem vorhergehenden Korollar gilt f\"ur beliebige Punkte 
\(P',\,Q'\in\Psi(\mathbb{R}^{n})\), da\ss \ die Verbindungsgerade
\([P',Q']\subseteq\Psi(\mathbb{R}^{n})\).
Mit dem Teilraumkriterium folgt die Behauptung.
\end{proof}

\begin{corollary}
Sei \(n=m,\,\Psi:\mathbb{R}^{n}\to\mathbb{R}^{m}\) l\"angentreu, 
\(B={b_{1},\ldots,b_{n}}\) Orthonormalbasis und \(\Psi(0)=0\). Dann ist auch
\(\Psi(B)\) eine Orthonormalbasis.
\end{corollary}
\begin{proof}
\(n=1\): Klar.\\
Sei \(n>1\). Betrachte Abst\"ande \(d(\mathbb{R}\cdot b_{i},{b_{j}})\) f\"ur
\(i\neq j\).\\
\(\implies 0=\Psi(0)\in\Psi(\mathbb{R}\cdot b_{i})=[0,\Psi(b_{i})]\) hat 
minimalen Abstand von \(\Psi(b_{j})\).\\
Lotgerade \(G=[0,\Psi(b_{j})]\bot[0,\Psi(b_{i})]\), also \(\Psi(b_{i})\bot\Psi(b_{j})\)\\
Ferner ist: \(||\Psi(b_{i}||=d(0,\Psi(b_{i}))=d(0,b_{i})=||b_{i}||=1\).
Also ist \(\Psi(B)\) eine Orthonormalbasis.
\end{proof}

\begin{corollary}
\(\Psi:\mathbb{R}^{n}\to\mathbb{R}^{m}\) l\"angentreu \(\implies\,\Psi\) ist 
bijektiv.
\end{corollary}
\begin{proof}
Ohne Beschr\"ankung der Allgemeinheit sei \(\Psi(0)=0\), also 
\(\Psi(\mathbb{R}^{n})\) Untervektorraum von \(\mathbb{R}^{n}\) mit einer 
Orthonormalbasis von \(\mathbb{R}^{n}\,\implies\,\Psi(\mathbb{R}^{n})=\mathbb{R}^{n}\).\\
Injektiv: \(\Psi(P)=\Psi(Q)\)
\[
\implies 0=d(\Psi(P),\Psi(Q))=d(P,Q)\quad\implies P=Q
\]
\end{proof}

\begin{theo}
Jede l\"angentreue Abbildung \(\Psi:E\to E\) eines euklidischen Raumes \(E\) ist
eine Bewegung (also \(\Psi\in\Autaff(E)\)).
\end{theo}
\begin{proof}
Die Wahl eines cartesischen Koordinatensystems erlaubt ohne Beschr\"ankung der
Allgemeinheit \(E=\mathbb{R}^{n}\) zu nehmen.\\
Wechsel zu \(\Psi':=(x\mapsto\Psi(x)-\Psi(0))\) ergibt \(\Psi'(0)=0\).

Beachte: \(\Psi\) ist affin (bzw. l\"angentreu) genau dann, wenn \(\Psi'\) affin
(bzw. l\"angentreu) ist.

Also sei ohne Einschr\"ankung \(\Psi(0)=0\). Restbehauptung: \(\Psi\) ist eine
lineare Abbildung.\\
\(n=1\): Klar.\\
\(n>1\): \(\Psi\) ist geradentreu nach dem ersten Korollar, also 
% Querverweis von LaTeX erledigen lassen?
\(\mathbb{Q}\)-linear (nach 21.4), insbesondere additiv. 
\[
\lambda\in\mathbb{R}:\,\Psi(\lambda x)=\lambda\cdot\overrightarrow{\Psi(0)\Psi(x)}+\underbrace{\Psi(0)}_{=0}=\lambda\Psi(x)
\]
\end{proof}

\chapter{Analytische Geometrie}
\section{Quadriken}
\index{Quadrik}\index{Multiindex}

\(K\) sei ein K\"orper, \(f\in K[X_{1},\ldots,X_{n}]\)
\[
f(X_{1},\ldots,X_{n})=\sum_{i_{1},\ldots,i_{n}\in\mathbb{N}}{\alpha_{i_{1},\ldots,i_{n}}\underbrace{X_{1}^{i_{1}}\ldots X_{n}^{i_{n}}}_{=:\underline{X}^{\underline{i}}}}=
\sum_{\underline{i}\in\mathbb{N}^{n}}{\alpha_{\underline{i}}\cdot\underline{X}^{\underline{i}}}
\]

\(\underline{i}\) hei\ss t \textbf{Multiindex}.
\begin{definition}
F\"ur \(\underline{i}\in\mathbb{N}^{n}\) sei \(|\underline{i}|:=i_{1}+\ldots+i_{n}\) der \textbf{Grad} von \(\underline{X}^{\underline{i}}\).\\
Der \textbf{(Gesamt-)Grad} von \(f\) ist \(\deg(f):=\max\{|\underline{i}|:\alpha_{\underline{i}}\neq0\}\).
\end{definition}

Wunsch: Beschreibe die Nullstellenmenge
\(\mathcal{N}(f):=\{x=(x_{1},\dots,x_{n}\in K^{n}\mid f(x_{1},\dots,x_{n})=0\}\)
f\"ur ein Polynom \(f\) mit \(\deg(f)=2\).

\begin{comment}
Den Fall eines oder mehrerer Polynome vom Grad 1 erledigt die lineare Algebra.
Mehrere Polynome vom Grad \(\geq 2\) behandelt die \textbf{Kommutative Algebra 
und algebraische Geometrie}.
\end{comment}

\begin{prepwork}
Klassifiziere die Menge \(\mathcal{N}(f)\) durch
Klassifizierung der Polynome. (Erinnerung: Klasseneinteilung entspricht einer
\"Aquivalenzrelation)

Dazu sei \(G\leq\Autaff(K^{n})\) (Untergruppe).

Definiere hiermit eine \"Aquivalenzrelation auf Polynomen bzw. auf Teilmengen
\(T\subseteq K^{n}\).
\begin{align*}
f_{1}\approx_{G}f_{2}&:\Longleftrightarrow\exists\mu\in K^{\times}\exists\varphi
\in G:\,f_{2}=\mu\cdot (f_{1}\circ\phi)\\
M_{1}\sim_{G}M_{2}&:\Longleftrightarrow\exists\varphi\in G:\,M_{2}=\varphi(M_{1})
\end{align*}
Klar: \(f_{1}\approx_{G}f_{2}\implies\mathcal{N}(f_{1})\sim_{G}\mathcal{N}(f_{2})\)
\end{prepwork}

\begin{ziel}
Klassifiziere die Polynome f\"ur spezielle \(G\).
\begin{itemize}
\item Affine Klassifikation (f\"ur Char(K)\(\neq 2\)): 
\[
G=\Autaff(K^{n})=\{\varphi=(A,b)\mid A\in\GL_{n}(K),b\in K^{n}\}
\]
\item Euklidische Klassifikation: 
\[
G=\Autaff(\mathbb{R}^{n})=\{(A,b)\mid A\in O_{n},b\in\mathbb{R}^{n}\}
\]
\end{itemize}
\end{ziel}

Sei nun Char(K)\(\neq 2\).

\begin{prep}
Jedes Polynom \(f\) mit \(\deg(f)=2\) hat die Form
\[
f(X_{1},\dots,X_{n})=\sum_{i,j=1}^{n}{\alpha_{ij}X_{i}X_{j}}+2\sum_{i=1}^{n}{\beta_{i}X_{i}}+\gamma
\]
mit einer symmetrischen Matrix \(A=(\alpha_{ij})\neq 0,\,b=\begin{pmatrix}\beta_{1}\\\vdots\\\beta_{n}\end{pmatrix}\in K^{n},\,y\in K\).
\end{prep}

\begin{proof}(Symmetrie von A)\\
Falls \(A\) nicht symmetrisch ist, ersetze \(A\) durch 
\[
\frac{1}{2}\left(A+A^{\top}\right)=:A'
\]
\end{proof}

Beachte: F\"ur \(x=\begin{pmatrix} x_{1}\\\vdots\\ x_{n}\end{pmatrix}\in K^{n}\)
gilt
\[
f\left(x^{\top}\right)=x^{\top}Ax+2b^{\top}x+\gamma
\]
mit \(A^{\top}=A\).

\(Q:=\mathcal{N}(f)\) hei\ss t \textbf{affine Quadrik}.
\begin{lemma}
F\"ur \(f\) wie oben und \(\varphi=(C,d)\in\Autaff(K^{n})\) sei 
\(g(y):=(f\circ\varphi)(y)\). Dann ist
\[
g(y)=y^{\top}A'y+2b'^{\top}y+\gamma'
\]
wobei \(A':=C^{\top}AC,\,b':=C^{\top}(Ad+b),\,\gamma':=f(d)\).
\end{lemma}
\begin{proof}
\begin{align*}
f\left(\varphi(y)\right)&=f(Cy+d)\\
&=\underbrace{(Cy+d)^{\top}}_{y^{\top}C^{\top}+d^{\top}}A(Cy+d)+2b^{\top}(Cy+d)+\gamma\\
&=y^{\top}\underbrace{C^{\top}AC}_{=:A'}y+d^{\top}ACy+
    \underbrace{\overbrace{y^{\top}C^{\top}Ad}}^{\in K^{1\times 1}}_{=d^{\top}A^{\top}Cy = d^{\top}ACy}
    +2b^{\top}Cy+\underbrace{d^{\top}Ad+2b^{\top}d+\gamma}_{=:\gamma'}\\
&=y^{\top}A'y+2b'^{\top}y+\gamma'
\end{align*}
\end{proof}

\textbf{Prinzip der Klassifikation:} Zu gegebenem \(f\) finde \((C,d)\), so 
da\ss \ \(A',\,b",\,\gamma'\) eine einfache, \"ubersichtliche ``Normalform''
annehmen.

\begin{comment}
\(\vp\) bewirkt Wechsel des Koordinatensystems \(y=\vp^{-1}(x)=D_{\mathcal{L}}(x)\).
\(y\) beschreibt \(Q=\mathcal{N}(f)\) im Koordinatensystem \(\mathcal{L}\).
\end{comment}
\begin{theo}[Satz von der quadratischen Erg\"anzung]
Sei \(A\in K^{n\times n}\) symmetrisch vom Rang \(r\) und 
\(\text{Char}(K)\neq 2\). Dann existiert \(C\in\GL_{n}(K)\) so da\ss \ 
\[
C^{\top}AC=\diag(\alpha_{1},\ldots,\alpha_{r},0,\ldots,0)
\]
\end{theo}
\begin{proof}
Sei \(A=(\alpha_{ij})\) mit \(\alpha_{ij}=\alpha_{ji}\) f\"ur alle \(i,j\).\\
Nutze eine Variante des Gau\ss algorithmus; es gen\"ugt Diagonalgestalt zu 
erreichen, den Rest erledigen Vertauschungsmatrizen \(V_{ij}\).

\(\nu\)-ter Schritt: Angenommen die Zeilen (Spalten) mit einer Nummer kleiner
\(\nu\) haben die gew\"unschte Form. Dann ist:
\[
A_{\nu}:=
    \begin{pmatrix}
    *& & &0& & \\
     &\ddots& & &\ddots& \\
     & &*& & &0\\
    0& & &*&\cdots&* \\
     &\ddots& &\vdots&\ddots&\vdots\\
     & &0&*&\cdots&*\\
    \end{pmatrix}
\]
Unterscheide folgende F\"alle:
\begin{enumerate}
\item \(\alpha_{\nu\nu}\neq 0\):\\
Mache Zeilenumformung: Subtrahiere Vielfaches
der \(\nu\)-ten Zeile von der unteren Zeile, so da\ss \ dort die \(\nu\)-te 
Spalte Null wird.\\
Dies geht mit
\[
C':=I-\sum_{k=\nu+1}^{n}{\frac{\alpha_{k\nu}}{\alpha_{\nu\nu}}E_{k\nu}}:\quad
C'A_{\nu}=(\beta_{ij})
\]
mit \(\beta_{\nu+1,\nu}=\ldots =\beta_{n}=0\). Die \(\nu\)-te Zeile ist 
\(\beta_{\nu j}=\alpha_{\nu j}\left(=\alpha_{j\nu}\right)\).
\item \(\alpha_{\nu\nu}=0,\,\alpha_{kk}\neq 0\) f\"ur ein \(k>\nu\):\\
Bilde \(A'_{\nu}:=V_{\nu k}A_{\nu}V_{\nu k}\), dann weiter wie in Fall 1.
\item \(\alpha_{kk}=0\) f\"ur \(k=\nu,\ldots,n\):\\
Ist \(\alpha_{k\nu}=0\,\forall k\geq\nu\), so ist bereits \(A_{\nu}\) diagonal
bis Zeile \(\nu\).\\
Sonst sei \(\beta:=\alpha_{k\nu}\neq0\) f\"ur ein \(k>\nu\)
(addiere die \(k\)-te Zeile zur \(\nu\)-ten).
Nutze die Additionsmatrix \(T:=A_{\nu k}(1)=I+E_{\nu k}\) mit
\(T^{\top}=I+E_{k\nu}\).\\
Dann folgt \(A'_{\nu}:=TA_{\nu}T^{\top}\) hat \(\alpha'_{\nu\nu}=2\beta\neq0\)
(da Char\((K)\neq2\)). Fahre fort wie in Fall 1.
\end{enumerate}
\end{proof}
Vorsicht: Die \(\alpha_{1},\ldots,\alpha_{n}\) sind im allgemeinen nicht eindeutig.
\begin{theo}[Tr\"agheitssatz von Sylvester]
\index{Tr\"agheitssatz von Sylvester}
Sei \(A\in K^{n\times n}\) symmetrisch vom Rang \(r\).
\begin{enumerate}
\item F\"ur \(K=\mathbb{C}\) existiert \(C\in\GL_{n}(\mathbb{C})\) mit
\[
C^{\top}AC=\diag(\underbrace{1,\ldots,1}_{r},0,\ldots,0)
\]
\item F\"ur \(K=\mathbb{R}\) existiert \(C\in\GL_{n}(\mathbb{R})\) mit
\[
C^{\top}AC=\diag(\underbrace{1,\ldots,1}_{p},\underbrace{-1,\ldots,-1}_{q},0,\ldots,0)
\]
wobei \(p,q\) durch \(A\) eindeutig bestimmt sind.
\end{enumerate}
\end{theo}
\begin{proof}
\begin{enumerate}
\item Nach dem vorherigen Satz mit \(D:=\diag(\beta_{1},\ldots,\beta_{r},0,\ldots,0)\).\\
Weiteres umformen liefert:
\[
D^{\top}\cdot\diag(\alpha_{1},\ldots,\alpha_{r},0,\ldots,0)\cdot D=
\diag(\beta_{1}^{2}\alpha_{1},\ldots,\beta_{r}^{2}\alpha_{r},0,\ldots,0)
\]
Falls \(\beta_{i}\) Nullstelle von \(X^{2}-\frac{1}{\alpha_{i}}\) ist, existiert
in \(\mathbb{C}\) immer in eine Diagonalmatrix \(\diag(1,\ldots,1,0,\ldots,0)\).
\item \"Ahnlich f\"ur \(\mathbb{R}\). Vorzeichen ber\"ucksichtigen

Restbehauptung: \(p\) ist eindeutig bestimmt durch \(A\)\\
Behauptung: \(p=\max\left\{\dim U\mid U\leq\mathbb{R}^{n}\text{ mit } \left.
s_{A}\right|_{U}\text{ positiv definit}\right\}\) wobei 
\(s_{A}(x,y):=\langle Ax,y\rangle\).\\
Sei anderes \(C'\) mit zugeh\"origem \(p',\,q'\). Setze
\begin{align*}
b_{i}&:=Ce_{i}\\
b'_{i}&:=C'e_{i}\\
U&:=\langle b_{1},\ldots,b_{p}\rangle\\
U'&:=\langle b'_{1},\ldots,b'_{p'}\rangle\\
V&:=\langle b_{p+1},\ldots,b_{p+q}\rangle\\
V'&:=\langle b'_{p'+1},\ldots,b'_{p'+q'}\rangle\\
\end{align*}
Dann sind \(\left.s_{A}\right|_{U},\,\left.s_{A}\right|_{U'},\,\left.-s_{A}\right|_{V},\,\left.-s_{A}\right|_{V'}\) positiv definit.

F\"ur \(W:=\Kern(\Lambda_{A})=\langle b_{r+1},\ldots,b_{n}\rangle =\langle b'_{r+1},\ldots,b'_{n}\rangle\) gilt
\[
\mathbb{R}^{n}=U\oplus V\oplus W=U'\oplus V'\oplus W
\]
Damit folgt
\[
U\cap(V'\oplus W)=0,
\]
denn 
\begin{align*}
\forall x\in U\cap(V'\oplus W): s_{A}(x,x)\geq 0,s_{A}(x,x)\leq 0&\implies
s_{A}(x,x)=0\\
&\implies x=0
\end{align*}
Damit folgt \(p=\dim U\leq\dim U'=p'\), da 
\begin{align*}
\dim U'+\dim(V'+W)&=n\\
&\geq\dim(U+V'+W)\\
&=\dim(U\oplus V'+W)\\
&=\dim U + \dim (V'+W)
\end{align*}
Aus Symmetriegr\"unden folgt \(p=p'\).
\end{enumerate}
\end{proof}

\paragraph{Fortsetzung der Polynomklassifikation (\(\deg=2\)) \"uber beliebigem
K\"orper \(K\):}{Aus obigem Lemma und Satz folgt: Der quadratische Anteil der
Polynome \(f(x)=x^{\top}Ax+2b^{\top}x+\gamma\) l\"asst sich durch eine geeignete
affine Abbildung \(\vp=(C,d)\) auf folgende einfache Gestalt bringen:
\[
\alpha_{1}x_{1}^{2}+\alpha_{2}x_{2}^{2}+\ldots+\alpha_{n}x_{n}^{2}
\]
\begin{note}
Ab\"andern von \(C\), etwa 
\(C_{1}=\diag(\underbrace{1,\ldots,1}_{r},B)\) mit \(B\in\GL_{n-r}(K)\),
\"andert den quadratischen Anteil \textbf{nicht}.
\end{note}}
\paragraph{N\"achste Vereinfachung:}{linearer Term \(2b'^{\top}y\)\\
Kann eventuell \(2b'^{\top}y=0\) erreicht werden?
\[
b'\overset{\text{Def.}}{=}C^{\top}(Ad+b)=0\Longleftrightarrow Ad+b=0
\]
Das hei\ss t das LGS \(Az=-b\) hat die L\"osung \(z=d\).}
\begin{definition}
\index{Mittelpunkt}\index{Quadrik!Mittelpunkt der}
Falls eine L\"osung \(d\) existiert, so hei\ss t \(d\) \textbf{Mittelpunkt} der
Quadrik.
\end{definition}
\begin{note}
\[
y=d+t\in\mathcal{N}(f)\implies\,d-t\in\mathcal{N}(f)
\]
\end{note}
\begin{proof}
\(f(d+t)=0\), das hei\ss t:
\begin{align*}
&(d+t)^{\top}A(d+t)+2b^{\top}(d+t)+\gamma=0\\
&(d+t)^{\top}A(d+t)+2(-Ad)^{\top}(d+t)+\gamma=0\\
&(d+t)^{\top}A(d+t)-2d^{\top}A(d+t)+\gamma=0\\
\Longleftrightarrow&(d-t)^{\top}A(d+t)+\gamma=0
\end{align*}
\begin{align*}
f(d-t)&=(d-t)^{\top}A(d-t)+2(-Ad)^{\top}(d-t)+\gamma\\
&=-(d-t)^{\top}A(d+t)+\gamma\\
&=0
\end{align*}
\end{proof}
\subsubsection{Affine Klassifikation der Quadriken mit Mittelpunkt}
\begin{enumerate}
\item Fall \(K=\mathbb{C}\):
    \begin{enumerate}
    \item\(f=X_{1}^{2}+\ldots+X_{r}^{2}\quad(\gamma'=0)\)
    \item\(f=X_{1}^{2}+\ldots+X_{r}^{2}+1\quad(\gamma'\neq0)\)
    \end{enumerate}
\item Fall \(K=\mathbb{R}\):
    \begin{enumerate}
    \item\(f=X_{1}^{2}+\ldots+X_{p}^{2}-X_{p+1}^{2}-\ldots-X_{p+q}^{2}\quad
	(\text{ohne Einschr\"ankung }p\geq q)\)
    \item\(f=X_{1}^{2}+\ldots+X_{p}^{2}-X_{p+1}^{2}-\ldots-X_{p+q}^{2}+1\quad
	(\gamma'\neq0)\)
    \end{enumerate}
\end{enumerate}
\begin{example}
\(n=r=2\)
\begin{enumerate}
\item Ellipse: \(f=X_{1}^{2}+X_{2}^{2}-1\)
\item Hyperbel: \(f=X_{1}^{2}-X_{2}^{2}+1\)
\end{enumerate}
\end{example}
\subsubsection{Affine Klassifikation der Quadriken ohne Mittelpunkt}
Jetzt sei \(Az=-b\) unl\"osbar. Es ist aber auch f\"ur \(A\) Diagonalform 
erreichbar: \(A=\diag(\alpha_{1},\ldots,\alpha_{r},0,\ldots,0)\), wobei 
\(r=\rank(A)\) ist.\\
Daraus folgt: es existiert ein \(d\) mit
\[
Ad+b=:c\in\langle e_{r+1},\ldots,e_{n}\rangle\quad(c\neq0)
\]
Nun w\"ahle \(C_{1}=\diag(\underbrace{1,\ldots,1}_{r},B)\), so da\ss \ 
\(C_{1}^{\top}c=-e_{r+1}\).
\[
C_{1}^{\top}c=C_{1}^{\top}(Ad+b)=:b'
\]
\begin{note}
\(c\) bleibt unver\"andert wenn \(d\) durch \(d+y\) mit 
\(y\in\langle e_{r+1},\ldots,e_{n}=\Kern(\Lambda_{A})\) ersetzt wird.
\end{note}
Somit: 
\(f=\alpha_{1}X_{1}^{2}+\ldots+\alpha_{r}X_{r}^{2}
    \underbrace{-2X_{r+1}}_{2b'^{\top}X}+\gamma'\)

Schlie\ss lich: affine Transformation 
\(\vp=\left(I,\frac{1}{2}\gamma'e_{r+1}\right)\) f\"uhrt zu 
\begin{align*}
f&=\alpha_{1}X_{1}^{2}+\ldots+\alpha_{r}X_{r}^{2}-2\left(X_{r+1}+\frac{1}{2}\gamma'\right)+\gamma'\\
&=\alpha_{1}X_{1}^{2}+\ldots+\alpha_{r}X_{r}^{2}-2X_{r=1}
\end{align*}
\begin{enumerate}
\item Fall \(K=\mathbb{C}\): \(f=X_{1}^{2}+\ldots+X_{r}^{2}-2X_{r+1}\quad(\text{f\"ur }r<n)\)
\item Fall \(K=\mathbb{R}\): \(f=X_{1}^{2}+\ldots+X_{p}^{2}-X_{p+1}^{2}-\ldots-X_{p+q}^{2}-2X_{r+1}\quad(p\geq q)\)
\end{enumerate}
\subsubsection{Euklidische Klassifikation}
(\(\vp=(x\mapsto Cx+d)\) mit \(C\in O_{n}\) sei zugelassen)\\
Zur Diagonalisierung von \(A\) verwende den Spektralsatz. Das hei\ss t, es
existiert \(C\in O_{n}:\,C^{\top}AC=\diag(\lambda_{1},\ldots,\lambda_{r},0,\ldots,0)\), 
wobei ohne Beschr\"ankung der Allgemeinheit 
\(\lambda_{1}\geq\ldots\geq\lambda_{r}\) sei.

Der Rest ist wie oben. Damit erhalten wir folgende Normalformen:
\begin{enumerate}
\item\(\lambda_{1}X_{1}^{2}+\ldots+\lambda_{r}X_{r}^{2}\quad\)(bis auf einen
gemeinsamen Faktor \(\mu\neq0\) eindeutig)
\item\(\lambda_{1}X_{1}^{2}+\ldots+\lambda_{r}X_{r}^{2}+1\)
\item\(\lambda_{1}X_{1}^{2}+\ldots+\lambda_{r}X_{r}^{2}-2X_{r+1}\)
\end{enumerate}
\begin{definition}
Die Zahlen \(\lvert\lambda_{i}\rvert^{-\frac{1}{2}}\) hei\ss en 
\index{Halbachse}\index{Halbachsenl\"ange}
\textbf{Halbachsenl\"angen}, die Geraden \(\langle e_{i}\rangle\,(i=1,\ldots,r)\)
\index{Hauptachse}
hei\ss en die \textbf{Hauptachsen} der Quadrik in Normalform.
\index{Hauptachsentransformation}
Der \"Ubergang in Normalform hei\ss t auch \textbf{Hauptachsentransformation}.
\end{definition}

\section{Der Tangentialraum}
\index{Tangentialraum}
Sei \(K\) ein beliebiger K\"orper.
\begin{definition}
\index{Hyperfl\"ache}
Die Nullstellenmenge \(\mathcal{F}=\mathcal{N}(f)\) eines Polynoms
\(f\in K[X_{1},\ldots,X_{n}]\) hei\ss t \textbf{Hyperfl\"ache}.
\end{definition}
Im folgenden sei stets \(\mathcal{N}(f)\neq\varnothing\). Es sei 
\(P\in\mathcal{F}\subseteq K^{n}\) ein Punkt auf der Hyperfl\"ache.\\
Betrachte die Geraden \(G=P+\langle u\rangle\) mit  \(u\in K^{n}\).
\[
Q\in G:\,Q=P+\tau u\quad\text{mit }u\in K^{n}
\]
\begin{note}
\(\mathcal{P}\in\mathcal{F}\) impliziert \(\left.T\right|f(P+Tu)\in K[T]\) (da
Nullstelle bei \(T=0\)).
\end{note}
\begin{definition}
\index{Tangente}
Eine Gerade hei\ss t \textbf{Tangente} an \(\mathcal{F}\) in \(P\), falls
\(\left.T^{2}\right|f(P+Tu)\) gilt.
\end{definition}
\begin{ziel}
Bestimme alle Tangenten durch \(P\) (d.h. \(u\) variiert).
\end{ziel}
Dazu schreibe:
\[
f(P+Tu)=\alpha_{0}+\alpha_{1}T+\alpha_{2}T^{2}+\ldots
    \quad\text{mit }\alpha_{i}=\alpha_{i}(u)
\]
Es gilt: \(\alpha_{1}\in\Hom(K^{n},K)\). Daraus folgt: es existiert ein Vektor
\(J_{p}(f):=J_{p}\in K^{1\times n}\) mit \(\alpha_{1}(u)=J_{p}\cdot u\).
\index{Jacobi-Matrix}
\(J_{p}\) hei\ss t \textbf{Jacobi-Matrix}.

In Analogie zur Analysis schreibe 
\[
J_{p}=:\left.\frac{\partial f}{\partial x}\right|_{x=p}
\]
Es gilt
\[
J_{p}=\left.\left(\frac{\partial f}{\partial X_{1}},\ldots,\frac{\partial f}{\partial X_{n}}\right)\right|_{x=p}
\]
Das hei\ss t: 
\[
G=P+\langle u\rangle\text{ ist Tangente}\Longleftrightarrow J_{p}u=0
    \Longleftrightarrow u\in J_{p}^{\bot}
\]
\begin{definition}
\begin{enumerate}
\item \index{regul\"ar} \(P\in\mathcal{F}\) hei\ss t \textbf{regul\"ar}, falls
    \(J_{p}\neq0\).\\
\index{Tangentialraum}\index{Hyperebene}
Die Hyperebene \(T_{p}(\mathcal{F}):=P+J_{p}^{\bot}\) hei\ss t 
\textbf{Tangentialraum}.
\item \index{singul\"ar}\index{Singularit\"at}Sonst hei\ss t \(P\) \textbf{singul\"ar} (oder \textbf{Singularit\"at}).
\end{enumerate}
\end{definition}
\begin{example}
\index{Kurve}
\begin{enumerate}
\item ``Kurven'' \(y=p(x)\) mit \(p(x)\in K[x]\)
\[
f(X,Y)=Y-p(X)
\]
\(\mathcal{N}(f)\) ist Singularit\"atenfrei, da
\begin{align*}
J_{p}&=\left.\left(\frac{\partial f}{\partial X},\frac{\partial f}{\partial Y}\right)\right|_{(X,Y)=P}\\
&=\left.\left(\frac{\partial p}{\partial X}, 1\right)\right|_{(X,Y)=P}\\
&\neq0
\end{align*}
\item Kurve \(y^{2}-x^{3}\quad f(X,Y)=Y^{2}-X^{3}\)
\[
J_{p}=\left(3X^{2},2Y\right)_{(X,Y)=P}=0\Longleftrightarrow P=(0,0)
\]
Also: \((0,0)\) ist die einzige Singularit\"at.
\end{enumerate}
\end{example}
\begin{theo}
\index{Affinit\"at}\index{Hyperfl\"ache}
Sei \(\vp\) eine Affinit\"at von \(K^{n}\) und \(\mathcal{F}\) eine 
Hyperfl\"ache. Dann gilt
\begin{enumerate}
\item\(P\in\mathcal{F}\) regul\"ar \(\Longleftarrow\,\vp(P)\) regul\"ar in
    \(\vp(\mathcal{F})\)
\item \(P\) regul\"ar \(\Longleftrightarrow\,T_{\vp(P)}(\vp(\mathcal{F}))=\vp(T_{p}(\mathcal{F}))\)
\end{enumerate}
\end{theo}
\begin{proof}
\begin{enumerate}
\item \(\vp(\mathcal{F})=\mathcal{N}\left(f\circ\vp^{-1}\right)\)\\
\index{Taylorentwicklung}
Taylorentwicklung von \(f\circ\vp^{-1}\) bei \(\vp(P)\)\\
Schreibe:
\[
\vp^{-1}(x)=Ax+b
\]
mit \(A=(\alpha_{ij})\in\GL_{n}(K)\).\\
Kettenregel anwenden auf \(f\circ\vp^{-1}(X)=f(AX+b)\) mit\break 
\(X=\begin{pmatrix}X_{1}\\\vdots\\X_{n}\end{pmatrix},\,
    AX+b=\begin{pmatrix}Y_{1}\\\vdots\\Y_{n}\end{pmatrix}\).
\begin{align*}
\left.\frac{\partial f}{\partial X_{i}}(AX+b)\right|_{X=\vp(P)}&=
    \left.\sum_{j=1}^{n}{\frac{\partial f}{\partial X_{j}}}\right|_{Y=P}\cdot
    \left.\frac{\partial(AX+b)_{j}}{\partial X_{i}}\right|_{X=\vp(P)}\\
&=J_{p}(f)\cdot\begin{pmatrix}\alpha_{1i}\\\vdots\\\alpha_{ni}\end{pmatrix}\\
\end{align*}
Damit folgt: 
\[
J_{\vp(P)}\left(f\circ\vp^{-1}\right)=J_{P}(f)\cdot A
\]
\begin{align*}
P\text{ regul\"ar in }\mathcal{F}&\Longleftrightarrow J_{P}(f)\neq0\\
&\overset{\exists A^{-1}}{\Longleftrightarrow}J_{\vp(P)}\left(f\circ\vp^{-1}\right)\neq0\\
&\Longleftarrow\vp(P)\text{ regul\"ar in }\vp(\mathcal{F})
\end{align*}
\item\begin{align*}
T_{\vp(P)}(\vp(\mathcal{F}))&=\vp(P)+J_{\vp(P)}\left(f\circ\vp^{-1}\right)^{\bot}\\
&\overset{!}{=}\vp(\underbrace{P+J_{P}(f)^{\bot}}_{=T_{P}(\mathcal{F})})
\end{align*}
\begin{align*}
J_{P}(f)Av=0&\Longleftrightarrow Av\in J_{P}(f)^{\bot}\\
&\Longleftrightarrow v\in A^{-1}\left(J_{P}(f)^{\bot}\right)
\end{align*}
\begin{note}
\(A^{-1}=\Lambda_{\vp}\)
\end{note}
\end{enumerate}
\end{proof}
\begin{example}
\(\mathcal{F}=Q\) Quadrik mit \(f(P)=P^{\top}AP+2b^{\top}P+\gamma=0\quad
    \left(A=A^{\top}\right)\). Damit folgt:
\begin{align*}
f(P+Tu)&=\underbrace{f(P)}_{=0}+2TP^{\top}Au+2Tb^{\top}u+T^{2}u^{\top}Au\\
&=T\cdot2\left(P^{\top}A+b^{\top}\right)u+T^{2}u^{\top}Au\\
&=T\cdot J_{P}(f)\cdot u+T^{2}u^{\top}Au\\
\end{align*}
\(P\) singul\"ar genau dann wenn \(f(P)=0\) und \(AP=-b\) (das liefert entweder
eine Hyperebene oder die leere Menge).
\end{example}
Aus dem obigen Satz folgt:
\index{Singularit\"at}\index{Affinit\"at}
\begin{enumerate}
\item Alle Singularit\"aten bleiben bei Affinit\"aten erhalten
\item Es gen\"ugt die Normalformen der affinen Klassifikation auf 
    Singularit\"aten zu untersuchen
\end{enumerate}

\section{Die oskulierende Quadrik}
\index{Quadrik!oskulierend}

Sei \(\mathcal{F}=\mathcal{N}(f)\in K^{n}\) Hyperfl\"ache, \(P\in\mathcal{F}\)
regul\"arer Punkt mit
\[
T_{P}(\mathcal{F})=
    \left\{P+(\lambda_{1},\ldots,\lambda_{n})^{\top},\,
\lambda_{i}\in K,\,\left(\frac{\partial f}{\partial X_{1}},\ldots,
    \frac{\partial f}{\partial X_{n}}\right)_{X=P}\cdot
    (\lambda_{1},\ldots,\lambda_{n})^{\top}=0\right\}
\]
Die definierende Gleichung ist aus der formalen Taylorentwicklung um \(P\)
ablesbar.
\[
f\left(P+(\lambda_{1},\ldots,\lambda_{n})^{\top}\right)=f(P)+
    \left.\frac{\partial f}{\partial X}\right|_{X=P}\cdot
    \begin{pmatrix}\lambda_{1}\\\vdots\\\lambda_{n}\end{pmatrix}+\frac{1}{2}
    \sum_{i,j=1}^{n}{
	\left.\frac{\partial^{2}f}{\partial X_{i}X_{j}}\right|_{X=P}
	\lambda_{i}\lambda_{j}}+\text{ h\"ohere Terme}
\]
(Dabei ist \(\Char(K)\neq2\))\\
\index{Tangentialraum}\index{Approximation}\index{N\"aherung}
Daher sagt man: Der Tangentialraum approximiert \(\mathcal{F}\) in einer
Umgebung von \(P\) in ``erster'' N\"aherung (d.h. Terme vom Grad gr\"o\ss er
2 weglassen).
Die Approximation wird besser je h\"oher der Grad der zugelassenen Terme ist.

Wir lassen nun nur Terme bis zum Grad 2 zu.
\begin{definition}
Die Quadrik
\[
Q_{P,\mathcal{F}}:=\left\{
    P+\begin{pmatrix}\lambda_{1}\\\vdots\\\lambda_{n}\end{pmatrix}\mid
    \left.\frac{\partial f}{\partial X}\right|_{X=P}\cdot
	\begin{pmatrix}\lambda_{1}\\\vdots\\\lambda_{n}\end{pmatrix}
    +\frac{1}{2}\sum_{i,j}{
	\left.\frac{\partial^{2}f}{\partial X_{i}X_{j}}\right|_{X=P}
	\cdot\lambda_{i}\lambda_{j}}=0\right\}
\]
hei\ss t \textbf{oskulierende} Quadrik zu \(\mathcal{F}\) im Punkt \(P\) (auch
\index{Quadrik!oskulierend}\index{Quadrik!Schmieg-}
\textbf{Schmieg-Quadrik} genannt).
\end{definition}
\begin{comment}
\index{Quadrik!oskulierend}\index{Tangentialraum}\index{Affinit\"at}
\index{Invariante!affine}
Die oskulierende Quadrik ist eine affine Invariante wie der Tangentialraum, d.h.
f\"ur jede Affinit\"at \(\vp\) gilt:
\[
Q_{\vp(P),\vp(\mathcal{F})}=\vp\left(Q_{P,\mathcal{F}}\right)
\]
\end{comment}
\begin{proof}
wie f\"ur den Tangentialraum.
\end{proof}
\begin{example}
\index{Torus}\index{Torusfl\"ache}
Die \textbf{Torusfl\"ache}\\
\(\mathcal{T}=\mathcal{N}(f)\subseteq\mathbb{R}^{3}\) f\"ur
\[
f(x,y,z)=(R^{2}-r^{2}+x^{2}+y^{2}+z^{2})-4R^{2}(x^{2}=y^{2})
\]
% Hier kommt noch ein schoenes Bild hin
Wir ben\"otigen eine Liste der partiellen Ableitungen:
\begin{align*}
f_{x}&=4x(-R^{2}-r^{2}+x^{2}+y^{2}+z^{2})\\
f_{y}&=4y(-R^{2}-r^{2}+x^{2}+y^{2}+z^{2})\\
f_{z}&=4z(R^{2}-r^{2}+x^{2}+y^{2}+z^{2})
\end{align*}
\index{Punkt!singul\"ar}\index{Punkt!regul\"ar}
Welche singul\"aren Punkte
\(\left.f\right|_{P}=0=
    \left.f_{x}\right|_{P}=\left.f_{y}\right|_{P}=\left.f_{z}\right|_{P}\)
existieren?
\begin{itemize}
\item{Fall \(0<r<R\):}
\[
R^{2}-r^{2}+x^{2}+y^{2}+z^{2}>0\quad\forall x,\,y,\,z\in\mathbb{R}
\]
Aus \(P=(x,y,z)\) singul\"ar folgt \(z=0\) (da \(\left.f_{z}\right|_{P}=0\)).
W\"ahre \(x\neq0\) oder \(y\neq0\), so erg\"abe \(f_{x}=f_{y}=0\)
\[
x^{2}+y^{2}=R^{2}+r^{2}
\]
In \(f\) einsetzen:
\[
\left(2R^{2}\right)^{2}=4R^{2}(R^{2}+r^{2})\quad\text{Widerspruch!}
\]
Also folgt \(x=y=z=0\). Aber: \(f(0,0,0)=R^{2}-r^{2}>0\), da \(R>r\), d.h.
\((0,0,0)\not\in\mathcal{T}\).

Damit sind alle Punkte auf \(\mathcal{T}\) regul\"ar.
\item{Fall \(r\geq R>0\):}\\
Es gibt singul\"are Punkte. Welche? \"Ubung. % ;-)
\end{itemize}
\end{example}

\renewcommand{\indexname}{Stichwortverzeichnis}
\printindex
\end{document}
